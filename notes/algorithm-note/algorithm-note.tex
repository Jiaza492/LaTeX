\documentclass[12pt]{article}
\parindent=.25in

\setlength{\oddsidemargin}{0pt}
\setlength{\textwidth}{440pt}
\setlength{\topmargin}{0in}

\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{algpseudocode}
\usepackage{algorithm}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\title{Introduction to Algorithms Note}
\author{Mengqi Zong $<mz2326@columbia.edu>$}

\begin{document}

\maketitle

\tableofcontents

\setlength{\parindent}{0in}

\section{The Role of Algorithms in Computing}

Informally, an \textbf {algorithm} is any well-defined computational procedure that takes some value, or set of values, as \textbf {input} and produces some value, or set of values, as \textbf {output}. An algorithm is thus a sequence of computational steps that transform the input into the output.

\section{Getting Started}

\subsection{Insertion sort}

INSERTION-SORT(A)
\begin{algorithmic}[1]
\For {$j = 2 \textbf { to } A.length$}
	\State $key = A[j]$
        \State // Insert $A[j]$ into the sorted sequence $A[1..j-1]$.
        \State $i = j - 1$
        \While {$i > 0$ and $A[i] > key$}
        	\State $A[i+1] = A[i]$
                \State $i = i - 1$
        \EndWhile
        \State $A[i+1] = key$
\EndFor
\end{algorithmic}

\subsection{Merge sort}

MERGE($A, p, q, r$)
\begin{algorithmic}[1]
\State $n_1 = q - p + 1$
\State $n_2 = r - q$
\State let $L[1..n_1+1]$ and $R[1..n_2+1]$ be new arrays
\For {$i = 1 \textbf { to } n_1$}
	\State $L[i] = A[p+i-1]$
\EndFor
\For {$j = 1 \textbf { to } n_2$}
	\State $R[j] = A[q+j]$
\EndFor
\State $L[n_1 + 1] = \infty$
\State $R[n_2 + 1] = \infty$
\State $i = 1$
\State $j = 1$
\For {$k = p \textbf { to } r$}
	\If {$L[i] \le R[j]$}
        	\State $A[k] = L[i]$
                \State $i = i + 1$
        \Else
        	\State $A[k] = R[j]$
        	\State $j = j + 1$
        \EndIf
\EndFor
\end{algorithmic}

MERGE-SORT($A, p, r$)
\begin{algorithmic}[1]
\If {$p < r$}
	\State $q = \lfloor (p+r)/2 \rfloor$
        \State MERGE-SORT($A, p, q$)
        \State MERGE-SORT($A, q+1, r$)
        \State MERGE($A, p, q, r$)
\EndIf
\end{algorithmic}

\section{Growth of Functions}

\subsection{Asymptotic notation}

\begin{eqnarray*}
  \Theta (g(n)) = \{ f(n): && \text{there exist positive constants
    $c_1$, $c_2$, and $n_0$ such that} \\
  && 0 \le c_1 g(n) \le f(n) \le c_2 g(n) \text{ for all } n \ge n_0 \} \\
  O(g(n)) = \{ f(n): && \text{there exist positive constants
    $c$ and $n_0$ such that} \\
  && 0 \le f(n) \le cg(n) \text{ for all } n \ge n_0 \} \\
  \Omega (g(n)) = \{ f(n): && \text{there exist positive constants
    $c$ and $n_0$ such that} \\
  && 0 \le cg(n) \le f(n) \text{ for all } n \ge n_0 \}
\end{eqnarray*}

\subsection{Common functions}

\begin{eqnarray*}
  e^x &=& \sum_0^{\infty} \frac {x^i}{i!} \\
  e^x &=& \lim_{n \rightarrow \infty} (1 + \frac {x}{n})^n \\
  n!  &=& \sqrt {2 \pi n} \left(\frac {n}{e} \right)^n 
          \left( 1 + \Theta \left( \frac {1}{n} \right) \right)
\end{eqnarray*}

\section{Divide-and-Conquer}

\subsection{The master method}

\begin{theorem}
  Let $a \ge 1$ and $b \ge 1$ be constants, let $f(n)$ be a function, and let $T(n)$ be defined on the non-negative integers by recurrence
  \begin{equation*}
    T(n) = aT(n/b) + f(n),
  \end{equation*}
  where we interpret $n/b$ to mean either $\lfloor n/b \rfloor$ or $\lceil n/b \rceil$. Then $T(n)$ has the following asymptotic bounds:
  \begin{enumerate}
  \item If $f(n) = O(n^{\log_b^a - \epsilon})$ for some constant $\epsilon > 0$, then $T(n) = \Theta (n^{\log_b a})$.
  \item If $f(n) = \Theta (n^{\log_b^a})$, then $T(n) = \Theta (n^{\log_b a} \lg n)$.
  \item If $f(n) = O(n^{\log_b^a + \epsilon})$ for some constant $\epsilon > 0$, and if $af(n/b) \le cf(n)$ for some constant $c < 1$ and all sufficiently large $n$, then $T(n) = \Theta \left( f(n) \right)$.
  \end{enumerate}
\end{theorem}

\section{Probabilistic Analysis and Randomized Algorithms}

\subsection{Indicator random variables}

Suppose we are given a sample space $S$ and an event $A$. Then the \textbf {indicator random variable} $I\{A\}$ associated with event A is defined as
\begin{equation*}
  I\{A\} =
  \begin{cases}
    1 & \text{if $A$ occurs,} \\
    0 & \text{if $A$ does not occur.}
  \end{cases}
\end{equation*}

\begin{lemma}
  Given a sample space $S$ and an event $A$ in the sample space $S$, let $X_A = I\{ A \}$. Then $E[X_A] = Pr \{ A \}$.
\end{lemma}

\subsection{The hiring problem}

HIRE-ASSISTANT($n$)
\begin{algorithmic}[1]
\State best = 0
\Comment candidate $0$ is a least-qualified dummy candidate
\For {$i = 1 \textbf { to } n$}
	\State interview candidate $i$
        \If {candidate $i$ is better than candidate $best$}
        	\State $best = i$
                \State hire candidate $i$
        \EndIf
\EndFor
\end{algorithmic}

\begin{lemma}
  Assuming that the candidates are presented in a random order, algorithm HIRE-ASSISTANT has a total hiring cost of $O(c_h \ln n)$.
\end{lemma}

Let $X$ be the random variable whose value equals the number of times we hire a new office assistant. Now we can compute $E[X]$:
\begin{eqnarray*}
  E[X]
  &=& E \left[ \sum_{i=1}^n X_i \right] \\
  &=& \sum_{i=1}^n E[X_i] \\
  &=& \sum_{i=1}^n 1/i \\
  &=& \ln n + O(1)
\end{eqnarray*}

\subsection{Probabilistic analysis and further uses of indicator random variables}

\subsubsection{The birthday paradox}

How many people must be in a room before there is a $50 \%$ chance that two of them were born on the same day of the year? \\

The event that $k$ people have distinct birthday is
\begin{equation*}
  B_k = \bigcap_{i=1}^k A_i,
\end{equation*}
where $A_i$ is the event that person $i$'s birthday is different from person $j$'s for all $j < i$. Since we can write $B_k = A_k \cap B_{k-1}$, we get
\begin{eqnarray*}
  Pr \{ B_k \} 
  &=& Pr \{ B_{k-1} \} Pr \{ A_k | B_{k-1} \} \\
  &=& Pr \{ B_{k-2} \} Pr \{ A_{k-1} | B_{k-2} \} Pr \{ A_{k} | B_{k-1} \} \\
  &\vdots& \\
  &=& Pr \{ B_{1} \} Pr \{ A_{2} | B_{1} \} Pr \{ A_{3} | B_{2} \} \cdots
      Pr \{ A_{k} | B_{k-1} \} \\
  &=& 1 \cdot \left( \frac {n-1}{n} \right) \left( \frac {n-2}{n} \right)
      \cdots \left( \frac {n-k+1}{n} \right) \\
  &=& 1 \cdot \left( 1 - \frac {1}{n} \right) \left( 1 - \frac {2}{n} \right)
      \cdots \left( 1 - \frac {k-1}{n} \right)
\end{eqnarray*}
Inequality $1 + x \le e^x$ gives us
\begin{eqnarray*}
  Pr \{ B_k \} 
  &\le& e^{-1/n} e^{-2/n} \cdots e^{-(k-1)/n} \\
  &=& e^{- \sum_{i=1}^{k-1} i/n} \\
  &=& e^{-k(k-1)/2n} \\
  &\le& 1/2
\end{eqnarray*}
when $-k(k-1)/2n \le \ln(1/2)$. we get $k \ge (1 + \sqrt {1 + (8 \ln 2)n})/2$. For $n = 365$, we must have $k \ge 23$.

\subsubsection{Balls and bins}

Consider the process of randomly tossing identical balls into $b$ bins, numbered $1, 2, \dots, b$. The tosses are independent, and on each toss the ball is equally likely to end up in any bin. \\

\emph{How many balls must one toss until every bin contains at least one ball?} Let us call a toss in which a ball falls into an empty bin a ``hit''. We want to know the expected number $n$ of tosses required to get $b$ hits. \\

The hits can be used to partition the $n$ tosses into stages. The $i$th stage consists of the tosses after the $(i-1)$st hit until the $i$th hit. Let $n_i$ denote the number of tosses in the $i$th stage. We get
\begin{equation*}
  E[n_i] = \frac {b}{b - i + 1}
\end{equation*}
By linearity of expectation,
\begin{eqnarray*}
  E[n]
  &=& E \left[ \sum_{i=1}^b n_i  \right] \\
  &=& \sum_{i=1}^b [n_i] \\
  &=& \sum_{i=1}^b \frac {b}{b-i+1} \\
  &=& \sum_{i=1}^b \frac {1}{i} \\
  &=& b( \ln b + O(1)).
\end{eqnarray*}
The problem is also known as the \textbf {coupon collector's problem}.

\subsubsection{Streaks}

Suppose you flip a fair coin $n$ times. What is the longest streak of consecutive heads that you expect to see? The answer is $\Theta (\lg n)$. \\

Let $A_{i,k}$ be the event that a streak of heads of length at least $k$ begins with the $i$th coin flip or, more precisely, the event that the k consecutive coin flips $i, i + 1, \dots, i + k -1$ yield only heads, where $1 \le k \le n$ and $1 \le i \le n - k + 1$. Since coin flips are mutually independent, for any given event $A_{ik}$, the probability that all $k$ flips are heads is
\begin{equation*}
  Pr \{ A_{ik} \} = 1 / 2^k.
\end{equation*}
For $k = 2 \lceil \lg n \rceil$,
\begin{eqnarray*}
  Pr \{ A_{i, 2 \lceil \lg n \rceil} \}
  &=& 1 / 2^{2 \lceil \lg n \rceil} \\
  &\le& 1 / 2^{2 \lg n} \\
  &=& 1 / n^2
\end{eqnarray*}
There are at most $n - 2 \lceil \lg n \rceil + 1$ positions where such a streak can begin. The probability that a streak of heads of length at least $2 \lceil \lg n \rceil$ begins anywhere is therefore
\begin{eqnarray*}
  Pr \left\{ \bigcup_{i=1}^{n - 2 \lceil \lg n \rceil + 1} A_{i,2 \lceil \lg n \rceil} \right\}
  &\le&  \sum_{i=1}^{n - 2 \lceil \lg n \rceil + 1} 1 / n^2 \\
  &<& \sum_{i=1}^n 1 / n^2 \\
  &=& 1/n,
\end{eqnarray*}
since Boole's inequality,
\begin{equation*}
  Pr \{ A_1 \cup A_2 \cup \cdots \} \le Pr \{ A_1 \} + Pr \{ A_2 \} + \cdots,
\end{equation*}
the probability of a union of events is at most the sum of the probabilities of the individual events. \\

By the definition of expected value,
\begin{eqnarray*}
  E[L]
  &=& \sum_{j=0}^{n} j Pr \{ L_j \} \\
  &=& \sum_{j=0}^{2 \lceil \lg n \rceil - 1} j Pr \{ L_j \}
      + \sum_{j = 2 \lceil \lg n \rceil - 1}^{n} j Pr \{ L_j \} \\
  &<& \sum_{j=0}^{2 \lceil \lg n \rceil - 1} (2 \lceil \lg n \rceil - 1)
      Pr \{ L_j \} + \sum_{j = 2 \lceil \lg n \rceil - 1}^{n} n Pr \{ L_j \} \\
  &=& 2 \lceil \lg n \rceil - 1 \sum_{j=0}^{2 \lceil \lg n \rceil - 1} 
      Pr \{ L_j \} + n \sum_{j = 2 \lceil \lg n \rceil - 1}^{n} Pr \{ L_j \} \\
  &<& 2 \lceil \lg n \rceil - 1 \cdot 1 + n \cdot (1/n) \\
  &=& O(\lg n)
\end{eqnarray*}
The chances that a streak of heads exceeds $r \lceil \lg n \rceil$ flips diminish quickly with $r$. For $r \ge 1$, the probability that a streak of $r \lceil \lg n \rceil$ heads starts in position $i$ is
\begin{eqnarray*}
  Pr \{ A_{i, r \lceil \lg n \rceil} \}
  &=& 1 / 2^{r \lceil \lg n \rceil} \\
  &\le& 1 / n^r
\end{eqnarray*}
Thus, the probability is at most $n / n^r = 1 / n^{r-1}$ that the longest streak is at least $r \lceil \lg n \rceil$. \\

We now prove a complementary lower bound: the expected length of the longest streak of heads in $n$ coin flips is $\Omega (\lg n)$. To prove this bound, we look for streaks of length $s$ by partitioning the $n$ flips into approximately $n/s$ groups of $s$ flips each. If we choose $s = \lfloor (\lg n)/2 \rfloor$, we can show that it is likely that at least one of these groups comes up all heads, and hence it is likely that the longest streak has length at least $s = \Omega (\lg n)$. We then show that the longest streak has expected length $\Omega (\lg n)$.
\begin{eqnarray*}
  Pr \{ A_{i, \lfloor (\lg n)/2 \rfloor} \}
  &=& 1 / 2^{\lfloor (\lg n)/2 \rfloor} \\
  &\ge& 1 / \sqrt n.
\end{eqnarray*}
The probability that a streak of heads of length at least $\lfloor (\lg n)/2 \rfloor$ does not begin in position $i$ is therefore at most $1 - 1 / \sqrt n$. Since the $\lfloor n / \lfloor (\lg n)/2 \rfloor \rfloor$ groups are formed from mutually exclusive, independent coin flips, the probability that every one of these groups fails to be a streak of length $\lfloor (\lg n)/2 \rfloor$ is at most
\begin{eqnarray*}
  (1 - 1 / \sqrt n)^{\lfloor n/ {\lfloor (\lg n)/2 \rfloor} \rfloor}
  &\le& (1 - 1 / \sqrt n)^{n/ {\lfloor (\lg n)/2 \rfloor} - 1} \\
  &\le& (1 - 1 / \sqrt n)^{2n/ {\lg n} - 1} \\
  &\le& e^{-(2n/ {\lg n} -1)/{\sqrt n}} \\
  &=& O(e^{- \lg n}) \\
  &=& O(1/n)
\end{eqnarray*}
For this argument, we used $(2n / {\lg n} - 1) / {\sqrt n} \ge \lg n$ for sufficiently large $n$. \\

Thus , the probability that the longest streak exceeds $\lfloor (\lg n)/2 \rfloor$ is
\begin{equation*}
  \sum_{j = \lfloor (\lg n)/2 \rfloor + 1}^{n} Pr \{ L_j \} \ge 1 - O(1/n)
\end{equation*}
We can now calculate a lower bound on the expected length of the longest streak:
\begin{eqnarray*}
  E[L]
  &=& \sum_{j=0}^{n} j Pr \{ L_j \} \\
  &=& \sum_{j=0}^{\lfloor (\lg n)/2 \rfloor} j Pr \{ L_j \}
      + \sum_{j = \lfloor (\lg n)/2 \rfloor + 1}^{n} j Pr \{ L_j \} \\
  &\ge& \sum_{j=0}^{\lfloor (\lg n)/2 \rfloor} 0 \cdot Pr \{ L_j \}
      + \sum_{j = \lfloor (\lg n)/2 \rfloor + 1}^{n} 
      \lfloor (\lg n)/2 \rfloor Pr \{ L_j \} \\
  &=& 0 \cdot \sum_{j=0}^{\lfloor (\lg n)/2 \rfloor} \cdot Pr \{ L_j \}
      + \lfloor (\lg n)/2 \rfloor \sum_{j = \lfloor (\lg n)/2 \rfloor + 1}^{n}
      Pr \{ L_j \} \\
  &\ge& 0 + \lfloor (\lg n)/2 \rfloor (1 - O(1/n)) \\
  &=& \Omega (\lg n).
\end{eqnarray*}
As with the birthday paradox, we can obtain a simpler but approximate analysis using indicator random variables. We let $X_{ik} = I \{ A_{ik} \}$ be the indicator random variable associated with a streak of heads of length at least $k$ beginning with the $i$th coin flip. To count the total number of such streaks, we define
\begin{equation*}
  X = \sum_{i=1}^{n-k+1} X_{ik}.
\end{equation*}
Taking expectations and using linearity of expectation, we have
\begin{eqnarray*}
  E[X]
  &=& E \left[ \sum_{i=1}^{n-k+1} X_{ik} \right] \\
  &=& \sum_{i=1}^{n-k+1} E[X_{ik}] \\
  &=& \sum_{i=1}^{n-k+1} Pr \{ X_{ik} \} \\
  &=& \sum_{i=1}^{n-k+1} 1 / 2^k \\
  &=& \frac {n-k+1}{2^k}
\end{eqnarray*}
By plugging in various values for $k$, we can calculate the expected number of streaks of length $k$. If $k = c \lg n$, for some positive constant $c$, we obtain
\begin{eqnarray*}
  E[X]
  &=& \frac {n - c \lg n + 1}{2^{c \lg n}} \\
  &=& \frac {n - c \lg n + 1}{n^c} \\
  &=& \frac {1}{n^c - 1} - \frac {(c \lg n - 1)/n}{n^{c-1}} \\
  &=& \Theta(1 / n^{c-1}).
\end{eqnarray*}

\section{Heapsort}

Like merge sort, but unlike insertion sort, heapsort's running time is $O(n \lg n)$. Like insertion sort, but unlike merge sort, heapsort sorts in place: only a constant number of array elements are stored outside the input array at any time.

\subsection{Heaps}

The \textbf {(binary) heap} data structure is an array object that we can view as a nearly complete binary tree. \\

PARENT($i$)
\begin{algorithmic}[1]
\State \textbf {return} $\lfloor i/2 \rfloor$
\end{algorithmic}

LEFT($i$)
\begin{algorithmic}[1]
\State \textbf {return} $2i$
\end{algorithmic}

RIGHT($i$)
\begin{algorithmic}[1]
\State \textbf {return} $2i+1$
\end{algorithmic}

There are two kinds of binary heaps: max-heaps and min-heaps. In both kinds, the values in the nodes satisfy a {\bf heap property}, the specifics of which depends on the kind of heap. In a {\bf max-heap}, the {\bf max-heap property} is that for every node $i$ other than the root,
\begin{equation*}
  A[\text{PARENT}(i)] \ge A[i],
\end{equation*}
that is, the value of a node is at most the value of its parent. \\

Viewing a heap as a tree, we define the {\bf height} of a node in a heap to be the number of edges on the longest simple downward path from the node to a leaf, and we define the height of the heap to be the height of its root.

\subsection{Maintaining the heap property}

MAX-HEAPIFY 's inputs are an array $A$ and an index $i$ into the array. When it is called, MAX-HEAPIFY assumes that the binary trees rooted at LEFT($i$) and RIGHT($i$) are max-heaps, but that $A[i]$ might be smaller than its children, thus violating he max-heap property. MAX-HEAPIFY lets the value at $A[i]$ ``float down'' in the max-heap so that the subtree rooted an index $i$ obeys the max-heap property. \\

 MAX-HEAPIFY($A,i$)
\begin{algorithmic}[1]
\State $l = \text {LEFT}(i)$
\State $r = \text {RIGHT}(i)$
\If {$l \le A.\text{heap-size}$ and $A[l] > A[i]$}
	\State $largest = l$
\Else
	\State $largest = i$
\EndIf
\If {$r \le A.\text{heap-size}$ and $A[r] > A[largest]$}
	\State $largest = r$
\EndIf
\If {$largest \neq i$}
	\State exchange $A[i]$ with $A[largest]$
        \State MAX-HEAPIFY($A, largest$)
\EndIf
\end{algorithmic}

We can describe the running time of MAX-HEAPIFY by recurrence
\begin{equation*}
  T(n) \le T(2n/3) + \Theta(1).
\end{equation*}
Worst case occurs when the bottom level of the tree is exactly half full. The solution to this recurrence is $T(n) = O(\lg n)$. Alternatively, we can characterize the running time of MAX-HEAPIFY on a node of height $h$ as $O(h)$.

\subsection{Building a heap}

BUILD-MAX-HEAP(A)
\begin{algorithmic}[1]
\State $A.\text{heap-size} = A.length$
\For {$i = \lfloor A.length/2 \rfloor \text {{ \bf downto} } 1$}
	\State MAX-HEAPIFY($A, i$)
\EndFor
\end{algorithmic}

The time required by MAX-HEAPIFY when called on a node of height $h$ is $O(h)$, so we can express the total cost of BUILD-MAX-HEAP as
\begin{eqnarray*}
  \sum_{h=0}^{\lfloor \lg n \rfloor} \lceil \frac {n}{2^{h+1}} \rceil O(h)
  &=& O(n \sum_{h=0}^{\lfloor \lg n \rfloor} \frac {h}{2^h}) \\
  &=& O(n \sum_{h=0}^{\infty} \frac {h}{2^h}) \\
  &=& O(2n) \\
  &=& O(n)
\end{eqnarray*}

\subsection{The heapsort algorithm}

HEAPSORT(A)
\begin{algorithmic}[1]
\State BUILD-MAX-HEAP(A)
\For {$i = A.length \text {{ \bf downto} } 2$}
	\State exchange $A[1]$ with $A[i]$
        \State $A.\text{heap-size} = A.\text{heap-size} - 1$
	\State MAX-HEAPIFY($A, 1$)
\EndFor
\end{algorithmic}

The HEAPSORT procedure takes time $O(n \lg n)$, since the call to BUILD-MAX-HEAP takes time O(n) and each of the $n-1$ calls to MAX-HEAPIFY takes time $O(\lg n)$.

\subsection{Priority queues}

HEAP-MAXIMUM(A)
\begin{algorithmic}[1]
\State \textbf {return} $A[1]$
\end{algorithmic}

HEAP-EXTRACT-MAX(A)
\begin{algorithmic}[1]
\If {$A.\text{heap-size} < 1$}
	\State \textbf {error} ``heap underflow''
\EndIf
\State $max$ = A[1]
\State $A[1] = A[A.\text{heap-size}]$
\State $A.\text{heap-size} = A.\text{heap-size} - 1$
\State MAX-HEAPIFY($A,1$)
\State \textbf {return} $max$
\end{algorithmic}

The running time of HEAP-EXTRACT-MAX is $O(\lg n)$, since it performs only a constant amount of work on top of the $O(\lg n)$ time for MAX-HEAPIFY. \\

HEAP-INCREASE-KEY($A, i, key$)
\begin{algorithmic}[1]
\If {$key < A[i]$}
	\State \textbf {error} ``new key is smaller than current key''
\EndIf
\State $A[i] = key$
\While {$i > 1$ and $A[\text {PARENT}(i)] < A[i]$}
	\State exchange $A[i]$ with $A[\text {PARENT}(i)]$
        \State $i = \text {PARENT}(i)$
\EndWhile
\end{algorithmic}

The running time of HEAP-INCREASE-KEY on an $n-$element heap is $O(\lg n)$. \\

MAX-HEAP-INSERT($A, key$)
\begin{algorithmic}[1]
\State $A.\text{heap-size} = A.\text{heap-size} + 1$
\State $A[A.\text{heap-size}] = -\infty$
\State HEAP-INCREASE-KEY($A, A.\text{heap-size},key$)
\end{algorithmic}

The running time of MAX-HEAP-INSERT on an $n-$element heap is $O(\lg n)$. \\

In summary, a heap can support any priority-queue operation on a set of size $n$ in $O(\lg n)$ time.

\section{Quicksort}

\subsection{Description of quicksort}

QUICKSORT($A, p, r$)
\begin{algorithmic}[1]
\If {$p < r$}
	\State $q = \text {PARTITION}(A, p, r)$
        \State QUICKSORT($A, p, q-1$)
        \State QUICKSORT($A, q+1, r$)
\EndIf
\end{algorithmic}

To sort an array $A$, the initial call is QUICKSORT($A, 1, A.length$). \\

PARTITION($A, p, r$)
\begin{algorithmic}[1]
\State $x = A[r]$
\State $i = p - 1$
\For {$j = p \textbf { to } r-1$}
	\If {$A[j] \le x$}
        	\State $i = i + 1$
                \State exchange $A[i]$ with $A[j]$
        \EndIf
\EndFor
\State exchange $A[i+1]$ with $A[r]$
\State \textbf{return } $i+1$
\end{algorithmic}

\subsection{Performance of quicksort}

\begin{itemize}
  \item \textbf{Worst-case partitioning}
    \begin{eqnarray*}
      T(n)
      &=& T(n-1) + T(0) + \Theta(n) \\
      &=& T(n-1) + \Theta(n).
    \end{eqnarray*}
    We get $T(n) = \Theta (n^2)$. This occurs when the input array is already completely sorted.
  \item \textbf {Best-case partitioning}
    \begin{eqnarray*}
      T(n)
      &=& 2T(n/2) + \Theta(n)
    \end{eqnarray*}
    We get $T(n) = \Theta (n \lg n)$.
  \item \textbf {Balanced partitioning}
    \begin{eqnarray*}
      T(n)
      &=& T(9n/10) + T(n/10) + cn
    \end{eqnarray*}    
    We get $T(n) = \Theta (n \lg n)$.
\end{itemize}

\subsection{A randomized version of quicksort}

RANDOMIZED-PARTITION($A, p, r$)
\begin{algorithmic}[1]
\State $i = \text{RANDOM}(p,r)$
\State exchange $A[r]$ with $A[i]$
\State \textbf{return } PARTITION($A, p, r$)
\end{algorithmic}

RANDOMIZED-QUICKSORT($A, p, r$)
\begin{algorithmic}[1]
\If {$p < r$}
	\State $q = \text {RANDOMIZED-PARTITION}(A, p, r)$
        \State RANDOMIZED-QUICKSORT($A, p, q-1$)
        \State RANDOMIZED-QUICKSORT($A, q+1, r$)
\EndIf
\end{algorithmic}

The expected running time of RANDOMIZED-QUICKSORT is $O(n \lg n)$.

\section{Sorting in Linear Time}

\subsection{Lower bounds for sorting}

\begin{theorem}
  Any comparison sort algorithm requires $\Omega (n \lg n)$ comparisons in the worst case.
\end{theorem}

\begin{corollary}
  Heapsort and merge sort are asymptotically optimal comparison sorts.
\end{corollary}

\subsection{Counting sort}

COUNTING-SORT($A, B, k$)
\begin{algorithmic}[1]
\State let $C[0..k]$ be a new array
\For {$i = 0 \textbf { to } k$}
	\State $C[i] = 0$
\EndFor
\For {$j = 1 \textbf { to } A.length$}
	\State $C[A[j]] = C[A[j]] + 1$
\EndFor
\State // $C[i]$ now contains the number of elements equal to $i$.
\For {i = 1 \textbf { to } k}
	\State $C[i] = C[i] + C[i-1]$
\EndFor
\State // $C[i]$ now contains the number of elements less than or equal to $i$.
\For {j = A.length \textbf { downto } 1}
	\State $B[C[A[j]]] = A[j]$
        \State $C[A[j]] = C[A[j]] - 1$
\EndFor
\end{algorithmic}

\subsection{Radix sort}

RADIX-SORT($A, d$)
\begin{algorithmic}[1]
\For {$i = 1 \textbf { to } d$}
	\State use a stable sort to sort array $A$ on digit $i$
\EndFor
\end{algorithmic}

\begin{lemma}
  Given $n$ $d-$digit numbers in which each digit can take on up to $k$ possible values, RADIX-SORT correctly sorts these numbers in $\Theta(d(n+k))$ time if the stable sort it uses takes $\Theta (n+k)$ time.
\end{lemma}

When $d$ is constant and $k = O(n)$, we can make radix sort run in linear time. More generally, we have some flexibility in how to break each key into digits.

\begin{lemma}
  Given $n$ $b$-bit numbers and any positive integer $r \le b$, RADIX-SORT correctly sorts these numbers in $\Theta ((b/r)(n + 2^r))$ time.
\end{lemma}

For a value $r \le b$, we view each key as having $d = \lceil b/r \rceil$ digits of $r$ bits each. Each digit is an integer in the range $0$ to $2^r-1$, so that we can use counting sort with $k = 2^r -1$.

\subsection{Bucket sort}

\textbf {Bucket sort} assumes that the input is drawn from a uniform distribution and has an average-case running time of $O(n)$. Bucket sort divides the interval $[0,1)$ into $n$ equal-sized sub-intervals, or \textbf {buckets}, and then distributes the $n$ input numbers into the buckets. \\

Our code for bucket sort assumes that the input is an $n$-element array $A$ and that each element $A[i]$ in the array satisfies $0 \le A[i] < 1$. The code requires an auxiliary array $B[0...n-1]$ of linked lists (buckets) and assumes that there is a mechanism for maintaining such lists. \\

BUCKET-SORT($A$)
\begin{algorithmic}[1]
\State let $B[0..n-1]$ be a new array
\State $n = A.length$
\For {$i = 0 \textbf { to } n-1$}
	\State make $B[i]$ an empty list
\EndFor
\For {$i = 1 \textbf { to } n$}
	\State insert $A[i]$ into list $B[\lfloor nA[i] \rfloor ]$
\EndFor
\For {$i = 0 \textbf { to } n-1$}
	\State sort list $B[i]$ with insertion sort
\EndFor
\State concatenate the lists $B[0], B[1], \dots, B[n-1]$ together in order
\end{algorithmic}

Since insertion sort runs in quadratic time, the running time of bucket sort is
\begin{equation*}
  T(n) = \Theta(n) + \sum_{i=0}^{n-1} O(n_i^2).
\end{equation*}
We now analyze the average-case running time of bucket sort, by computing the expected value of the running time, where we take the expectation over the input distribution. We have
\begin{eqnarray*}
  E[T(n)]
  &=& E \left[ \Theta (n) + \sum_{i=0}^{n-1} O(n_i)^2 \right] \\
  &=& \Theta (n) + \sum_{i=0}^{n-1} E \left[ O(n_i)^2 \right] \\
  &=& \Theta (n) + \sum_{i=0}^{n-1} E \left( O[n_i]^2 \right) \\
  &=& \Theta (n) + \sum_{i=0}^{n-1} (2 - 1/n) \\
  &=& \Theta (n)
\end{eqnarray*}

\section{Medians and Order Statistics}

The $i$th \textbf {order statistic} of a set of $n$ elements is the $i$th smallest element.

\subsection{Selection in expected linear time}

RANDOMIZED-SELECT($A, p, r, i$)
\begin{algorithmic}[1]
\If {$p == r$}
	\State \textbf {return } $A[p]$
\EndIf
\State $q = \text{RANDOMIZED-PARTITION}(A, p, r)$
\State $k = q - p + 1$
\If {$i == k$}
\Comment the pivot value is the answer
	\State \textbf {return} $A[q]$
\ElsIf {$i < k$}
	\State \textbf {return} RANDOMIZED-SELECT($A, p, q-1, i$)
\Else
	\State \textbf {return} RANDOMIZED-SELECT($A, q+1, r, i-k$)
\EndIf
\end{algorithmic}

\subsection{Selection in worst-case linear time}

Like RANDOMIZED-SELECT, the algorithm SELECT finds the desired element by recursively partitioning the input array. Here, however, we guarantee a good split upon partitioning the array. SELECT uses the deterministic partitioning algorithm PARTITION from quicksort, but modified to take the element to partition around as an input parameter. \\

The SELECT algorithm determines the $i$th smallest of an input array of $n>1$ distinct elements by executing the following steps. (If $n = 1$, then SELECT merely returns its only input value as the $i$th smallest.)

\begin{enumerate}
  \item Divide the $n$ elements of the input array into $\lfloor n/5 \rfloor$ groups of $5$ elements each and at most one group made up of remaining $n \mod 5$ elements.
  \item Find the median of each of the $\lceil n/5 \rceil$ groups by first insertion-sorting the elements of each group (of which there are at most $5$) and then picking the median from the sorted list of group elements.
  \item Use SELECT recursively to find the median $x$ of the $\lceil n/5 \rceil$ medians found in step $2$. (If there are an even number of medians, then by our convention, $x$ is the lower median.)
  \item Partition the input array around the median-of-medians $x$ using the modified version of PARTITION. Let $k$ be one more than the number of elements on low side of the partition, so that $x$ is the $k$th smallest element and there are $n-k$ elements on the high side of the partition.
  \item If $i = k$, then return $x$. Otherwise, use SELECT recursively to find the $i$th smallest element on the low side if $i < k$, or the $(i-k)$th smallest element on the high side if $i>k$.
\end{enumerate}

\section{Elementary Data Structure}

\begin{enumerate}
  \item Stacks and queues
  \item Linked lists
  \item Implementing pointers and objects
  \item Representing rooted trees
\end{enumerate}

\section{Hash Tables}

\subsection{Direct-address tables}

DIRECT-ADDRESS-SEARCH($T, k$)
\begin{algorithmic}[1]
\State \textbf {return} $T[k]$
\end{algorithmic}

DIRECT-ADDRESS-INSERT($T, x$)
\begin{algorithmic}[1]
\State $T[x.key] = x$
\end{algorithmic}

DIRECT-ADDRESS-DELETE($T, x$)
\begin{algorithmic}[1]
\State $T[x.key] = NIL$
\end{algorithmic}

Each of these operations takes only $O(1)$ time.

\subsection{Hash tables}

With hashing, an element with key $k$ is stored in slot $h(k)$; that is, we use a \textbf {hash function} $h$ to compute the slot from the key $k$. Here, $h$ maps the universe $U$ of keys into the slots of a \textbf {hash table} $T[0..m-1]$:
\begin{equation*}
  h: U \rightarrow \{ 0,1, \dots, m-1 \},
\end{equation*}
where the size $m$ of the hash table is typically much less than $|U|$.

\subsubsection*{Collision resolution by chaining}

In chaining, we place all elements that hash to the same slot into the same linked list.

CHAINED-HASH-INSERT($T, x$)
\begin{algorithmic}[1]
\State insert $x$ at the head of list $T[h(x.key)]$
\end{algorithmic}

CHAINED-HASH-SEARCH($T, k$)
\begin{algorithmic}[1]
\State search for an element with key $k$ in list $T[h(k)]$
\end{algorithmic}

CHAINED-HASH-DELETE($T, x$)
\begin{algorithmic}[1]
\State delete $x$ from the list $T[h(x.key)]$
\end{algorithmic}

\subsubsection*{Analysis of hashing with chaining}

Given a hash table $T$ with $m$ slots that stores $n$ elements, we define the \textbf {load factor} $\alpha$ for $T$ as $n/m$, that is, the average number of elements stored in a chain. Load factor can be less than, equal to, or greater than 1. \\

The average-case performance of hashing depends on how well the hash function $h$ distributes the set of keys to be stored among the $m$ slots, on the average. Now we shall assume that any given element is equally likely to hash into any of the $m$ slots, independently of where any other element has hashed to. We call this the assumption of \textbf {simple uniform hashing}.

\begin{theorem}
  In a hash table in which collisions are resolved by chaining, an unsuccessful search takes average-case time $\Theta (1 + \alpha)$, under the assumption of simple uniform hashing.
\end{theorem}

\begin{theorem}
  In a hash table in which collisions are resolved by chaining, a successful search takes average-case time $\Theta (1 + \alpha)$, under the assumption of simple uniform hashing.
\end{theorem}

\subsection{Hash functions}

A good hash function satisfies (approximately) the assumption of simple uniform hashing: each key is equally likely to hash to any of the $m$ slots, independently of where any other key has hashed to. Unfortunately, we typically have no way to check this condition, since we rarely know the probability distribution from which the keys are drawn. Moreover, the keys might not be drawn independently.

\subsubsection*{Interpreting keys as natural numbers}

Most hash functions assume that the universe of keys is the set $\mathbb {N} = \{0,1,2,\dots \}$ of natural numbers.

\subsubsection{The division method}

In the \textbf {division method} for creating hash functions, we map a key $k$ into one of $m$ slots by taking the remainder of $k$ divided by $m$. That is, the hash function is
\begin{equation*}
  h(k) = k \mod m.
\end{equation*}
A prime not too close to an exact power of $2$ is often a good choice for $m$.

\subsubsection{The multiplication method}

The \textbf {multiplication method} for creating hash functions operates in two steps. First, we multiply the key $k$ by a constant $A$ in the range $0 < A < 1$ and extract the fractional part of $kA$. Then, we multiply this value by $m$ and take the floor of the result. In short, the hash function is
\begin{equation*}
  h(k) = \lfloor m (kA \mod 1) \rfloor,
\end{equation*}
where ``$kA \mod 1$'' means the fractional part of $kA$, that is, $kA - \lfloor kA \rfloor$. \\

An advantage of the multiplication method is that the value of m is not critical. We typically choose it to be a power of $2$ ($m = 2^p$ for some integer $p$), since we can then easily implement the function on most computers as follows. Suppose that the word size of the machine is $w$ bits and that $k$ fits into a single word. We restrict $A$ to be a fraction of the form $s/2^w$, where $s$ is an integer in the range $0 < s < 2^w$. We first multiply $k$ by the $w$-bit integer $s = A \cdot 2^w$. The result is a $2w$-bit value $r_12^w+r_0$, where $r_1$ is the high-order word of the product and $r_0$ is the low-order word of the product. The desired $p$-bit hash value consists of the $p$ most significant bits of $r_0$.

\subsubsection{Universal hashing}

If a malicious adversary chooses the keys to be hashed by some fixed hash function, then the adversary can choose $n$ keys that all hash to the same slot, yielding an average retrieval time of $\Theta(n)$. Any fixed hash function is vulnerable to such terrible worst-case behavior; the only effective way to improve the situation is to choose the hash function randomly in a way that is independent of the keys that are actually going to be stored. This approach, called \textbf {universal hashing}, can yield provably good performance on average, no matter which keys the adversary chooses. \\

In universal hashing, at the beginning of execution we select the hash function at random from a carefully designed class of functions. Because we randomly select the hash function, the algorithm can behave differently on each execution, even for the same input, guaranteeing good average-case performance for any input. \\

Let $\mathcal {H}$ be a finite collection of hash functions that map a given universe $U$ of keys into the range $\{ 0,1,\dots,m-1 \}$. Such a collection is said to be \textbf {universal} if for each pair of distinct keys $k, l \in U$, the number of hash functions $h \in \mathcal {H}$ for which $h(k) = h(l)$ is at most $|\mathcal {H}| / m$. In other words, with a hash function randomly chosen from $\mathcal {H}$, the chance of a collision between distinct keys $k$ and $l$ is no more than the chance $1/m$ of a collision if $h(k)$ and $h(l)$ were randomly and independently chosen from the set $\{ 0,1,\dots, m-1\}$. \\

Recall that $n_i$ denotes the length of list $T[i]$.

\begin{theorem}
  Suppose that a hash function $h$ is chosen randomly from a universal collection of hash functions and has been used to hash $n$ keys into a table $T$ of size $m$, using chaining to resolve collisions. If key $k$ is not in the table, then the expected length $E[n_{h(k)}]$ of the list that key $k$ hashes to is at most the load factor $\alpha = n/m$. If key $k$ is in the table, then the expected length $E[n_{h(k)}]$ of the list containing key $k$ is at most $1 + \alpha$.
\end{theorem}

\begin{corollary}
  Using universal hashing and collision resolution by chaining in an initially empty table with $m$ slots, it takes expected time $\Theta (n)$ to handle any sequence of $n$ INSERT, SEARCH, and DELETE operations containing $O(m)$ INSERT operations.
\end{corollary}

\subsection{Open addressing}

In \textbf {open addressing}, all elements occupy the hash table itself. That is, each table entry contains either an element of the dynamic set or NIL. \\

To perform insertion using open addressing, we successively examine, or \textbf {probe}, the hash table until we find an empty slot in which to put the key. To determine which slot to probe, we extend the hash function to include the probe number (starting from 0) as a second input. Thus, the hash function becomes
\begin{equation*}
  h: U \times \{ 0,1,\dots,m-1 \} \rightarrow \{ 0,1,\dots,m-1 \}.
\end{equation*}
With open addressing, we require that for every key $k$, the \textbf {probe sequence}
\begin{equation*}
  <h(k,0), h(k,1), \dots, h(k, m-1)>
\end{equation*}
be a permutation of $<0,1,\dots,m-1>$, so that every hash-table position is eventually considered as a slot for a new key as the table fills up. \\

HASH-INSERT($T, k$)
\begin{algorithmic}[1]
\State i = 0
\Repeat
	\State $j = h(k,i)$
        \If {$T[j] == \text {NIL}$}
        	\State {$T[j] = k$}
                \State \textbf {return} $j$
        \Else
        	\State $i = i + 1$
        \EndIf
\Until {$i == m$}
\State \textbf {error} ``hash table overflow''
\end{algorithmic}

HASH-SEARCH($T, k$)
\begin{algorithmic}[1]
\State i = 0
\Repeat
	\State $j = h(k,i)$
        \If {$T[j] == k$}
                \State \textbf {return} $j$
        \EndIf
        \State $i = i + 1$
\Until {$T[j] == \text {NIL or } i == m$}
\State \textbf {return} NIL
\end{algorithmic}

\subsubsection*{Linear probing}

Given an ordinary hash function $h': U \rightarrow \{ 0,1,\dots,m-1 \}$, which we refer to as an \textbf {auxiliary hash function}, the method of \textbf {linear probing} uses the hash function
\begin{equation*}
  h(k,i) = (h'(k) + i) \mod m
\end{equation*}
for $i = 0,1,\dots,m-1$. Linear probing is easy to implement, but it suffers from a problem known as \textbf {primary clustering}. Long runs of occupied slots build up, increasing the average search time. Clusters arise because an empty slot preceded by $i$ full slots get filled next with probability $(i+1)/m$. Long runs of occupied slots tend to get longer, and the average search time increases.

\subsubsection*{Quadratic probing}

\textbf {Quadratic probing} uses a hash function of the form
\begin{equation*}
  h(k,i) = (h'(k) + c_1 i + c_2 i^2) \mod m,
\end{equation*}
where $h'$ is an auxiliary hash function, $c_1$ and $c_2$ are positive auxiliary constants and $i = 0,1,\dots,m-1$. This methods works much better than linear probing, but to make full use of the hash table, the values of $c_1, c_2$ and $m$ are constrained. Also, if two keys have the same initial probe position, then their probe sequences are the same. This property leads to a milder from of clustering, called \textbf {secondary clustering}.

\subsubsection*{Double hashing}

Double hashing offers one of the best methods available for open addressing because the permutations produced have many of the characteristics of randomly chosen permutations. \textbf {Double hashing} uses a hash function of the form
\begin{equation*}
  h(k,i) = (h_1(k) + ih_2(k)) \mod m,
\end{equation*}
where both $h_1$ and $h_2$ are auxiliary hash functions.

\subsubsection*{Analysis of open-address hashing}

\begin{theorem}
  Given an open-address hash table with load factor $\alpha =n/m < 1$, the expected number of probes in an unsuccessful search is at most $1/(1-\alpha)$, assuming uniform hashing.
\end{theorem}

\begin{corollary}
  Inserting an element into an open-address hash table with load factor $\alpha$ requires at most $1/(1-\alpha)$ probes on average, assuming uniform hashing.
\end{corollary}

\begin{theorem}
  Given an open-address hash table with load factor $\alpha < 1$, the expected number of probes in a successful search is at most
  \begin{equation*}
    \frac {1}{\alpha} \ln \frac {1}{1 - \alpha},
  \end{equation*}
  assuming uniform hashing and assuming that each key in the table is equally likely to be searched for.
\end{theorem}

\subsection{Perfect hashing}

Hashing can provide excellent worst-case performance when the set of keys is \textbf {static}: once the keys are stored in the table, the set of keys never changes. We call a hashing technique \textbf {perfect hashing} if $O(1)$ memory accesses are required to perform a search in the worst case. \\

To create a perfect hashing scheme, we use two levels of hashing, with universal hashing at each level.

\section{Binary Search Trees}

\subsection{What is a binary search tree}

The keys in a binary search tree are always stored in such a way as to satisfy the \textbf {binary-search-tree property}:
\begin{quote}
  Let $x$ be a node in a binary search tree. If $y$ is a node in the left subtree of $x$, then $y.key \le x.key$. If $y$ is a node in the right subtree of $x$, then $y.key \ge x.key$.
\end{quote}
\textbf {Inorder tree walk} prints the key of the root of a subtree between printing the values in its left subtree and printing those in its right subtree. Similarly, a \textbf {preorder tree walk} prints the root before the values in either subtree, and a \textbf {postorder tree walk} prints the root after the values in its subtrees. \\

INORDER-TREE-WALK($x$)
\begin{algorithmic}[1]
\If {$x \neq \text {NIL}$}
\State INORDER-TREE-WALK($x.\text{left}$)
\State print $x.\text{key}$
\State INORDER-TREE-WALK($x.\text{right}$)
\EndIf
\end{algorithmic}

\subsection{Querying a binary search tree}

\subsubsection*{Searching}

TREE-SEARCH($x, k$)
\begin{algorithmic}[1]
\If {$x == \text {NIL}$ or $k == x.\text{key}$}
	\State \textbf {return} $x$
\EndIf
\If {$k < x.\text{key}$}
	\State \textbf {return} TREE-SEARCH($x.\text{left}, k$)
\Else
	\State \textbf {return} TREE-SEARCH($x.\text{right}, k$)
\EndIf
\end{algorithmic}

ITERATIVE-TREE-SEARCH($x, k$)
\begin{algorithmic}[1]
\While {$x \neq \text {NIL}$ and $x \neq x.\text{key}$}
	\If {$k < x.\text{key}$}
		\State $x = x.\text{left}$
        \Else
		\State $x = x.\text{right}$
	\EndIf
\EndWhile
\State \textbf {return} $x$
\end{algorithmic}

TREE-MINIMUM($x$)
\begin{algorithmic}[1]
\While {$x.\text{left} \neq \text {NIL}$}
	\State $x = x.\text{left}$
\EndWhile
\State \textbf {return} $x$
\end{algorithmic}

TREE-MAXIMUM($x$)
\begin{algorithmic}[1]
\While {$x.\text{right} \neq \text {NIL}$}
	\State $x = x.\text{right}$
\EndWhile
\State \textbf {return} $x$
\end{algorithmic}

TREE-SUCCESSOR($x$)
\begin{algorithmic}[1]
\If {$x.\text{right} \neq \text {NIL}$}
	\State \textbf {return} TREE-MINIMUM($x.\text{right}$)
\EndIf
\State $y = x.p$
\While {$y \neq \text {NIL}$ and $x == y.\text{right}$}
	\State $x = y$
        \State $y = y.p$
\EndWhile
\State \textbf {return} $y$
\end{algorithmic}

\begin{theorem}
  We can implement the dynamic-set operations SEARCH, MINIMUM, MAXIMUM, SUCCESSOR, and PREDECESSOR so that each one runs in $O(h)$ time on a binary search tree of height $h$.
\end{theorem}

\subsection{Insertion and deletion}

\subsubsection*{Insertion}

TREE-INSERT($T,z$)
\begin{algorithmic}[1]
\State $y = \text {NIL}$
\State $x = T.\text{root}$
\While {$x \neq \text {NIL}$}
	\State $y = x$
        \If {$z.\text{key} < x.\text{key}$}
        	\State $x = x.\text{left}$
        \Else
        	\State $x = x.\text{right}$
        \EndIf
\EndWhile
\State $z.p = y$
\If {$y == \text {NIL}$}
	\State $T.\text{root} = z$
        \Comment tree $T$ was empty
\ElsIf {$z.\text{key} < y.\text{key}$}
	\State $y.\text{left} = z$
\Else
	\State $y.\text{right} = z$
\EndIf
\end{algorithmic}

\subsubsection{Deletion}

TRANSPLANT replaces one subtree ($u$) as a child of its parent ($u.p$) with another subtree ($v$). \\

TRANSPLANT($T,u,v$)
\begin{algorithmic}[1]
\If {$u.p == \text {NIL}$}
	\State $T.\text{root} = v$
\ElsIf {$u == u.p.\text{left}$}
	\State $u.p.\text{left} = v$
\Else
	\State $u.p.\text{right} = v$
\EndIf
\If {$v \neq \text {NIL}$}
	\State $v.p = u.p$
\EndIf
\end{algorithmic}

Deletion: Replace $z$ with its successor $y$. Note that when $z$ has both left and right subtrees, then its successor $y$ does not have a left subtree. \\

TREE-DELETE($T,z$)
\begin{algorithmic}[1]
\If {$z.\text{left} == \text {NIL}$}
	\State TRANSPLANT($T,z,z.\text{right}$)
\ElsIf {$z.\text{right} == \text {NIL}$}
	\State TRANSPLANT($T,z,z.\text{left}$)
\Else
	\State $y = \text {TREE-MINIMUM}(z.\text{right})$
        \If {$y.p \neq z$}
		\State TRANSPLANT($T,y,y.\text{right}$)
                \State $y.\text{right} = z.\text{right}$
                \State $y.\text{right}.p = y$
        \EndIf
        \State TRANSPLANT($T,z,y$)
        \State $y.\text{left} = z.\text{left}$
        \State $y.\text{left}.p = y$
\EndIf
\end{algorithmic}

\begin{theorem}
  We can implement the dynamic-set operations INSERT and DELETE so that each one runs in $O(h)$ time on a binary search tree of height $h$.
\end{theorem}

\subsection{Randomly built binary search tree}

A \textbf {randomly built binary search tree} on $n$ keys is one that arises from inserting the keys in random order into an initially empty tree, where each of the $n!$ permutations of the input keys is equally likely. 

\begin{theorem}
  The expected height of a randomly built binary search tree on $n$ distinct keys is $O(\lg n)$.
\end{theorem}

\section{Red-Black Tree}

Red-black trees are one of many search-tree schemes that are ``balanced'' in order to guarantee that basic dynamic-set operations take $O(\lg n)$ time in the worst case.

\subsection{Properties of red-black trees}

A \textbf {red-black tree} is a binary search tree with one extra bit of storage per node: its \textbf {color}, which can be either RED or BLACK. By constraining the node colors on any simple path from the root to a leaf, red-black trees ensure that no such path is more than twice as long as any other, so that the tree is approximately \textbf {balanced}. \\

A red-black tree is a binary tree that satisfies the following \textbf {red-black properties}:
\begin{enumerate}
  \item Every node is either red or black.
  \item The root is black.
  \item Every leaf (NIL) is black.
  \item Of a node is red, then both its children are black.
  \item For each node, all simple paths from the node to descendant leaves contain the same number of black nodes.
\end{enumerate}

We call the number of black nodes on any simple path from, but not including, a node $x$ down to a leaf the \textbf {black-height} of the node, denoted $bh(x)$. We define the black-height of a red-black tree to be the black-height of its root.

\begin{lemma}
  A red-black tree with $n$ internal nodes has height at most $2 \lg (n+1)$.
\end{lemma}

As an immediate consequence of this lemma, we can implement the dynamic-set operations SEARCH, MINIMUM, MAXIMUM, SUCCESSOR, and PREDECESSOR in $O(\lg n)$ time on red-black tree.

\subsection{Rotations}

We change the pointer structure through \textbf {rotation}, which is a local operation in a search tree that preserves the binary-search-tree property. \\

The pseudocode for LEFT-ROTATE assumes that $x.right \neq T.nil$ and that root's parent is $T.nil$. \\

LEFT-ROTATE($T,x$)
\begin{algorithmic}[1]
\State $y = x.\text{right}$
\Comment set $y$
\State $x.\text{right} = y.\text{left}$
\Comment turn $y$'s left subtree into $x$'s right subtree
\If {$y.\text{left} \neq T.\text{nil}$}
	\State $y.\text{left}.p = x$
\EndIf
\State $y.p = x.p$
\Comment link $x$'s parent to $y$
\If {$x.p == T.\text{nil}$}
	\State $T.\text{root} = y$
\ElsIf {$x == x.p.\text{left}$}
	\State $x.p.\text{left} = y$
\Else
	\State $x.p.\text{right} = y$
\EndIf
\State $y.\text{left} = x$
\Comment put $x$ on $y$'s left
\State $x.p = y$
\end{algorithmic}

Both LEFT-ROTATE and RIGHT-ROTATE run in $O(1)$ time. Only pointers are changed by a rotation; all other attributes in a node remain the same.

\subsection{Insertion}

RB-INSERT($T,z$)
\begin{algorithmic}[1]
\State $y = T.\text{nil}$
\State $x = T.\text{root}$
\While {$x \neq T.\text{nil}$}
	\State $y = x$
        \If {$z.key < x.\text{key}$}
        	\State $x = x.\text{left}$
        \Else
        	\State $x = x.\text{right}$
        \EndIf
\EndWhile
\State $z.p = y$
\If {$y == T.\text{nil}$}
	\State $T.\text{root} = z$
\ElsIf {$z.\text{key} < y.\text{key}$}
	\State $y.\text{left} = z$
\Else
	\State $y.\text{right} = z$
\EndIf
\State $z.\text{left} = T.\text{nil}$
\State $z.\text{right} = T.\text{nil}$
\State $z.\text{color} = RED$
\State RB-INSERT-FIXUP($T,z$)
\end{algorithmic}

RB-INSERT-FIXUP($T,z$)
\begin{algorithmic}[1]
\While {$z.p.\text{color} == RED$}
        \If {$z.p == z.p.p.\text{left}$}
        	\State $y = z.p.p.\text{right}$
                \If {$y.\text{color} == RED$}
                	\State $z.p.\text{color} = BLACK$
                        \State $y.\text{color} = BLACK$
                        \State $z.p.p.\text{color} = RED$
                        \State $z = z.p.p$
                \Else
                	\If {$z == z.p.\text{right}$}
                		\State $z = z.p$
                        	\State LEFT-ROTATE($T,z$)
                        \EndIf
                        \State $z.p.\text{color} = BLACK$
                        \State $z.p.p.\text{color} = RED$
                        \State RIGHT-ROTATE($T,z.p.p$)
                \EndIf
        \Else
        	\State (same as \textbf {then} clause with ``right'' and ``left'' exchanged)
        \EndIf
\EndWhile
\State $T.\text{root}.\text{color} = BLACK$
\end{algorithmic}

\section{Augmenting Data Structures}

\subsection{Dynamic order statistics}

Recall that the $i$th order statistic of a set of $n$ elements, where $i \in \{ 1,2,\dots,n \}$, is simply the element in the set with the $i$th smallest key. The \textbf{rank} of an element is its position in the linear order of the set. \\

An \textbf{order-statistic tree} T is simply a red-black tree with additional information sorted in each node. Besides the usual red-black tree attributes $x.key$, $x.color$, $x.p$, $x.left$ and $x.right$ in a node x, we have another attribute, $x.size$. This attribute contains the number of (internal) nodes in the subtree rooted at $x$ (including $x$ itself), that is, the size of the subtree. If we define the sentinel's size to be 0 -- that is, we set $T.\text{nil}.\text{size}$ to be 0 -- then we have the identity
\begin{equation*}
  x.\text{size} = x.\text{left}.\text{size} + x.\text{right}.\text{size} + 1
\end{equation*}

\subsubsection*{Retrieving an element with a given rank}

OS-SELECT($x,i$)
\begin{algorithmic}[1]
\State $r = x.left.size + 1$
\If {$i == r$}
	\State \textbf{return} $x$
\ElsIf {$i < r$}
	\State \textbf{return} OS-SELECT($x.left, i$)
\Else
	\State \textbf{return} OS-SELECT($x.right, i-r$)
\EndIf
\end{algorithmic}

The running time of OS-SELECT is $O(\lg n)$ for a dynamic set of $n$ elements.

\subsubsection*{Determining the rank of an element}

OS-RANK($T, x$)
\begin{algorithmic}[1]
\State $r = x.left.size + 1$
\State $y = x$
\While {$y \neq T.root$}
	\If {$y == y.p.right$}
        	\State $r = r + y.p.left.size + 1$
        \EndIf
        \State $y = y.p$
\EndWhile
\State \textbf{return} $r$
\end{algorithmic}

The running time of OS-RANK is at worst proportional to the height of the tree: $O(\lg n)$ on an $n$-node order-statistic tree.

\subsection{How to augment a data structure}

We can break the process of augmenting a data structure into four steps:
\begin{enumerate}
  \item Choose an underlying data structure.
  \item Determine additional information to maintain in the underlying data structure.
  \item Verify that we can maintain the additional information for the basic modifying operations on the underlying data structure.
  \item Develop new operations.
\end{enumerate}

\begin{theorem} [Augmenting a red-black tree]
  Let $f$ be an attribute that augments a red-black tree $T$ of $n$ nodes, and suppose that the value of $f$ for each node $x$ depends on only the information in nodes $x$, $x.\text{left}$, and $x.\text{right}$, possibly including $x.\text{left}.f$ and $x.\text{right}.f$. Then, we can maintain the values of $f$ in all nodes of $T$ during insertion and deletion without asymptotically affecting the $O(\lg n)$ performance of these operations.
\end{theorem}

\section{Dynamic Programming}

Dynamic programming, like the divide-and-conquer method, solves problems by combining the solutions to sub-problems. (``Programming'' in this context refers to a tabular method, not to writing computer code.)

We typically apply dynamic programming to optimization problems. When developing a dynamic-programming algorithm, we follow a sequence of four steps:
\begin{enumerate}
  \item Characterize the structure of an optimal solution.
  \item Recursively define the value of an optimal solution.
  \item Compute the value of an optimal solution, typically in a bottom-up fashion.
  \item Construct an optimal solution from computed information.
\end{enumerate}

\subsection{Rod cutting}

The \textbf{rod-cutting problem} is the following. Given a rod of length $n$ inches and a table of prices $p_i$ for $i = 1, 2, \dots, n$, determine the maximum revenue $r_n$ obtainable by cutting up the rod and selling the pieces. Note that if the price $p_n$ for a rod of length n is large enough, an optimal solution may require no cutting at all.

\subsubsection*{Recursive top-down implementation}

CUT-ROD($p, n$)
\begin{algorithmic}[1]
\If {$n == 0$}
	\State \textbf{return } $0$
\EndIf
\State $q = -\infty$
\For {$i = 1 \textbf { to } n$}
	\State $q = \max (q, p[i] + \text{CUT-ROD}(p, n-i))$
\EndFor
\State \textbf{return } $q$
\end{algorithmic}

For this algorithm, $T(0) = 1$. And the time complexity is

\begin{eqnarray*}
  T(n) &=& 1 + \sum_{j=0}^{n-1} {T(j)} \\
  \Rightarrow T(n) &=& 2^n
\end{eqnarray*}

\subsubsection*{Using dynamic programming for optimal rod cutting}

The dynamic-programming method works as follows. Having observed that naive recursive solution is inefficient because it solves the same sub-problems repeatedly, we arrange for each sub-problem to be solved only once, saving its solution. If we need to refer to this sub-problem's solution again later, we can just look it up, rather than recompute it. Dynamic programming thus uses additional memory to save computation time; it serves an example of a \textbf{time-memory trade-off}. The savings may be dramatic: an exponential-time solution may be transformed into a polynomial-time solution. A dynamic-programing approach runs in polynomial time when the number of distinct sub-problems involved is polynomial int the input size and we can solve each sub-problem in polynomial time. \\

There are usually two equivalent ways to implement a dynamic-programming approach: \textbf{top-down with memorization} and \textbf{bottom-up method}. \\

MEMORIZED-CUT-ROD($p, n$)
\begin{algorithmic}[1]
\State let $r[0 \dots n]$ be a new array
\For {$i = 0 \textbf{ to } n$}
	\State $r[i] = -\infty$
\EndFor
\State \textbf{return } MEMORIZED-CUT-ROD-AUX($p, n, r$)
\end{algorithmic}


MEMORIZED-CUT-ROD-AUX($p, n$)
\begin{algorithmic}[1]
\If $r[n] \ge 0$
	\State \textbf{return } $r[n]$
\EndIf
\If {$n == 0$}
	\State $q = 0$
\Else
	\State $q = -\infty$
        \For {$i = 1 \textbf{ to } n$}
        	\State $q = \max(q, p[i] + MEMORIZED-CUT-ROD-AUX(p, n-i, r))$
        \EndFor
\EndIf
\State $r[n] = q$
\State \textbf{return } $q$
\end{algorithmic}

The bottom-up version is even simpler: \\

BOTTOM-UP-CUT-ROD($p, n$)
\begin{algorithmic}[1]
\State let $r[0 \dots n]$ be a new array
\State $r[0] = 0$
\For {$j = 1 \textbf{ to } n$}
	\State $q = -\infty$
        \For {$i = 1 \textbf{ to } j$}
        	\State $q = \max(q, p[i] + r(j-i))$
        \EndFor
        \State $r[j] = q$
\EndFor
\State \textbf{return } $r[n]$
\end{algorithmic}

\subsubsection{Reconstructing a solution}

EXTENDED-BOTTOM-UP-CUT-ROD($p, n$)
\begin{algorithmic}[1]
\State let $r[0 \dots n]$ and $s[0 \dots n]$ be a new array
\State $r[0] = 0$
\For {$j = 1 \textbf{ to } n$}
	\State $q = -\infty$
        \For {$i = 1 \textbf{ to } j$}
        	\State $q = \max(q, p[i] + r(j-i))$
                \State $S[j] = i$
        \EndFor
        \State $r[j] = q$
\EndFor
\State \textbf{return } $r[n]$
\end{algorithmic}

The following procedure prints out the complete list of piece sizes in an optimal decomposition of a rod of length $n$: \\

PRINT-CUT-ROD-SOLUTION($p, n$)
\begin{algorithmic}[1]
\State $(r,s) = \text{EXTENDED-BOTTOM-UP-CUT-ROD($p, n$)}$
\While {$ n > 0$}
	\State print $S[n]$
        \State $n = n - S[n]$
\EndWhile
\end{algorithmic}

\section{Greedy Algorithms}

For many optimization problems, using dynamic programming to determine the best choices is overkill; simpler, more efficient algorithms will do. A \textbf{greedy algorithm} always makes the choice that looks best at the moment. That is, it makes a locally optimal choice in the hope that this choice will lead to a globally optimal solution.

\subsection{An activity-selection problem}

Suppose we have a set $S = \{ a_1, a_2, \dots, a_n \}$ of $n$ proposed \textbf{activities} that wish to use a resource, such as a lecture hall, which can serve only one activity at a time. Each activity $a_i$ has a \textbf{start time} $s_i$ and a \textbf{finish time} $f_i$, where $0 \le s_i < f_i < \infty$. If selected, activity $a_i$ takes place during the half0open time interval $[s_i, f_i)$. Activities $a_i$ and $a_j$ are \textbf{compatible} if the intervals $[s_i, f_i)$ and $[s_j, f_j)$. do not overlap. That is, $a_i$ and $a_j$ are compatible if $s_i \ge f_j$ or $s_j \ge f_i$. In the \textbf{activity-selection problem}, we wish to select a maximum-size subset of mutually compatible activities. We assume that the activities are sorted in monotonically increasing order of finish time:

\begin{equation*}
  f_1 \le f_2 \le f_3 \le \dots \le f_{n-1} \le f_n
\end{equation*}

\subsubsection*{The optimal sub-structure of the activity-selection problem}

Let us denote by $S_{ij}$ the set of activities that start after activity $a_i$ finishes and that finish before activity $a_j$ starts. Suppose that we wish to find a maximum set of mutually compatible activities in $S_{ij}$, and suppose further that such a maximum set is $A_{ij}$, which includes some activity $a_k$. By including $a_k$ in an optimal solution, we are left with two sub-problems: finding mutually compatible activities in the set $S_{ik}$ and fining mutually compatible activities in the set $S_{kj}$. Let $A_{ik} = A_{ij} \cap S_{ik}$ and $A_{kj} = A_{ij} \cap S_{kj}$, so that $A_{ik}$ contains the activities in $A_{ij}$ finish before $a_k$ starts and $A_{kj}$ contains activities in $A_{ij}$ that start after $a_k$ finishes. Thus we have $A_{ij} = A_{ik} \cup \{ a_k \} \cup A_{kj}$, and so the maximum-size set $A_{ij}$ of mutually compatible activities in $S_{ij}$ consists of $|A_{ij}| = |A_{ik}| + |A_{kj}| + 1$activities. \\

The usual cut-and-paste argument shows that the optimal solution $A_{ij}$ must also include optimal solutions to the two sub-problems for $S_{ik}$ and $S_{kj}$. \\

This way of characterizing optimal substructure suggests that we might solve the activity-selection problem by dynamic programming. If we denote the size of an optimal solution for the set $S_{ij}$ by $c[i,j]$, then we would have the recurrence

\begin{equation*}
  c[i,j] = c[i,k] + c[k,j] + 1
\end{equation*}

Of course, if we did not know that an optimal solution for the set $S_{ij}$ includes activity $a_k$, we would have to examine all activities in $S_{ij}$ to find which one to choose, so that

\begin{equation*}
  c[i,j] =
  \begin{cases}
    0 & \text{if $S_{ij} = \emptyset$,} \\
    \max_{a_k \in S_{i,j}} \{ c[i,k] + c[k,j] + 1\} & \text{if $S_{ij} \neq \emptyset$.}
  \end{cases}
\end{equation*}

\subsubsection*{Making the greedy choice}

For the activity-selection problem, we need consider only one choice: the greedy choice. \\

What do we mean by the greedy choice for the activity-selection problem? Intuition suggests that we should choose an activity that leaves the resource available for as many other activities as possible. Now, of activities we end up choosing, one of them must be the first one to finish. Our intuition tells us, therefore, to choose the activity in S with the earliest finish time, since that would leave the resource available for as many of the activities that follow it as possible. \\

\begin{theorem}
  Consider any nonempty sub-problem $S_k$, and let $a_m$ be an activity in $S_k$ with the earliest finish time. Then $a_m$ is included in some maximum-size subset of mutually compatible activities of $S_k$.
\end{theorem}

\subsubsection*{A recursive greedy algorithm}

The procedure $RECURSIVE-ACTIVITY-SELECTOR$ takes the start and finish time of the activities, represented as arrays $s$ and $f$, the index $k$ that defines the sub-problem $S_k$ it is to solve, and the size $n$ of the original problem. It returns a maximum-size set of mutually compatible activities in $S_k$. We assume that the $n$ input activities are already ordered by monotonically increasing finish time, according to the previous equation. If not we can sort them into this order in $O(n \log n)$ time, breaking ties arbitrarily. In order to start, we add the fictitious activity $a_0$ with $f_0 = 0$, so that sub-problem $S_0$ is the entire set of activities $S$. The initial call, which solves the entire problem, is $RECURSIVE-ACTIVITY-SELECTOR(s, f, 0, n)$

RECURSIVE-ACTIVITY-SELECTOR($s, f, k, n$)
\begin{algorithmic}[1]
\State $m = k + 1$
\While {$ m \le n \text{ and } s[m] < f[k]$}
	\State $m = m + 1$
\EndWhile
\If {$m \le n$}
	\State \textbf{return } $\{ a_m\} \cup \text{RECURSIVE-ACTIVITY-SELECTOR}(s, f, m, n)$
\Else
	\State \textbf{return } $\emptyset$
\EndIf
\end{algorithmic}

\subsubsection*{An iterative greedy algorithm}

GREEDY-ACTIVITY-SELECTOR($s, f$)
\begin{algorithmic}[1]
\State $n = s. \text{length}$
\State $A = {a_1}$
\State $k = 1$
\For {$ m = 2 \textbf{ to } n$}
	\If {$s[m] \ge f[k]$}
		\State $A = A \cup \{ a_m \}$
                \State $k = m$
	\EndIf
\EndFor
\State \textbf{return } $A$
\end{algorithmic}

\subsection{Elements of the greedy strategy}

\begin{enumerate}
  \item Determine the optimal substructure of the problem.
  \item Develop a recursive solution.
  \item Show that if we make the greedy choice, then only one sub-problem remains.
  \item Prove that it is always safe to make the greedy choice.
  \item Develop a recursive algorithm that implements that greedy strategy.
  \item Convert the recursive algorithm to an iterative algorithm.
\end{enumerate}

More generally, we design greedy algorithms according to the following sequence of steps:

\begin{enumerate}
  \item Cast the optimization problem as one in which we make a choice and are left with one sub-problem to solve.
  \item Prove that there is always an optimal solution to the original problem that makes the greedy choice, so that greedy choice is always safe.
  \item Demonstrate optimal sub-structure by showing that, having made the greedy choice, what remains is a sub-problem wit the property that if we combine an optimal solution to the sub-problem with the greedy choice we have made, we arrive at an optimal solution to the original problem.
\end{enumerate}

\subsubsection*{Greedy-choice property}

The first key ingredient is the \textbf{greedy-choice property}: we can assemble a globally optimal solution by making locally optimal (greedy) choices. \\

Here is where greedy algorithms differ from dynamic programming. In dynamic programming, we make a choice at each step, but the choice usually depends on the solutions to sub-problems. Consequently, we typically solve dynamic-programming problems in a bottom-up manner, progressing from smaller sub-problems to larger sub-problems. In a greedy algorithm, we make whatever choice seems best at the moment and then solve the sub-problem that remains. The choice made by a greedy algorithm may depend on choices so far, but it cannot depend on any future choices or on the solutions to sub-problems. Thus, unlike dynamic programming, which solves the sub-problems before making the first choice, a greedy algorithm makes its first choice before solving any sub-problems.

\subsubsection*{Optimal substructure}

A problem exhibits \textbf{optimal substructure} if an optimal solution to the problem contains within it optimal solutions to sub-problems. This property is a key ingredient of assessing the applicability of dynamic programming as well as greedy algorithms.

\section{Amortized Analysis}

In an amortized analysis, we average the time required to perform a sequence of data-structure operations over all the operations performed. With amortized analysis, we can show that the average cost of an operation is small, if we average over a sequence of operations, even though a single operation within the sequence might be expensive. Amortized analysis differs from average-case analysis in that probability is not involved; an amortized analysis guarantees the average performance of each operation in the worst case.

\subsection{Aggregate analysis}

In \textbf{aggregate analysis}, we show that for all $n$, a sequence of $n$ operations takes worst-case time $T(n)$ in total. In the worst case, the average cost, or \textbf{amortized cost}, per operation is therefore $T(n)/n$.

\subsection{The accounting method}

In the \textbf{accounting method} of amortized analysis, we assign differing charges to different operations, with some operations charged more or less than they actually cost. We call the amount we charge an operation its \textbf{amortized cost}. When an operation's amortized cost exceeds its actual cost, we assign the difference to specific objects in the data structure as \textbf{credits}. Credit can help pay for later operations whose amortized cost is less than their actual cost. Thus, we can view the amortized cost of an operation as being split between its actual cost and credit that is either deposited or used up. Different operations may have different amortized costs. This method differs from aggregate analysis, in which all operations have the same amortized cost. \\

IF we denote the actual cost of the $i$th operation by $c_i$ and the amortized cost of the $i$th operation by $\hat{c}_i$, we require

\begin{equation*}
  \sum_{i=1}^{n} \hat{c}_i \ge \sum_{i=1}^n c_i
\end{equation*}

for all sequences of $n$ operations. The total credit stored in the data structure is the difference between the total amortized cost and the total actual cost, or $\sum_{i=1}^{n} \hat{c}_i - \sum_{i=1}^n c_i$. By the previous inequality, the total credit associated with the data structure must be non-negative at all times. 

\subsection{The potential method}

Instead of representing prepaid work as credit stored with specific objects in the data structure, the \textbf{potential method} of amortized analysis represents the prepaid work as ``potential energy'', or just ``potential,'' which can be released to pay for future operations. We associate the potential with the data structure as a whole rather than with specific objects with the data structure. \\

The potential method works as follows. We will perform $n$ operations, starting with an initial data structure $D_0$. For each $i = 1,2,\dots$, we let $c_i$ be the actual cost of the $i$th operation and $D_i$ be the data structure that results after applying the $i$th operation to the data structure $D_{i-1}$. A \textbf{potential function} $\Phi$ maps each data structure $D_i$ to a real number $\Phi(D_i)$, which is the \textbf{potential} associated with data structure $D_i$. The \textbf{amortized cost} $\hat{c}_i$ of the $i$th operation with respect to potential function $\Phi$ is defined by

\begin{equation*}
  \hat{c}_i = c_i + \Phi(D_i) - \Phi(D_{i-1}).
\end{equation*}

The amortized cost of each operation is therefore its actual cost plus the change in potential due to the operation. By the previous equation, the total amortized cost of the $n$ operation is

\begin{eqnarray*}
  \sum_{i=1}^n \hat{c}_i
  &=& \sum_{i=1}^n (c_i + \Phi(D_i) - \Phi(D_{i-1})) \\
  &=& \sum_{i=1}^n c_i + \Phi(D_i) - \Phi(D_0)
\end{eqnarray*}

If we can define a potential function $\Phi$ so that $\Phi(D_n) \ge \Phi(D_0)$, then the total amortized cost $\sum_{i=1}^n \hat{c}_i$ gives an upper bound on the total actual cost $\sum_{i=1}^n c_i$. In practice, we do not always know how many operations might be performed. Therefore, if we require that $\Phi(D_i) \ge \Phi(D_0)$ for all $i$, then we guarantee, as in the accounting method, that we pay in advance. We usually just define $\Phi(D_0)$ to be 0 and then show that $\Phi(D_i) \ge 0$ for all $i$.

\section{B-Trees}

B-trees are balanced search trees designed to work well on disks or other direct-access secondary storage devices. B-trees are similar to red-black trees, but they are better at minimizing disk I/O operations. Many database systems use B-trees, or variants of B-trees, to store information. \\

B-tree differ from red-black trees in that B-tree nodes may have many children, from a few to thousands. That is, the ``branching factor'' of a B-tree can be quite large, although it usually depends on characteristics of the disk unit used. B-trees are similar to red-black trees in that every n-node B-tree has height $O(\log n)$. The exact height of a B-tree can be considerably less than that of a red-black tree, however, because its branching factor, and hence the base of the logarithm that expresses its height, can be much larger. Therefore, we can also use B-trees to implement many dynamic-set operations in time $O(\log n)$.

\subsection{Definition of B-trees}

A common variant on a B-tree, known as a \textbf{$B^+$-tree}, stores all the satellite information in the leaves and stores only keys and child pointers in the internal nodes, thus maximizing the branching factor of the internal nodes. \\

A \textbf{B-tree} $T$ is a rooted tree (whose root is T.root) having the following properties:
\begin{enumerate}
  \item Every node $x$ has the following attributes:
    \begin{enumerate}
    	\item $x.n$, the number of keys currently stored in node $x$,
        \item the $x.n$ keys themselves, $x.\text{key}_1, x.\text{key}_2, \dots, x.\text{key}_{x.n}$, stored in non-decreasing order, so that $x.\text{key}_1 \le x.\text{key}_2 \le \dots \le x.\text{key}_{x.n}$,
        \item $x.\text{leaf}$, a boolean value that is TRUE if $x$ is a leaf and FALSE if $x$ is an internal node.
    \end{enumerate}
  \item Each internal node $x$ also contains $x.n+1$ pointers $x.c_1, x.c_2, \dots, x.c_{x.n+1}$ to its children. Leaf nodes have no children, and so their $c_i$ attributes are undefined.
  \item The keys $x.\text{key}_i$ separate the ranges of keys stored in each subtree: if $k_i$ is any key stored in the subtree with root $x.c_i$, then 
    \begin{equation}
      k_1 \le x.key_1 \le k_2 \le x.key_2 \le \dots \le x.key_{x.n} \le k_{x.n+1}
    \end{equation}
  \item All leaves have the same depth, which is the tree's height $h$.
  \item Nodes have lower and upper bounds on the number of keys they can contain. We express these bounds in terms of a fixed integer $t \ge 2$ called the \textbf{minimum degree} of the B-tree:
    \begin{enumerate}
      \item Every node other than the root must have at least $t-1$ keys. Every internal node other than the root thus has at least $t$ children. If the tree is non-empty, the root must have at least one key.
      \item Ever node may contain at most $2t-1$ keys. Therefore, an internal node may have at most $2t$ children. We say that a node is \textbf{full} if it contains exactly $2t-1$ keys.
    \end{enumerate}
\end{enumerate}

The simplest B-tree occurs when $t=2$. Every internal node then has either 2, 3, or 4 children, and we have a \textbf{2-3-4 tree}. In practice, however, much larger values of $t$ yield of B-trees with smaller height.

\section{Data Structures for Disjoint Sets}

\subsection{Disjoint-set operations}

A \textbf{disjoint-set data structure} maintains a collection $\delta = \{ S_1, S-2, \dots, S_k \}$ of disjoint dynamic sets. We identify each set by a \textbf{representative}, which is some member of the set. In some applications, it doesn't matter which member is used as the representative; we care only that if we ask for the representative of a dynamic set twice without modifying the set between the requests, we get the same answer both times. Other applications may require a pre-specified rule for choosing the representative, such as choosing the smallest member in the set (assuming that the elements can be ordered). \\

As in the order dynamic-set implementations we have studied, we represent each element of a set by an object. Letting $x$ denote an object, we wish to support the following operations: \\

$MAKE-SET(x)$ creates a new set whose only member (and thus representative is $x$). Since the sets are disjoint, we require that $x$ not already be in some other set. \\

$UNION(x,y)$ unites the dynamic sets that contain $x$ and $y$, say $S_x$ and $S_y$, into a new set that is the union of these two sets. We assume that the two sets are disjoint prior to the operation. The representative of the resulting set is any member joint prior to the operation. The representative of the resulting set is any member of $S_x \cup S_y$, although many implementations of $UNION$ specifically choose the representative of either $S_x$ or $S_y$ as the new representative. Since we require the sets in the collection to be the new representative. Since we require the sets in the collection to be disjoint, conceptually we destroy sets $S_x$ and $S_y$, removing them from collection $\delta$. In practice, we often absorb the elements of one of the sets into the other set. \\

$FIND-SET(x)$ returns a pointer to the representative of the (unique) set containing $x$. \\

Throughout this chapter, we shall analyze the running times of disjoint-set data structures in terms of two parameters: $n$, the number of $MAKE-SET$ operations, and $m$, the total number of $MAKE-SET$, $UNION$, and $FIND-SET$ operations.

\subsection{Linked-list representation of disjoint sets}

A simple way to implement a disjoint-set data structure: each set is represented by its own linked list. The object for each set has attributes $head$, pointing to the first object in the list, and $tail$, pointing to the last object. Each object in the list contains a set member, a pointer to the next object in the list, and a pointer back to the set object. Within each linked list, the objects may appear in any order. The representative is the set member in the first object in the list. \\

With this linked-list representation, both $MAKE-SET$ and $FIND-SET$ are easy, requiring $O(1)$ time. \\

\subsubsection*{A simple implementation of union}

The simplest implementation of the $UNION$ operation using the linked-list set representation takes significantly more time than $MAKE-SET$ or $FIND-SET$. We perform $UNION(x,y)$ by appending $y$'s list onto the end of $x$'s list. Unfortunately, we must update the pointer to the set object for each object originally on $y$'s list, which takes time linear in the length of $y$'s list. \\

In fact, we can easily construct a sequence of $m$ operations on $n$ objects that requires $\Theta(n^2)$ time. That is, the amortized time of an operation is $\Theta(n)$.

\subsubsection*{A weighted-union heuristic}

Suppose instead that each list also includes the length of the list (which we can easily maintain) and that we always append the shorter list onto the longer, breaking ties arbitrarily. With this simple \textbf{weighted-union heuristic}, a single $UNION$ operation can still take $\Omega(n)$ time if both sets have $\Omega(n)$ members. As the following theorem shows, however, a sequence of $m$ $MAKE-SET$, $UNION$, and $FIND-SET$ operations, $n$ of which are $MAKE-SET$ operations, takes $O(m + n \log n)$ time.

\begin{theorem}
  Using the linked-list representation of disjoint sets and the weighted-union heuristic, a sequence of $m$ $MAKE-SET$, $UNION$, and $FIND-SET$ operations, $n$ of which are $MAKE-SET$ operations, takes $O(m + n \log n)$ time.
\end{theorem}

\subsection{Disjoint-set forests}

In a \textbf{disjoint-set forests}, each member points only to its parent. The root of each tree contains the representative and is its own parent. \\

We perform the three disjoint-set operations as follows. A $MAKE-SET$ operation simply creates a tree with just one node. We perform a $FIND-SET$ operation by following parent pointers until we find the root of the tree. The nodes visited on this simple path toward the root constitute the \textbf{find path}. A $UNION$ operation, cause the root of one tree to point to the root of the other.

\subsubsection*{Heuristics to improve the running time}

The first heuristic is \textbf{union by rank}. We want to make the root of the tree with fewer nodes point to the root of the tree with more nodes. Rather than explicitly keeping track of the size of the subtree rooted at each node, we shall use an approach that ease the analysis. For each node, we maintain a \textbf{rank}, which is an upper bound on the height of the node. In union by rank, we make the root with smaller rank point to the root with smaller rank point to the root with larger rank during a $UNION$ operation. \\

The second heuristic, \textbf{path compression}, is also quite simple and highly effective. We use it during $FIND-SET$ operations to make each node on the find path point directly to the root. Path compression does not change any ranks.

\subsubsection*{Pseudocode for disjoint-set forests}

MAKE-SET($x$)
\begin{algorithmic} [1]
\State $x.p = x$
\State $x.\text{rank} = 0$
\end{algorithmic}

UNION($x, y$)
\begin{algorithmic} [1]
\State LINK(FIND-SET($x$), FIND-SET($y$))
\end{algorithmic}

LINK($x, y$)
\begin{algorithmic} [1]
\If {$x.rank > y.rank$}
	\State $y.p = x$
\Else
	\State $x.p = y$
	\If {$x.rank == y.rank$}
		\State $y.rank = y.rank + 1$
        \EndIf
\EndIf
\end{algorithmic}

FIND-SET($x$)
\begin{algorithmic} [1]
\If {$x \neq x.p$}
	\State $x.p = \text{FIND-SET}(x.p)$
\EndIf
\State \textbf{return } $x.p$
\end{algorithmic}

\subsubsection*{Effect of the heuristics on the running time}

When we use both union by rank and path compression, the worst-case running time is $O(m \alpha(n))$, where $\alpha(n)$ is a very slowly growing function. For $n < 10^{80}$, $alpha(n) \le 4$. Thus, we can view the running time as linear in $m$ in all practical situations. Strictly speaking, however, it is super linear.

\section{Elementary Graph Algorithms}

\subsection{Representations of graphs}

We can choose between two standard ways to represent a graph $G = (V,E)$: as a collection of adjacency lists or as an adjacency matrix. Either way applies to both directed and undirected graphs. Because the adjacency-list representation provides a compact way to represent \textbf{sparse} graphs--those for which $|E|$ is much less than $|V|^2$--it is usually the method of choice. Most of the graph algorithms presented in this book assume that an input graph is represented in adjacency-list form. We may prefer an adjacency-matrix representation, however, when the graph is \textbf{dense}--$|E|$ is close to $|V|^2$--or when we need to be able to tell quickly if there is an edge connecting two given vertices. \\

The \textbf{adjacency-list representation} of a graph $G = (V,E)$ consists of an array $Adj$ of $|V|$ lists, one for each vertex in $V$. For each $u \in V$, the adjacency list $Adj[u]$ contains all the vertices $v$ such that there is an edge $(u,v) \in E$. That is $Adj[u]$ consists of all the vertices adjacent to $u$ in $G$. (Alternatively, it may contain pointers to these vertices.) Since the adjacency lists represent the edges of a graph, in pseudocode we treat the array $Adj$ as an attribute of the graph, just as we treat the edge set $E$. In pseudocode, therefore, we will see notation such as $G.Adj[u]$. For both directed and undirected graphs, the adjacency-list representation has the desirable property that the amount of memory it requires is $\Theta (V+E)$. \\

We can readily adapt adjacency list to represent \textbf{weighted graphs}, that is, graphs for which each edge has an associated \textbf{weight}, typically given by a \textbf{weight function} $\omega : E \rightarrow \mathbb{
R}$. We simply store the weight $\omega(u,v)$ of the edge $(u,v) \in E$ with vertex $v$ in $u$'s adjacency list. The adjacency-list representation is quite robust in that we can modify it to support many other graph variants. \\

For the \textbf{adjacency-matrix representation} of a graph $G = (V,E)$, we assume that the vertices are numbered $1,2,\dots,|V|$ in some arbitrary manner. Then the adjacency-matrix representation of a graph $G$ consists of a $|V| \times |V|$ matrix $A = (a_{ij})$ such that

\begin{equation*}
  a_{ij} =
  \begin{cases}
    1 & \text{if $(i,j) \in E$,} \\
    0 & \text{otherwise.}
  \end{cases}
\end{equation*}

Like the adjacency-list representation of a graph, an adjacency matrix can represent a weighted graph. We can simply store the weight $\omega(u,v)$ of the edge $(u,v) \in E$ as the entry in row $u$ and column $v$ of the adjacency matrix. If an edge does not exist, we can store a $NIL$ value as its corresponding matrix entry, though for many problems it is convenient to use a value such as $0$ or $\infty$. \\

Although the adjacency-list representation is asymptotically at least as space-efficient as the adjacency-matrix representation, adjacency matrices are simpler, and so we may prefer them when the graphs are reasonably small. Moreover, adjacency matrices carry a further advantage for unweighted graphs: they require only one bit per entry.

\subsection{Breadth-first search}

Given a graph $G = (V,E)$ and a distinguished \textbf{source} vertex $s$, breadth-first search systematically explores the edges of $G$ to ``discover'' every vertex that is reachable from $s$. It computes the distance (smallest number of edges) from $s$ to each reachable vertex. It also produce a ``breadth-first tree'' with root $s$ that to each reachable vertices. For any vertex $v$ reachable from $s$, the simple path in the breadth-first tree from $s$ to $v$ corresponds to a ``shortest path'' from $s$ to $v$ in $G$, that is, a path containing the smallest number of edges. The algorithm works on both directed and undirected graphs. \\

The breadth-first-search procedure BFS below assumes that the input graph $G = (V,E)$ is represented using adjacency lists. \\

BFS($G, s$)
\begin{algorithmic}[1]
\For {each vertex $u \in G.V - \{ s \}$}
	\State $u.\text{color} = \text{WHITE}$
	\State $u.d = \infty$
	\State $u.\pi = \text{NIL}$
\EndFor
\State $s.\text{color} = \text{WHITE}$
\State $s.d = 0$
\State $s.\pi = \text{NIL}$
\State $Q = \emptyset$
\State ENQUEUE($Q,s$)
\While {$Q \neq \emptyset$}
	\State $u = \text{DEQUEUE}(Q)$
        \For {each $v \in G.Adj[u]$}
        	\If {$v.\text{color} == \text{WHITE}$}
                	\State $v.\text{color} == \text{GREY}$
                        \State $v.d = u.d + 1$
                        \State $v.\pi = u$
                        \State ENQUEUE($Q, v$)
                \EndIf
        \EndFor
        \State $u.\text{color} == \text{BLACK}$
\EndWhile
\end{algorithmic}

\subsubsection*{Analysis}

Because the procedure scans the adjacency list of each vertex only when the vertex is dequeued, it scans each adjacency list at most once. Since the sum of the lengths of all the adjacency lists is $\Theta(E)$, the total time spent in scanning adjacency lists is $O(E)$. The overhead for initialization is $O(V)$, and thus the total running time of the BFS procedure is $O(V+E)$.

\subsubsection*{Shortest paths}

Define the \textbf{shortest-path distance} $\delta(s,v)$ from $s$ to $v$ as the minimum number of edges in any path from vertex $s$ to vertex $v$; if there is no path from $s$ to $v$, then $\delta (s,v) = \infty$. We call a path of length $\delta(s,v)$ from $s$ to $v$ a \textbf{shortest path} from $s$ to $v$.

\begin{lemma}
  Let $G = (V,E)$ be a directed or undirected graph, and let $s \in V$ be an arbitrary vertex. Then, for any edge $(u,v) \in E$,
  \begin{equation*}
    \delta(s,v) \le \delta(s,u) + 1
  \end{equation*}
\end{lemma}

\begin{lemma}
  Let $G = (V,E)$ be a directed or undirected graph, and suppose that BFS is run on $G$ from a given source vertex $s \in V$. Then upon termination, for each vertex $v \in V$, the value $v.d$ computed by BFS satisfies $v.d \ge \delta(s,v)$.
\end{lemma}

\begin{lemma}
  Suppose that during the execution of BFS on a graph $G = (V,E)$, the queue $Q$ contains the vertices $(v_1, v_2, \dots, v_r)$, where $v_1$ is the head of $Q$ and $v_r$ is the tail. Then, $v_r.d \le v_1.d + 1$ and $v_i.d \le v_{i+1}.d$ for $i = 1, 2, \dots, r-1$.
\end{lemma}

\begin{corollary}
  Suppose that vertices $v_i$ and $v_j$ are enqueued during the execution of BFS, and that $v_i$ is enqueued before $v_j$, Then $v_i.d \le v_j.d$ at the time that $v_j$ is enqueued.
\end{corollary}

\begin{theorem}
  Let $G = (V,E)$ be a directed or undirected graph, and suppose that BFS is run on $G$ from a given source vertex $s \in V$. Then, during its execution, BFS discovers every vertex $v \in V$ that is reachable from the source $s$, and upon termination, $v.d = \delta (s,v)$ for all $v \in V$. Moreover, for any vertex $v \neq s$ that is reachable from $s$, one of the shortest paths from $s$ to $v$ is a shortest path from $s$ to $v.\pi$ followed by the edge $()v.\pi, v$.
\end{theorem}

\subsubsection*{Breadth-first trees}

For a graph $G = (V,E)$ with source $s$, we define the \textbf{predecessor subgraph} of $G$ as $G_{\pi} = \{ V_{\pi}, E_{\pi} \}$, where

\begin{equation*}
  V_{\pi} = \{ v \in V : v.\pi \neq \text{NIL} \} \cup \{ s \}
\end{equation*}

and

\begin{equation*}
  E_{\pi} = \{ (v.\pi, v) : v \in V_{\pi} - \{ s \} \} 
\end{equation*}

The predecessor subgraph $G_{\pi}$ is a \textbf{breadth-first tree} if $V_{\pi}$ consists of the vertices reachable from $s$ and, for all $v \in V_{\pi}$, the subgraph $G_{\pi}$ contains a unique simple path from $s$ to $v$ that is also a shortest path from $s$ to $v$ in $G$. We call the edges in $E_{\pi}$ \text{tree edges}.

\begin{lemma}
  When applied to a directed or undirected graph $G = (V,E)$, procedure BFS constructs $\pi$ so that the predecessor subgraph $G_{\pi} = (V_{\pi}, E_{\pi})$ is a breadth-first tree.
\end{lemma}

\subsection{Depth-first search}

Unlike breadth-first search, whose predecessor subgraph forms a tree, the predecessor subgraph produced by a depth-first search may be composed of several trees, because the search may repeat from multiple sources. Therefore, We define the \textbf{predecessor subgraph} of a depth-first search slightly differently from that of a breadth-first search: we let $G_{\pi} = (V, E_{\pi})$, where

\begin{equation*}
  E_{\pi} = \{ (v.\pi, v) : v \in V \text{ and } v.\pi \neq \text{NIL} \}
\end{equation*}

The predecessor subgraph of a depth-first search forms a \textbf{depth-first forest} comprising several \textbf{depth-first trees}. The edges in $E_{\pi}$ are \textbf{tree edges}. \\

The following pseudocode is the basic depth-first-search algorithm. The input graph $G$ may be undirected or directed. The variable $time$ is a global variable that we use for time stamping. \\

DFS($G$)
\begin{algorithmic}[1]
\For {each vertex $u \in G.V$}
	\State $u.\text{color} = \text{WHITE}$
	\State $u.\pi = \text{NIL}$
\EndFor
\State $\text{time} = 0$
\For {each vertex $u \in G.V$}
	\If {$u.\text{color} == \text{WHITE}$}
		DFS-VISIT($G,u$)
	\EndIf
\EndFor
\end{algorithmic}

DFS-VISIT($G, u$)
\begin{algorithmic}[1]
\State $time = time + 1$
\State $u.d = time$
\State $u.\text{color} = \text{GRAY}$
\For {each vertex $v \in G.Adj[u]$}
	\If {$v.\text{color} == \text{WHITE}$}
		\State $v.\pi == u$
		\State DFS-VISIT($G,v$)
	\EndIf
\EndFor
\State $u.\text{color} = \text{BLACK}$
\State $time = time + 1$
\State $u.f = time$
\end{algorithmic}

Since

\begin{equation*}
  \sum_{v \in V} |Adj[v]| = \Theta(E)
\end{equation*}

the running time of DFS is $\Theta(V+E)$. \\

\subsubsection*{Properties of depth-first search}

Perhaps the most basic property of depth-first search is that the predecessor subgraph $G_{\pi}$ does indeed form a forest of trees. Additionally, vertex $v$ is a descendant of vertex $u$ in the depth-first forest if and only if $v$ is discovered during the time in which $u$ is gray. \\

Another important property of depth-first search is that discovery and finishing times have \textbf{parenthesis structure}. If we represent the discovery of vertex $u$ with a left parenthesis ``$(u$'' and its finishing by a right parenthesis ``$u)$'', then the history of discoveries and finishings makes a well-formed expression in the sense that the parentheses are properly nested.

\begin{theorem}
  In any depth-first search of a (directed or undirected) graph $G=(V,E)$m for any two vertices $u$ and $v$, exactly one of the following three condition holds:
  \begin{itemize}
  \item the intervals $[u.d, u.f]$ and $[v.d, v.f]$ are entirely disjoint, and neither $u$ nor $v$ is a descendant of the other in the depth-first forest,
  \item the interval $[u.d, u.f]$ is contained entirely within the interval $[v.d, v.f]$ and $u$ is the descendant of $v$ in a depth-first tree,
  \item the interval $[v.d, v.f]$ is contained entirely within the interval $[u.d, u.f]$, and $v$ is a descendant of $u$ in a depth-first tree.
  \end{itemize}
\end{theorem}

\begin{corollary}
  Vertex $v$ is a proper descendant of vertex $u$ in the depth-first forest for a (directed or undirected) graph $G$ if and only if $u.d < v.d < v.f < u.f$
\end{corollary}

\begin{theorem} [White-path theorem]
  In a depth-first of a (directed or undirected) graph $G = (V,E)$, vertex $v$ is a descendant of vertex $u$ if and only if at the time $u.d$ that the search discovers $u$, there is a path from $u$ to $v$ consisting entirely of white vertices.
\end{theorem}

\subsubsection*{Classification of edges}

We can define four edge types in terms of the depth-first forest $G_{\pi}$ produced by a depth-first search on $G$:

\begin{enumerate}
  \item \textbf{Tree edges} are edges in the depth-first forest $G_{\pi}$, Edge $(u,v)$ is a tree edge if $v$ was first discovered by exploring edge $(u,v)$
  \item \textbf{Back edges} are those edges $(u,v)$ connecting a vertex $u$ to an ancestor $v$ in a depth-first tree. We consider self-loops, which may occur in directed graphs, to be back edges.
  \item \textbf{Forward edges} are those non-tree edges $(u,v)$ connecting a vertex $u$ to a descendant $v$ in a depth-first tree.
  \item \textbf{Cross edges} all other edges. They can go between vertices in the same depth-first tree, as long as one vertex is not an ancestor of the other, or they can go between vertices in different depth-first trees.
\end{enumerate}

The DFS algorithm has enough information to classify some edges as it encounters them. The key idea is that when we first explore an edge $(u,v)$, the color of vertex $v$ tells us something about the edge:

\begin{enumerate}
  \item WHITE indicates a tree edge.
  \item GRAY indicates a back edge, and
  \item BLACK indicates a forward or cross edges.
\end{enumerate}

An undirected graph may entail some ambiguity in how we classify edges, since $(u,v)$ and $(v,u)$ are really the same edge. In such a case, we classify the edge as the first type in the classification list that applies. Equivalently, we can classify the edge according to whichever of $(u,v)$ or $(v,u)$ the search encounters first.

\begin{theorem}
  In a depth-first search of an undirected graph $G$, every edge of $G$ is neither a tree edge or a back edge.
\end{theorem}

\subsection{Topological sort}

This section shows how we can use depth-first search to perform a topological sort of a directed acyclic graph, or a ``dag'' as it is sometimes called. A \textbf{topological sort} of a dag $G = (V,E)$ is a linear ordering of all its vertices such that if $G$ contains an edge $(u,v)$, then $u$ appears before $v$ in the ordering. (If the graph contains a cycle, then no linear ordering is possible.) \\

The following simple algorithm topologically sorts a dag: \\

TOPOLOGICAL-SORT($G$)
\begin{algorithmic} [1]
\State call DFS($G$) to compute finishing times $v.f$ for each vertex $v$
\State as each vertex is finished, insert it onto the front of a linked list
\State \textbf{return } the linked list of vertices 
\end{algorithmic}

The time complexity of a topological sort is $\Theta(V+E)$. \\

\begin{lemma}
  A directed graph $G$ is acyclic if and only if a depth-first search of $G$ yields no back edges.
\end{lemma}

\begin{theorem}
  TOPOLOGICAL-SORT produces a topological sort of the directed acyclic graph provided as its input.
\end{theorem}

\subsection{Strongly connected component}

We now consider a classic application of depth-first search: decomposing a directed graph into its strongly connected components. This section shows how to do so suing two depth-first searches. Many algorithms that work with directed graphs begin with such a decomposition. After decomposing the graph into strongly connected components, such algorithms run separately on each one and then combine the solutions according to the structure of connections among components. \\

A strongly connected component of a directed graph $G=(V,E)$ is a maximal set of vertices $C \subseteq V$ such that for every pair of vertices $u$ and $v$ in $C$, we have both $u \leadsto v$ and $v \leadsto u$; that is, vertices $u$ and $v$ are reachable from each other. \\

We define the transpose of $G$ is the graph $G^T = (V,E^T)$, where $E^T = \{(u,v) : (v,u) \in E \}$. Given an adjacency-list representation of $G$, he time to create $G^T$ is $O(V+E)$. It is interesting to observe that $G$ and $G^T$ have exactly the same strongly connected components: $u$ and $v$ are reachable from each other in $G$ if and only if they are reachable from each other in $G^T$. \\

STRONGLY-CONNECTED-COMPONENTS($G$)
\begin{algorithmic} [1]
\State call DFS($G$) to compute finishing times $u.f$ for each vertex $x$
\State compute $G^T$
\State call DFS($G^T$), but in the main loop of DFS, consider the vertices in order of decreasing $u.f$ (as computed in line 1)
\State output the vertices of each tree in the depth-first forest formed in line 3 as a separately strongly connected component
\end{algorithmic}

The idea behind this algorithm comes from a key property of the \textbf{component graph} $G^{SCC} = (V^{SCC}, E^{SCC})$, which we define as follows. Suppose that $G$ has a strongly connected components $C_1, C_2, \dots, C_k$. The vertex set $V^{SCC}$ is $\{ v_1, v_2, \dots, v_k \}$, and it contains a vertex $v_i$ for each strongly connected component $C_i$ of $G$. There is an edge $(v_i, v_j) \in E^{SCC}$ if $G$ contains a directed edge $(x, y)$ for some $x \in C_i$ and some $y \in C_j$. Looked at another way, by contracting all edges whose incident vertices are within the same strongly connected component of $G$, the resulting graph is $G^{SCC}$. \\

The key property is that the component graph is a dag, which the following lemma implies.

\begin{lemma}
  Let $C$ and $C'$ be distinct strongly connected components in directed graph $G = (V,E)$, let $u,v \in C$, let $u', v' \in C'$, and suppose that $G$ contains a path $u \leadsto u'$. Then $G$ cannot also contain a path $v' \leadsto v$.
\end{lemma}

We extend the notation for discovery and finishing times to sets of vertices. If $U \subseteq V$, then we define $d(U) = \min_{u \in U} \{ i.d \}$ and $f(U) = \max_{u \in U} \{ u.f \}$. That is, $d(U)$ and $f(U)$ are the earliest discovery time and latest finishing time, respectively, of any vertex in U. \\

The following lemma and its corollary give a key property relating strongly connected components and finishing times in the first depth-first search.

\begin{lemma}
  Let $C$ and $C'$ be distinct strongly connected components in directed graph $G = (V,E)$. Suppose that there is an edge $(u,v) \in E$, where $u \in C$ and $v \in C'$. Then $f(C) > f(C')$. 
\end{lemma}

The following corollary tells us that each edge in $G^T$ that goes between different strongly connected components goes from a component with an earlier finishing time (in the first depth-first search) to a component with a later finishing time.

\begin{corollary}
  Let $C$ and $C'$ be distinct strongly connected components in directed graph $G = (V,E)$. Suppose that there is an edge $(u,v) \in E^T$, where $u \in C$ and $v \in C'$. Then $f(C) < f(C')$.
\end{corollary}

\begin{theorem}
  The STRONGLY-CONNECTED-COMPONENTS procedure correctly computes the strongly connected components of the directed graph $G$ provided as its input.
\end{theorem}

Here is another way to look at how the second depth-first search operates. Consider the component graph $(G^T)^{SCC}$ of $G^T$. If we map each strongly connected component visited in the second depth-first search to a vertex of $(G^T)^{SCC}$, the second depth-first search visits vertices of $(G^T)^{SCC}$, the second depth-first search visits vertices of $(G^T)^{SCC}$ in the reverse of a topologically sorted order. If we reverse the edges of $(G^T)^{SCC}$, we get the graph $((G^T)^{SCC})^T$. Because $((G^T)^{SCC})^T = (G^T)^{SCC}$, the second depth-first search visits the vertices of $G^{SCC}$ in topologically sorted order.

\section{Minimum Spanning Trees}

\subsection{Growing a minimum spanning tree}

The generic greedy method manages a set of edges $A$ maintaining the following loop invariant:

\begin{equation*}
  \text{Prior to each iteration, $A$ is a subset of some minimum spanning tree.}
\end{equation*}

At each step, we determine an edge $(u,v)$ that we can add to $A$ without violating this invariant, in the sense that $A \cup \{ (u,v) \}$ is also a subset of a minimum spanning tree.  We call such an edge a \textbf{safe edge} for $A$, since we can add it safely to $A$ while maintaining the invariant. \\

GENERIC-MST($G, \omega$)
\begin{algorithmic} [1]
\State $A = \emptyset$
\While {$A$ does not form a spanning tree}
	\State find an edge $(u,v)$ that is safe for $A$
	\State $A = A \cup \{ (u,v) \}$
\EndWhile
\State \textbf{return } $A$
\end{algorithmic}

A \textbf{cut} $(S, V-S)$ of an undirected graph $G = (V,E)$ is a partition of $V$. We say that an edge $(u,v) \in E$ crosses the cut $(S, V-S)$ if one of its endpoints is in $S$ and the other is in $V-S$. We say that a cut $respects$ a set $A$ of edges if no edge in A crosses the cut. An edge is a \textbf{light edge} crossing a cut if its weight is the minimum of any edge crossing the cut.

\begin{theorem}
  Let $G = (V,E)$ be a connected, undirected graph with a real-valued weight function $\omega$ defined on $E$. Let $A$ be a subset of $E$ that is included in some minimum tree for $G$, let $(S, V-S)$ be any cut of $G$ that respects $A$, and let $(u,v)$ be a light edge crossing $(S, V-S)$. Then, edge $(u,v)$ is safe for $A$.
\end{theorem}

\begin{corollary}
  Let $G = (V,E)$ be a connected, undirected graph with a real-valued weight function $\omega$ defined on $E$. Let $A$ be a subset of $E$ that is included in some minimum spanning tree for $G$, and let $C = (V_C, E_C)$ be a connected component (tree) in the forest $G_A = (V, A)$. If $(u,v)$ is a light edge connecting $C$ to some other component in $G_A$, then $(u,v)$ is safe for $A$.
\end{corollary}

\subsection{The algorithms of Kruskal and Prim}

\subsubsection*{Kruskal's algorithm}

The operation $FIND-SET(u)$ returns a representative element from the set that contains $u$. \\

MST-KRUSKAL($G, \omega$)
\begin{algorithmic} [1]
\State $A = \emptyset$
\For {each vertex $v \in G$}
	\State MAKE-SET($v$)
\EndFor
\State sort the edges of $G.E$ into non-decreasing order by weight $\omega$
\For {each edge $(u,v) \in G.E$, taken in non-decreasing order by weight}
	\If {$\text{FIND-SET}(u) \neq \text{FIND-SET}(v)$}
        	\State $A = A \cup \{ (u,v) \}$
		\State $UNION(u,v)$
	\EndIf
\EndFor
\State \textbf{return } $A$
\end{algorithmic}

The running time of Kruskal's algorithm is $O(E \log V)$. \\

\subsubsection*{Prim's algorithm}

During the execution of the algorithm, all vertices that are not in the tree reside in a min-priority queue $Q$ based on a $key$ attribute. For each vertex $v$, the attribute $v$ is the minimum weight of any edge connecting $v$ to a vertex in the tree; by convention, $v.\text{key} = \infty$ if there is no such edge. \\

MST-PRIM($G, \omega, r$)
\begin{algorithmic} [1]
\For {each $u \in G.V$}
	\State $u.\text{key} = \infty$
        \State $u.\pi = \text{NIL}$
\EndFor
\State $r.\text{key} = 0$
\State $Q = G.V$
\While {$Q \neq \emptyset$}
	\State $u = \text{EXTRACT-MIN}(Q)$
	\For {each $v \in G.Adj[u]$}
		\If {$v \in Q$ and $\omega(u,v) < v.\text{key}$}
			\State $v.\pi = u$
                        \State $v.\text{key} = \omega(u,v)$
                \EndIf
        \EndFor
\EndWhile
\end{algorithmic}

The assignment in line 12 involve an implicit DECREASE-KEY operation on the min-heap, which a binary min-heap supports in $O(\log V)$ time. Thus the total time for Prim's algorithm is $O(V \log V + E \log V) = O(E \log V)$, which is asymptotically the same as for our implementation of Kruskal's algorithm. \\

We can improve the asymptotic running time of Prim's algorithm by using Fibonacci heaps. If so, the running time of Prim's algorithm improves to $O(E + V \log V)$.

\section{Single-Source Shortest Paths}

In a \textbf{shortest-paths problem}, we are given a weighted, directed graph $G = (V,E)$, with weight function $\omega : E \rightarrow \mathbb{R}$ mapping edges to real-valued weights. The \textbf{weights} $\omega(p)$ of path $p = <v_0, v_1, \dots, v_k>$ is the sum of the weights of its constituent edges:

\begin{equation*}
  \omega = \sum_{i=1}^k \omega (v_{i-1}, v_i)
\end{equation*}

We define the \textbf{shortest-path weight} $\delta (u,v)$ from $u$ to $v$ by

\begin{equation*}
  \delta(u,v) =
  \begin{cases}
    \min \{ \omega(p) : u \leadsto^p v\} & \text{if there is  a path from $u$ to $v$,} \\
    \infty & \text{otherwise.}
  \end{cases}
\end{equation*}

A \textbf{shortest path} from vertex $u$ to vertex $v$ is then defined as any path $p$ with weight $\omega(p) = \delta(u,v)$.

\subsubsection*{Variants}

In this chapter we shall focus on the \textbf{single-source shortest-paths problem}: given a graph $G = (V,E)$, we want to find a shortest path from a given \textbf{source} vertex $s \in V$ to each vertex $v \in V$. The algorithm for the single-source problem can solve man other problems, including the following variants. \\

\textbf{Single-destination shortest-path problem:} Find a shortest path to a given \textbf{destination} vertex $t$ from each vertex $v$. By reversing the direction of each edge in the graph, we can reduce this problem to a single-source problem. \\

\textbf{Single-pair shortest path problem:} Find a shortest path from $u$ to $v$ for given vertices $u$ and $v$. If we solve the single-source problem with source vertex $u$, we solve this problem also. Moreover, all known algorithms for this problem have the same worst-case asymptotic running time as the best single-source algorithms. \\

\textbf{All-pairs shortest-path problem:} Find a shortest path from $u$ to $v$ for ever pair of vertices $u$ and $v$. Although we can solve this problem by running a single-source algorithm once from each vertex, we usually can solve it faster. Additionally, its structure is interesting in its own right.

\subsubsection*{Optimal substructure of a shortest path}

Shortest-paths algorithms typically rely on the property that a shortest path between two vertices contains other shortest paths within it.

\begin{lemma} [Subpaths of shortest paths are shortest paths]
  Given a weighted, directed graph $G = (V,E)$ with weight function $\omega : E \rightarrow \mathbb{R}$, let $p = <v_0, v_1, \dots, v_k>$ be a shortest path from vertex $v_0$ to vertex $v_k$ and, for any $i$ and $j$ such that $0 \le i \le j \le k$, let $p_{ij} = <v_i, v_{i+1}, \dots, v_J>$ be the subpath of $p$ from vertex $v_i$ to vertex $v_j$. Then $p_{ij}$ is a shortest path from $v_i$ to $v_j$.
\end{lemma}

\subsubsection*{Relaxation}

The algorithm in this chapter use the technique of \textbf{relaxation}. For each vertex $v \in V$, we maintain an attribute $v.d$, which is an upper bound on the weight of a shortest path from source $s$ to $v$. We call $v.d$ a \textbf{shortest-path estimate}. We initialize the shortest path estimate and predecessors by the following $\Theta(V)$-time procedure: \\

INITIALIZE-SINGLE-SOURCE($G,s$)
\begin{algorithmic} [1]
\For {each vertex $v \in G.V$}
	\State $v.d = \infty$
        \State $v.\pi = \text{NIL}$
\EndFor
\State $s.d = 0$
\end{algorithmic}

After initialization, we have $v.\pi = \text{NIL}$ for all $v \in V$, $s.d = 0$, and $v.d = \infty$ for $v \in V - \{ s \}$. \\

RELAX($u,v,w$)
\begin{algorithmic} [1]
\If {$v.d > u.d + \omega(u,v)$}
	\State $v.d = u.d + \omega(u,v)$
	\State $v.\pi = u$
\EndIf
\end{algorithmic}

\subsubsection*{Properties of shortest paths and relaxation}

\begin{itemize}
  \item \textbf{Triangle inequality} For any edge $(u,v) \in E$, we have $\delta(s,v) \le \delta(s,u) + w(u,v)$
  \item \textbf{Upper-bound property} We always have $v.d \ge \delta(s,v)$ for all vertices $v \in V$, and once $v.d$ achieves the value $\delta(s,v)$, it never changes.
  \item \textbf{No-path property} If there is no path from $s$ to $v$, then we always have $v.d = \delta(s,v) = \infty$.
  \item \textbf{Convergence property} If $s \leadsto u \rightarrow v$ is a shortest path in $G$ for some $u,v \in V$, and if $u.d = \delta(s,u)$ at any time prior to relaxing edge $(u,v)$, then $v.d = \delta(s,v)$ at all times afterward.
  \item \textbf{Path-relaxation property} If $p = <v_0, v_1, \dots, v_k>$ is a shortest path from $s = v_0 \text{ to } v_k$, and we relax the edges of $p$ in the order $(v_0, v_1), (v_1, v_2), \dots, (v_{k-1}, v_k)$, then $v_k.d = \delta(s, v_k)$. This property holds regardless of any other relaxation steps that occur, even if they are intermixed with relaxations of the edges of $p$.
  \item \textbf{Predecessor-subgraph property} Once $v.d=\delta(s,v)$ for all $v \in V$, the predecessor subgraph is a shortest-paths tree rooted at $s$.
\end{itemize}

\subsection{The Bellman-Ford algorithm}

The \textbf{Bellman-Ford algorithm} solves the single-source shortest-paths problem in the general case in which edge weights may be negative. Given a weighted, directed graph $G = (V,E)$ with source $s$ and weight function $\omega : E \rightarrow \mathbb{R}$, the Bellman-Ford algorithm returns a boolean value indicating whether or not there is a negative-weight cycle that is reachable from the source. If there is such a cycle, the algorithm indicates that on solution exists. If there is no such cycle the algorithm produce the shortest paths and their weights. \\

BELLMAN-FORD($G, \omega, s$)
\begin{algorithmic} [1]
\State INITIALIZE-SINGLE-SOURCE($G,s$)
\For {$i = 1 \textbf{ to } |G.V| - 1$}
	\For {each edge $(u,v) \in G.E$}
		\State RELAX($u,v,\omega$)
        \EndFor
\EndFor
\For {each edge $(u,v) \in G.E$}
	\If {$v.d > u.d + \omega(u,v)$}
		\State \textbf{return } FALSE
        \EndIf
\EndFor
\State \textbf{return } TRUE
\end{algorithmic}

The Bellman-Ford algorithm runs in time $O(VE)$. \\

\begin{lemma}
  Let $G = (V,E)$ be a weighted, directed graph with source $s$ and weight function $\omega : E \rightarrow \mathbb{R}$, and assume that $G$ contains no negative-weight cycles that are reachable from $s$. Then after the $|V| - 1$ iterations of the first \textbf{for} loop of BELLMAN-FORD, we have $v.d = \delta(s.v)$ for all vertices $v$ that are reachable from $s$.
\end{lemma}

\begin{corollary}
  Let $G = (V,E)$ be a weighted, directed graph with source vertex $s$ and weight function $\omega : E \rightarrow \mathbb{R}$, and assume that $G$ contains  no negative-weight cycles that are reachable from $s$. Then, for each vertex $v \in V$, there is a path from $s$ to $v$ if and only if BELLMAN-FORD terminates with $v.d < \infty$ when it is run on $G$.
\end{corollary}

\begin{theorem} [Correctness of Bellman-Ford algorithm]
  Let BELLMAN-FORD be run on a weighted, directed graph $G = (V,E)$ with source $s$ and weight function $\omega : E \rightarrow \mathbb{R}$. If G contains no negative-weight cycles that are reachable from $s$, then the algorithm returns $TRUE$, we have $v.d = \delta(s,v)$ for all vertices $v \in V$, and the predecessor subgraph $G_{\pi}$ is a shortest-paths tree rooted at $s$. If $G$ does contain a negative-weight cycle reachable from $s$, then the algorithm returns $FALSE$.
\end{theorem}

\subsection{Single-source shortest paths in directed acyclic graphs}

By relaxing the edges of a weighted dag $G = (V,E)$ according to a topological sort of its vertices, we can compute shortest paths from a single source in $\Theta(V+E)$ time. \\

DAG-SHORTEST-PATHS($G, \omega, s$)
\begin{algorithmic} [1]
\State topologically sort the vertices of $G$
\State INITIALIZE-SINGLE-SOURCE($G,s$)
\For {each vertex $u$, taken in topologically sorted order}
	\For {each vertex $v \in G.Adj[u]$}
		\State RELAX($u, v, \omega$)
        \EndFor
\EndFor
\end{algorithmic}

The total running time is $\Theta(V+E)$.

\begin{theorem}
  If a weighted, directed graph $G = (V,E)$ has source vertex $s$ and no cycles, then at the termination of the $DAG-SHORTEST-PATHS$ procedure, $v.d=\delta(s,v)$ for all vertices $v \in V$, and the predecessor subgraph $G_{\pi}$ is a shortest-paths tree.
\end{theorem}

\subsection{Dijkstra's algorithm}

Dijkstra's algorithm solves the single-source shortest-paths problem on a weighted directed graph $G = (V,E)$ for the case in which all edge weights are non-negative. \\

DIJKSTRA($G, \omega, s$)
\begin{algorithmic} [1]
\State INITIALIZE-SINGLE-SOURCE($G,s$)
\State $S = \emptyset$
\State $Q = G.V$
\While {$Q \neq \emptyset$}
	\State $u = \text{EXTRACT-MIN}(Q)$
	\State $S = S \cup \{ u \}$
        \For {each vertex $v \in G.Adj[u]$}
		\State RELAX($u,v,w$)
        \EndFor
\EndWhile
\end{algorithmic}

\begin{theorem} [Correctness of Dijkstra's algorithm]
  Dijkstra's algorithm, run on a weighted, directed graph $G = (V,E)$ with non-negative weight function $\omega$ and source $s$, terminates with $u.d = \delta(s,u)$ for all vertices $u \in V$.
\end{theorem}

\begin{corollary}
  If we run Dijkstra's algorithm on a weighted, directed graph $G = (V,E)$ with non-negative weight function $w$ and source $s$, then at termination, the predecessor subgraph $G_{\pi}$ is a shortest-paths tree rooted at $s$.
\end{corollary}

\subsubsection*{Analysis}

If we  implement the min-priority queue with a binary min-heap, then the total running time is $O((V+E)\log V) = O(E \log V)$. Moreover, if we implement the min-priority queue with a Fibonacci heap, then the running time will be $O(V \log V + E)$.

\subsection{Difference constraints and shortest paths}

\subsubsection*{Linear programming}

In the general \textbf{linear-programming problem}, we are given an $m \times n$ matrix $A$, an $m$-vector $b$, and an $n$-vector $c$. We wish to find a vector $x$ of $n$ elements that maximizes the \textbf{objective function} $\sum_{i=1}^n c_i x_i$ subject to the $m$ constraints given by $Ax \le b$.

\section{All-Pairs Shortest Paths}

\subsection{Shortest paths and matrix multiplication}

his section presents a dynamic-programming algorithm for the all-pairs shortest-paths problem on a directed graph $G = (V, E)$. Each major loop of the dynamic program will invoke an operation that is very similar to matrix multiplication, so that the algorithm will look like repeated matrix multiplication. We shall start by developing a $\Theta(V^4)$-time algorithm for the all-pairs shortest-paths problem and then improve its running time to $\Theta(V^3 \log V)$.

\subsection{The Floyd-Warshall algorithm}

In this section, we shall use a different dynamic-programming formulation to solve the all-pairs shortest-paths problem on a directed graph $G = (V,E)$. The resulting algorithm, known as the \textbf{Floyd-Warshall algorithm}, runs in $\Theta(V^3)$ time.

\subsubsection*{A recursive solution to the all-pairs shortest-paths problems}

Let $d_{ij}^{(k)}$ be the weight of a shortest path from vertex $i$ to vertex $j$ for which all intermediate vertices are in the set $\{ 1,2,\dots,k \}$. We define $d_{ij}^{(k)}$ recursively by

\begin{equation*}
  d_{ij}^{(k)} =
  \begin{cases}
    \omega_{ij} & \text{if $k=0$,} \\
    \min (d_{ij}^{(k-1)}, d_{ik}^{(k-1)} + d_{kj}^{(k-1)}) & \text{if $k \ge 1$.}
  \end{cases}
\end{equation*}

Because of any path, all intermediate vertices are in the set $\{ 1,2,\dots,n \}$, the matrix $D^{(n)} = (d_{ij}^(n))$ gives the final answer: $d_{ij}^{(n)} = \delta(i,j)$ for all $i,j \in V$.

\subsubsection*{Computing the shortest-path weights bottom up}

Let $W = (\omega_{ij})$. \\

FLOYD-WARSHALL($W$)
\begin{algorithmic} [1]
\State $n = W.rows$
\State $D^{(0)} = W$
\For {$k = 1 \text{ to } n$}
	\State let $D^{(k)} = (d_{ij}^{(k)})$ be $n \times n$ matrix
	\For {$i = 1 \text{ to } n$}
		\For {$j = 1 \text{ to } n$}
			\State $d_{ij}^{(k)} = \min (d_{ij}^{(k-1)}, d_{ik}^{(k-1)} + d_{kj}^{(k-1)})$
                \EndFor
        \EndFor
\EndFor
\State \textbf{return } $D^{(n)}$
\end{algorithmic}

The running time of this algorithm is $\Theta(n^3)$.

\subsubsection*{Constructing a shortest path}

We can computer the predecessor matrix $\prod$ while the algorithm computes the matrices $D^{(k)}$. Specifically, we compute a sequence of matrices $\prod^{(0)}, \prod^{(1)}, \dots, \prod^{(n)}$, where $\prod = \prod^{(n)}$ and we define $\pi_{ij}^{(k)}$ as the predecessor of vertex $j$ on a shortest path from vertex $i$ with all intermediate vertices in the set $\{ 1,2, \dots, k \}$. \\

We can give a recursive formulation of $\pi_{ij}^{k}$. When $k = 0$,

\begin{equation*}
  \pi_{ij}^{(0)} =
  \begin{cases}
    NIL & \text{if $i=j$ or $\omega_{ij} = \infty$,} \\
    i   & \text{if $i \neq j$ and $\omega_{ij} < \infty$.}
  \end{cases}
\end{equation*}

For $k \ge 1$,

\begin{equation*}
  \pi_{ij}^{(k)} =
  \begin{cases}
    \pi_{ij}^{(k)-1} & \text{if $d_{ij}^{(k-1)} \le d_{ik}^{(k-1)} + d_{kj}^{(k-1)}$,} \\
    \pi_{kj}^{(k-1)} & \text{if $d_{ij}^{(k-1)} > d_{ik}^{(k-1)} + d_{kj}^{(k-1)}$.}
  \end{cases}
\end{equation*}

\subsection{Johnson's algorithm for spare graphs}

Johnson's algorithm uses the technique of \textbf{reweighting}. If $G$ has negative-weight edges but no negative-weight cycles, we simply compute a new set of non-negative edge weights that allow us to use the same method. The new set of edge weights $\hat{\omega}$ must satisfy two important properties:

\begin{enumerate}
  \item For all pairs of vertices $u ,v \in V$, a path $p$ is a shortest path from $u$ to $v$ using weight function $\omega$ if and only if $p$ is also a shortest path from $u$ to $v$ using weight function $\hat{\omega}$.
  \item For all edges $(u,v)$, the new weight $\hat{\omega}(u,v)$ is non-negative.
\end{enumerate}

We can pre-process $G$ to determine the new weight function $\hat{\omega}$  in $O(VE)$ time.

\subsubsection*{Preserving shortest paths by reweighting}

\begin{lemma}
  Given a weighted, directed graph $G = (V, E)$ with weight function $\omega : E \rightarrow \mathbb{R}$ be any function mapping vertices to real numbers. For each edge $(u,v) \in E$, define
  \begin{equation*}
    \hat{\omega}(u,v) = \omega(u,v) + h(u) - h(v).
  \end{equation*}
  Let $p = <v_0, v_1, \dots, v_k>$ be any path from vertex $v_0$ to vertex $v_k$. Then $p$ is a shortest path from $v_0$to $v_k$ with weight function $\omega$ if and only if it is a shortest path with weight function $\hat{\omega}$. That is, $\omega(p) = \delta(v_0, v_k)$ if and only if $\hat{w}(p) = \hat{\delta}(v_0, v_k)$.Furthermore, $G$ has a negative-weight cycle using weight function $\omega$ if and only if $G$ has a negative-weight cycle using weight function $\hat{\omega}$.
\end{lemma}

\subsubsection*{Producing non-negative weights by reweighting}

Our next goal is to ensure that the second property holds. Given a weighted, directed graph $G = (V,E)$ with weight function $\omega : E \rightarrow \mathbb{R}$, we make a new graph $G' = (V', E')$, where $V' = V \cup {s}$ for some new vertex $s \notin V$ and $E' = E \cup \{ (s,v) : v \in V \}$. We extend the weight function $\omega$ so that $\omega(s,v) = 0$ for all $v \in V$. Note that because $s$ has no edges that enter it, no shortest paths in $G'$, other than those with source $s$, contain $s$. Moreover, $G'$ has no negative-weight cycles if and only if $G$ has no negative-weight cycles. \\

Suppose that $G$ and $G'$ have no negative cycles. Let us define $h(v) = \delta(s, v)$ for all $v \in V'$ By the triangle inequality, we have $h(v) \le h(u) + \omega(u,v)$ for all edges $(u,v) \in E'$. Thus, we can define the new weights $\hat{\omega} = \omega(u,v) + h(u) - h(v) \ge 0$.

\subsubsection*{Computing all-pairs shortest paths}

JOHNSON($G, \omega$)
\begin{algorithmic} [1]
\State compute $G'$
\If {$\text{BELLMAN-FORD}(G', \omega, s) == \text{FALSE}$}
	\State print ``the input graph contains a negative-weight cycle''
\Else
	\For {each vertex $v \in G'.V$}
		\State set $h(v)$ to the value of $\delta(u,v)$ computed by the Bellman-Ford algorithm
        \EndFor
        \For {each edge $(u,v) \in G'.E$}
		\State $\hat{\omega}(u,v) = \omega(u,v) + h(u) - h(v)$
        \EndFor
        \State Let $D = (d_{uv})$ be a new $n \times n$ matrix
        \For {each vertex $u \in G.V$}
		\State run DIJKSTRA($G, \hat{\omega}, u$) to compute $\hat{\delta}$ for all $v \in G.V$
		\For{each vertex $v \in G.V$}
			\State $d_{uv} = \hat{\delta}(u,v) + h(v) - h(u)$
                \EndFor
        \EndFor
        \State \textbf{return } $D$
\EndIf
\end{algorithmic}

If we use simple binary min-heap, Johnson's algorithm runs in $O(VE \log V)$. If we implement the min-priority queue in Dijkstra's algorithm by a Fibonacci heap, Johnson's algorithm runs in $O(V^2 \log V + VE)$.

\section{Maximum Flow}

\subsection{Flow networks}

A \textbf{flow network} $G = (V,E)$ is a directed graph in which each edge $(u,v) \in E$ has a non-negative \textbf{capacity} $c(u,v) \ge 0$. If $(u,v) \notin E$, then for convenience we define $c(u,v) = 0$, and we disallow self-loops. We distinguish two vertices in a flow network: a \textbf{source} $s$ and a \textbf{sink} $t$. \\

Let $G = (V,E)$ be a flow network with a capacity function $c$. Let $s$ be the source of the network, and let $t$ be the sink. A \textbf{flow} in $G$ is a real-valued function $f : V \times V \rightarrow \mathbb{R}$ that satisfies the following two properties: \\

\textbf{Capacity constraint:} For all $u,v \in V$, we require $0 \le f(u,v) \le c(u,v)$. \\

\textbf{Flow conservation:} For all $u \in V - \{ s,t \}$, we require
\begin{equation*}
  \sum_{v \in V} f(v,u) = \sum_{v \in V} f(u,v).
\end{equation*}

When $(u,v) \notin E$, there can be no flow from $u$ to $v$, and $f(u,v) = 0$. \\

We call the non-negative quantity $f(u,v)$ the flow from vertex $u$ to vertex $v$. The \textbf{value} $|f|$ of a flow $f$ is defined as
\begin{equation*}
  |f| = \sum_{v \in V} f(s,v) - \sum_{v \in V} f(v,s)
\end{equation*}

that is, the total flow out of the source minus the flow into the source.

\subsubsection{Modeling problems with antiparallel edges}

If an edge $(v_1, v_2) \in E$, and $(v_2, v_1) \in E$, we call the two edges $(v_1, v_2)$ and $(v_2, v_1)$ \textbf{antiparallel}.

\subsubsection{Networks with multiple sources and sinks}

A maximum-flow problem may have several sources and sinks, rather than just one of each. We can reduce the problem of determining a maximum flow in a network with multiple sources and multiple sinks to an ordinary maximum-flow problem. We dd a \textbf{supersource} $s$ and add a direct edge $(s, s_i) = \infty$ for each $i = 1,2,\dots,m$. We also create a new \textbf{supersink} $t$ and add a directed edge $(t_i, t)$ with capacity $c(t_i, t) = \infty$ foreach $i = 1,2,\dots,n$. 

\subsection{The Ford-Fulkerson method}

FORD-FULKERSON-METHOD($G, s, t$)
\begin{algorithmic} [1]
\State initialize flow $f$ to $0$
\While {there exists an augmenting path $p$ in the residual network $G_f$}
	\State augment flow $f$ along $p$
\EndWhile
\State \textbf{return } $f$
\end{algorithmic}

\subsubsection*{Residual networks}

Given a flow network $G$ and a flow $f$, the residual network $G_f$ consists of edges with capacities that represent how we can change the flow on edges of $G$. \\

We define the \textbf{residual capacity} $c_f(u,v)$ by

\begin{equation*}
  c_f(u,v) =
  \begin{cases}
    c(u,v) - f(u,v) & \text{if $(u,v) \in E$,} \\
    f(v,u) & \text{if $(v,u) \in E$,} \\
    0 & \text{otherwise.}
  \end{cases}
\end{equation*}

Given a flow network $G = (V,E)$ and a flow $f$, the \textbf{residual network} of $G$ induced by $f$ is $G_f = (V, E_f)$, where

\begin{equation*}
  E_f = \{ (u,v) \in V \times V : c_f(u,v) > 0 \}
\end{equation*}

That is, as promised above, each edge of the residual network, or \textbf{residual edge}, can admit a flow that is greater than 0. \\

If $f$ is a flow in $G$ and $f'$ is a flow in the corresponding residual network $G_f$, we define $f \uparrow f'$, the \textbf{augmentation} of flow $f$ by $f'$, to be a function from $V \times V$ to $\mathbb{R}$, defined by

\begin{equation*}
  (f \uparrow f')(u,v) =
  \begin{cases}
    f(u,v) + f'(u,v) - f'(v,u) & \text{if $(u,v) \in E$,} \\
    0 & \text{otherwise.}
  \end{cases}
\end{equation*}

The intuition behind this definition follows the definition of the residual network. We increase the flow on $(u,v)$ by $f'(v,u)$ because pushing flow on the reverse edge in the residual network signifies decreasing the flow in the original network. Pushing flow on the reverse edge in the residual network is also known as \textbf{cancellation}.

\begin{lemma}
  Let $G = (V,E)$ be a flow network with source $s$ and sink $t$, and let $f$ be a flow in $G$. Let $G_f$ be the residual network of $G$ induced by $f$, and let $f'$ be a flow in $G_f$. Then the function $f \uparrow f'$ defined in the previous equation is a flow in $G$ with value $|f \uparrow f'| = |f| + |f'|$.
\end{lemma}

\subsubsection*{Augmenting paths}

Given a flow network $G = (V,E)$ and a flow $f$, an \textbf{augmenting path} $p$ is a simple path from $s$ to $t$ in the residual network $G_f$. We call the maximum amount by which we can increase the flow on each edge in an augmenting path $p$ the \textbf{residual capacity} of $p$, given by

\begin{equation*}
  c_f(p) = \min \{ c_f(u,v): (u,v) \text{ is on } p \}.
\end{equation*}

\begin{lemma}
  Let $G = (V,E)$ be a flow network, let $f$ be a flow in $G$, and let $p$ be an augmenting path in $G_f$. Define a function $f_p : V \times V \rightarrow \mathbb{R}$ by
\begin{equation*}
  f_p(u,v) =
  \begin{cases}
    c_f(p) & \text{if $(u,v)$ is on $p$,} \\
    0 & \text{otherwise.}
  \end{cases}
\end{equation*}

Then $f_p$ is a flow in $G_f$ with value $|f_p| = c_f(p) > 0$.
\end{lemma}

\begin{corollary}
  Let $G = (V, E)$ be a flow network, let $f$ be a flow in $G$, and let $p$ be an augmenting path in $G_f$. Let $f_p$ be defined as in the previous equation, and suppose that we augment $f$ by $f_p$. Then the function $f \uparrow f_p$ is a flow in $G$ with value $|f \uparrow f'| = |f| + |f_p| > |f|$.
\end{corollary}

\subsubsection*{Cuts of flow networks}

A \textbf{cut} $(S,T)$ of flow network $G = (V,E)$ is a partition of $V$ into $S$ and $T = V - S$ such that $s \in S$ and $t \in T$. If $f$ is a flow, then the \textbf{net flow} across the cut $(S,T)$ is defined to be
\begin{equation*}
  f(S,T) = \sum)_{u \in S} \sum_{v \in T} f(u,v) - \sum)_{u \in S} \sum_{v \in T} f(v,u)
\end{equation*}

The \textbf{capacity} of the cut $(S,T)$ is

\begin{equation*}
  c(S,T) = \sum_{u \in S} \sum_{v \in T} c(u,v).
\end{equation*}

A \textbf{minimum cut} of a network is a cut whose capacity is minimum over all cuts of the network.

\begin{lemma}
  Let $f$ be a flow in a flow network $G$ with source $s$ and sink $t$, and let $(S,T)$ be any cut of $G$. Then the net flow across (S,T) is $f(S,T) = |f|$.
\end{lemma}

\begin{corollary}
  The value of any flow $f$ in a flow network $G$ is bounded from above by the capacity of any cut of $G$.
\end{corollary}

\begin{theorem} [Max-flow min-cut theorem]
  If $f$ is a flow network $G = (V,E)$ with source $s$ and sink $t$, then the following conditions are equivalent:
  \begin{enumerate}
    \item $f$ is a maximum flow in $G$.
    \item The residual network $G_f$ contains no augmenting paths.
    \item $|f| = c(S,T)$ for some cut $(S,T)$ of $G$.
  \end{enumerate}
\end{theorem}

\subsubsection*{The basic Ford-Fulkerson algorithm}

FORD-FULKERSON($G, s, t$)
\begin{algorithmic} [1]
\For {each edge $(u,v) \in G.E$}
	\State $(u, v).f = 0$
\EndFor
\While {there exists a path $p$ from $s$ to $t$ in the residual network $G_f$}
	\State $c_f(p) = \min \{ c_f(u,v) : (u,v) \text{ is in } p \}$
	\For {each edge $(u,v)$ in $p$}
		\If {$(u,v) \in E$}
			\State $(u,v).f = (u,v).f + c_f(p)$
                \Else
			\State $(u,v).f = (v,u).f - c_f(p)$
                \EndIf
        \EndFor
\EndWhile
\end{algorithmic}

The running time of FORD-FULKERSON depends on how we find the augmenting path $p$ in line 3.

\subsubsection*{The Edmonds-Karp algorithm}

We call the Ford-Fulkerson method implemented by finding the augmenting path $p$ with a breadth-first search the \textbf{Edmonds-Karp algorithm}. And the algorithm runs in $O(VE^2)$ time.

\begin{lemma}
  If the Edmond-Karp algorithm is run on a flow network $G = (V,E)$ with source $s$ and sink $t$, then for all vertices $v \in V - \{ s,t \}$, the shortest-path distance $\delta_f(s,v)$ in the residual network $G_f$ increases monotonically with each flow augmentation.
\end{lemma}

\begin{theorem}
  If the Edmonds-Karp algorithm is run on a flow network $G = (V,E)$ with source $s$ and sink $t$, then the total number of flow augmentations performed by the algorithm is $O(VE)$.
\end{theorem}

\section{String Matching}

We say that pattern $P$ \textbf{occurs with shift $s$} in text $T$ (or, equivalently, that pattern $P$ \textbf{occurs beginning at position $s+1$} in text $T$) if $0 \le s \le n-m$ and $T[s+1 \dots s+m] = P[1 \dots m]$ (that is , if $T[s+j] = P[j]$, for $1 \le j \le m$). If $P$ occurs with shift $s$ in $T$, then we call $s$ a \textbf{valid shift}; otherwise, we call $s$ an \textbf{invalid shift}. The \textbf{string-matching problem} is the problem of finding all valid shifts with which a given pattern $P$ occurs in a given text $T$. \\

We denote by $\Sigma^*$ the set of all finite-length strings formed using characters from the alphabet $\Sigma$. The zero-length \textbf{empty string}, denoted $\varepsilon$. The length of a string $x$ denoted $|x|$. The \textbf{concatenation} of two strings $x$ and $y$, denoted $xy$m has length $|x| + |y|$ and consists of the characters from $x$ followed by the characters from $y$. \\

We say that a string $\omega$ is a \textbf{prefix} of a string $x$, denoted $\omega \sqsubset x$, if $x = \omega y$ for some string $y \in \Sigma^*$. Note that if $\omega \sqsubset x$, then $|\omega| < |x|$. Similarly, we say that a string $\omega$ is a \textbf{suffix} of a string $x$, denoted $\omega \sqsupset x$, if $x = y \omega$ for some $y \in \Sigma^*$. As with a prefix, $\omega \sqsubset x$ implies $|\omega| \le |x|$.

\begin{lemma} [Overlapping-suffix lemma]
  Suppose that $x, y$, and $z$ are strings such $x \sqsupset z$ and $y \sqsupset z$. If $|x| \le |y|$, then $x \sqsupset y$. If $|x| \ge |y|$, then $y \sqsupset x$. if $|x| = |y|$, then $x = y$.
\end{lemma}

\subsection{The Knuth-Morris-Pratt algorithm}

KMP-MATCHER($T, P$)
\begin{algorithmic} [1]
\State $n = T.\text{length}$
\State $m = P.\text{length}$
\State $\pi = \text{COMPUTE-PREFIX-FUNCTION}(P)$
\State $q = 0$
\For {$i = 1 \textbf{ to } n$}
	\While {$q > 0$ and $P[q+1] \neq T[i]$}
        	\State $q = \pi [q]$
        \EndWhile
        \If {$P[q+1] == T[i]$}
		\State $q = q + 1$
        \EndIf
        \If {$q == m$}
		\State print ``Pattern occurs with shift" $i-m$
                \State $q = \pi [q]$
        \EndIf
\EndFor
\end{algorithmic}

COMPUTE-PREFIX-FUNCTION($P$)
\begin{algorithmic} [1]
\State $m = P.\text{length}$
\State let $\pi [1 \dots m]$ be a new array
\State $\pi [1] = 0$
\State $k = 0$
\For {$q = 2 \textbf{ to } m$}
	\While {$k > 0$ and $P[k+1] \neq P[q]$}
		\State $k = \pi [k]$
        \EndWhile
        \If {$P[k+1] == P[q]$}
        	\State $k = k + 1$
        \EndIf
        \State $\pi [q] = k$
\EndFor
\State \textbf{return } $\pi$
\end{algorithmic}

Using the aggregate method of amortized analysis, $COMPUTE-PREFIX-FUNCTION$ runs in time $\Theta(m)$. And $KMP-MATCHER$ runs in $\Theta(n)$

\section{NP-Completeness}

\subsection{Polynomial time}

We say that a function $f: \{ 0,1 \}^*$ is \textbf{polynomial-time computable} if there exists a polynomial-time algorithm $A$ that, given any input $x \in \{ 0,1 \}^*$, produces as output $f(x)$. For some set $I$ of problem instances, we that two encoding $e_1$ and $e_2$ are \textbf{polynomial related} if there exist two polynomial-time computable functions $f_{12}$ and $f_{21}$ such that for any $i \in I$, we have $f_{12}(e_1(i)) = e_2(i)$ and $f_{21}(e_2(i)) = e_1(i)$. That is, a polynomial-time algorithm can compute the encoding $e_2(i)$ from encoding $e_1(i)$, and vice versa.

\subsection{Polynomial-time verification}

We define a \textbf{verification algorithm} as being a two-argument algorithm A, where one argument is an ordinary input string $x$ and other is a binary string $y$ called a \textbf{certificate}. A two-argument algorithm $A$ \textbf{verifies} an input string $x$ if there exists a certificate $y$ such that $A(x,y) = 1$. The \textbf{language verified} by a verification algorithm $A$ is 

\begin{equation*}
  L = \{ x \in \{ 0,1 \}^*: \text{ there exists } y \in \{ 0,1 \}^* \text{ such that } A(x,y) = 1 \}
\end{equation*}

The \textbf{complexity class $NP$} is the class of languages that can be verified by a polynomial-time algorithm. More precisely, a language $L$ belongs to $NP$ if and only if there exist a two-input polynomial-time algorithm $A$ and a constant $c$ such that

\begin{equation*}
  L = \{ x \in \{ 0,1 \}^*: \text{ there exists } y \text{ with } |y = O(|x|^c)| \text{ such that } A(x,y) = 1 \}
\end{equation*}

We say that algorithm $A$ \textbf{verifies} language $L$ \textbf{in polynomial time}. \\

We define the \textbf{complexity class co-NP} as the set of language $L$ such that $\bar{L} \in NP$.

\subsection{NP-completeness and reducibility}

We say that a language $L_1$ is \textbf{polynomial-time reducible} to a language $L_2$, written $L_1 \le_p L_2$, if there exists a polynomial-time computable function $f : \{ 0,1 \}^* \rightarrow \{ 0,1 \}^*$ such that for all $x \in \{ 0,1 \}^*$,

\begin{equation*}
  x \in L_1 \text{ if and only if } f(x) \in L_2
\end{equation*}

We call the function $f$ the \textbf{reduction function}, and a polynomial-time $F$ that computes $f$ is a \textbf{reduction algorithm}. \\

A language $L \subseteq \{ 0,1 \}^*$ is \textbf{NP-complete} if
\begin{enumerate}
  \item $L \in NP$, and
  \item $L' \le_P L$ for every $L\ \in NP$
\end{enumerate}

If a language $L$ satisfies property 2, but not necessarily property 1, we say that $L$ is \textbf{NP-hard}. We also define $NPC$ to be the class of $NP$-complete languages.

\subsection{NP-completeness proofs}

\begin{lemma}
If $L$ is a language such that $L\ \le_P L$ for some $L\ \in NPC$, then $L$ is $NP$-hard. If, in addition, $L \in NP$, then $L \in NPC$.
\end{lemma}




\end{document}


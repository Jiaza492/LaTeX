\documentclass[12pt]{article}
\parindent=.25in

\setlength{\oddsidemargin}{0pt}
\setlength{\textwidth}{440pt}
\setlength{\topmargin}{0in}

\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{algpseudocode}
\usepackage{algorithm}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\title{Introduction to Algorithms Note}
\author{Mengqi Zong $<mz2326@columbia.edu>$}

\begin{document}

\maketitle

\tableofcontents

\setlength{\parindent}{0in}

\section{The Role of Algorithms in Computing}

Informally, an \textbf {algorithm} is any well-defined computational procedure that takes some value, or set of values, as \textbf {input} and produces some value, or set of values, as \textbf {output}. An algorithm is thus a sequence of computational steps that transform the input into the output.

\section{Getting Started}

\subsection{Insertion sort}

INSERTION-SORT(A)
\begin{algorithmic}[1]
\For {$j = 2 \textbf { to } A.length$}
	\State $key = A[j]$
        \State // Insert $A[j]$ into the sorted sequence $A[1..j-1]$.
        \State $i = j - 1$
        \While {$i > 0$ and $A[i] > key$}
        	\State $A[i+1] = A[i]$
                \State $i = i - 1$
        \EndWhile
        \State $A[i+1] = key$
\EndFor
\end{algorithmic}

\subsection{Merge sort}

MERGE($A, p, q, r$)
\begin{algorithmic}[1]
\State $n_1 = q - p + 1$
\State $n_2 = r - q$
\State let $L[1..n_1+1]$ and $R[1..n_2+1]$ be new arrays
\For {$i = 1 \textbf { to } n_1$}
	\State $L[i] = A[p+i-1]$
\EndFor
\For {$j = 1 \textbf { to } n_2$}
	\State $R[j] = A[q+j]$
\EndFor
\State $L[n_1 + 1] = \infty$
\State $R[n_2 + 1] = \infty$
\State $i = 1$
\State $j = 1$
\For {$k = p \textbf { to } r$}
	\If {$L[i] \le R[j]$}
        	\State $A[k] = L[i]$
                \State $i = i + 1$
        \Else
        	\State $A[k] = R[j]$
        	\State $j = j + 1$
        \EndIf
\EndFor
\end{algorithmic}

MERGE-SORT($A, p, r$)
\begin{algorithmic}[1]
\If {$p < r$}
	\State $q = \lfloor (p+r)/2 \rfloor$
        \State MERGE-SORT($A, p, q$)
        \State MERGE-SORT($A, q+1, r$)
        \State MERGE($A, p, q, r$)
\EndIf
\end{algorithmic}

\section{Growth of Functions}

\subsection{Asymptotic notation}

\begin{eqnarray*}
  \Theta (g(n)) = \{ f(n): && \text{there exist positive constants
    $c_1$, $c_2$, and $n_0$ such that} \\
  && 0 \le c_1 g(n) \le f(n) \le c_2 g(n) \text{ for all } n \ge n_0 \} \\
  O(g(n)) = \{ f(n): && \text{there exist positive constants
    $c$ and $n_0$ such that} \\
  && 0 \le f(n) \le cg(n) \text{ for all } n \ge n_0 \} \\
  \Omega (g(n)) = \{ f(n): && \text{there exist positive constants
    $c$ and $n_0$ such that} \\
  && 0 \le cg(n) \le f(n) \text{ for all } n \ge n_0 \}
\end{eqnarray*}

\subsection{Common functions}

\begin{eqnarray*}
  e^x &=& \sum_0^{\infty} \frac {x^i}{i!} \\
  e^x &=& \lim_{n \rightarrow \infty} (1 + \frac {x}{n})^n \\
  n!  &=& \sqrt {2 \pi n} \left(\frac {n}{e} \right)^n 
          \left( 1 + \Theta \left( \frac {1}{n} \right) \right)
\end{eqnarray*}

\section{Divide-and-Conquer}

\subsection{The master method}

\begin{theorem}
  Let $a \ge 1$ and $b \ge 1$ be constants, let $f(n)$ be a function, and let $T(n)$ be defined on the non-negative integers by recurrence
  \begin{equation*}
    T(n) = aT(n/b) + f(n),
  \end{equation*}
  where we interpret $n/b$ to mean either $\lfloor n/b \rfloor$ or $\lceil n/b \rceil$. Then $T(n)$ has the following asymptotic bounds:
  \begin{enumerate}
  \item If $f(n) = O(n^{\log_b^a - \epsilon})$ for some constant $\epsilon > 0$, then $T(n) = \Theta (n^{\log_b a})$.
  \item If $f(n) = \Theta (n^{\log_b^a})$, then $T(n) = \Theta (n^{\log_b a} \lg n)$.
  \item If $f(n) = O(n^{\log_b^a + \epsilon})$ for some constant $\epsilon > 0$, and if $af(n/b) \le cf(n)$ for some constant $c < 1$ and all sufficiently large $n$, then $T(n) = \Theta \left( f(n) \right)$.
  \end{enumerate}
\end{theorem}

\section{Probabilistic Analysis and Randomized Algorithms}

\subsection{Indicator random variables}

Suppose we are given a sample space $S$ and an event $A$. Then the \textbf {indicator random variable} $I\{A\}$ associated with event A is defined as
\begin{equation*}
  I\{A\} =
  \begin{cases}
    1 & \text{if $A$ occurs,} \\
    0 & \text{if $A$ does not occur.}
  \end{cases}
\end{equation*}

\begin{lemma}
  Given a sample space $S$ and an event $A$ in the sample space $S$, let $X_A = I\{ A \}$. Then $E[X_A] = Pr \{ A \}$.
\end{lemma}

\subsection{The hiring problem}

HIRE-ASSISTANT($n$)
\begin{algorithmic}[1]
\State best = 0
\Comment candidate $0$ is a least-qualified dummy candidate
\For {$i = 1 \textbf { to } n$}
	\State interview candidate $i$
        \If {candidate $i$ is better than candidate $best$}
        	\State $best = i$
                \State hire candidate $i$
        \EndIf
\EndFor
\end{algorithmic}

\begin{lemma}
  Assuming that the candidates are presented in a random order, algorithm HIRE-ASSISTANT has a total hiring cost of $O(c_h \ln n)$.
\end{lemma}

Let $X$ be the random variable whose value equals the number of times we hire a new office assistant. Now we can compute $E[X]$:
\begin{eqnarray*}
  E[X]
  &=& E \left[ \sum_{i=1}^n X_i \right] \\
  &=& \sum_{i=1}^n E[X_i] \\
  &=& \sum_{i=1}^n 1/i \\
  &=& \ln n + O(1)
\end{eqnarray*}

\subsection{Probabilistic analysis and further uses of indicator random variables}

\subsubsection{The birthday paradox}

How many people must be in a room before there is a $50 \%$ chance that two of them were born on the same day of the year? \\

The event that $k$ people have distinct birthday is
\begin{equation*}
  B_k = \bigcap_{i=1}^k A_i,
\end{equation*}
where $A_i$ is the event that person $i$'s birthday is different from person $j$'s for all $j < i$. Since we can write $B_k = A_k \cap B_{k-1}$, we get
\begin{eqnarray*}
  Pr \{ B_k \} 
  &=& Pr \{ B_{k-1} \} Pr \{ A_k | B_{k-1} \} \\
  &=& Pr \{ B_{k-2} \} Pr \{ A_{k-1} | B_{k-2} \} Pr \{ A_{k} | B_{k-1} \} \\
  &\vdots& \\
  &=& Pr \{ B_{1} \} Pr \{ A_{2} | B_{1} \} Pr \{ A_{3} | B_{2} \} \cdots
      Pr \{ A_{k} | B_{k-1} \} \\
  &=& 1 \cdot \left( \frac {n-1}{n} \right) \left( \frac {n-2}{n} \right)
      \cdots \left( \frac {n-k+1}{n} \right) \\
  &=& 1 \cdot \left( 1 - \frac {1}{n} \right) \left( 1 - \frac {2}{n} \right)
      \cdots \left( 1 - \frac {k-1}{n} \right)
\end{eqnarray*}
Inequality $1 + x \le e^x$ gives us
\begin{eqnarray*}
  Pr \{ B_k \} 
  &\le& e^{-1/n} e^{-2/n} \cdots e^{-(k-1)/n} \\
  &=& e^{- \sum_{i=1}^{k-1} i/n} \\
  &=& e^{-k(k-1)/2n} \\
  &\le& 1/2
\end{eqnarray*}
when $-k(k-1)/2n \le \ln(1/2)$. we get $k \ge (1 + \sqrt {1 + (8 \ln 2)n})/2$. For $n = 365$, we must have $k \ge 23$.

\subsubsection{Balls and bins}

Consider the process of randomly tossing identical balls into $b$ bins, numbered $1, 2, \dots, b$. The tosses are independent, and on each toss the ball is equally likely to end up in any bin. \\

\emph{How many balls must one toss until every bin contains at least one ball?} Let us call a toss in which a ball falls into an empty bin a ``hit''. We want to know the expected number $n$ of tosses required to get $b$ hits. \\

The hits can be used to partition the $n$ tosses into stages. The $i$th stage consists of the tosses after the $(i-1)$st hit until the $i$th hit. Let $n_i$ denote the number of tosses in the $i$th stage. We get
\begin{equation*}
  E[n_i] = \frac {b}{b - i + 1}
\end{equation*}
By linearity of expectation,
\begin{eqnarray*}
  E[n]
  &=& E \left[ \sum_{i=1}^b n_i  \right] \\
  &=& \sum_{i=1}^b [n_i] \\
  &=& \sum_{i=1}^b \frac {b}{b-i+1} \\
  &=& \sum_{i=1}^b \frac {1}{i} \\
  &=& b( \ln b + O(1)).
\end{eqnarray*}
The problem is also known as the \textbf {coupon collector's problem}.

\subsubsection{Streaks}

Suppose you flip a fair coin $n$ times. What is the longest streak of consecutive heads that you expect to see? The answer is $\Theta (\lg n)$. \\

Let $A_{i,k}$ be the event that a streak of heads of length at least $k$ begins with the $i$th coin flip or, more precisely, the event that the k consecutive coin flips $i, i + 1, \dots, i + k -1$ yield only heads, where $1 \le k \le n$ and $1 \le i \le n - k + 1$. Since coin flips are mutually independent, for any given event $A_{ik}$, the probability that all $k$ flips are heads is
\begin{equation*}
  Pr \{ A_{ik} \} = 1 / 2^k.
\end{equation*}
For $k = 2 \lceil \lg n \rceil$,
\begin{eqnarray*}
  Pr \{ A_{i, 2 \lceil \lg n \rceil} \}
  &=& 1 / 2^{2 \lceil \lg n \rceil} \\
  &\le& 1 / 2^{2 \lg n} \\
  &=& 1 / n^2
\end{eqnarray*}
There are at most $n - 2 \lceil \lg n \rceil + 1$ positions where such a streak can begin. The probability that a streak of heads of length at least $2 \lceil \lg n \rceil$ begins anywhere is therefore
\begin{eqnarray*}
  Pr \left\{ \bigcup_{i=1}^{n - 2 \lceil \lg n \rceil + 1} A_{i,2 \lceil \lg n \rceil} \right\}
  &\le&  \sum_{i=1}^{n - 2 \lceil \lg n \rceil + 1} 1 / n^2 \\
  &<& \sum_{i=1}^n 1 / n^2 \\
  &=& 1/n,
\end{eqnarray*}
since Boole's inequality,
\begin{equation*}
  Pr \{ A_1 \cup A_2 \cup \cdots \} \le Pr \{ A_1 \} + Pr \{ A_2 \} + \cdots,
\end{equation*}
the probability of a union of events is at most the sum of the probabilities of the individual events. \\

By the definition of expected value,
\begin{eqnarray*}
  E[L]
  &=& \sum_{j=0}^{n} j Pr \{ L_j \} \\
  &=& \sum_{j=0}^{2 \lceil \lg n \rceil - 1} j Pr \{ L_j \}
      + \sum_{j = 2 \lceil \lg n \rceil - 1}^{n} j Pr \{ L_j \} \\
  &<& \sum_{j=0}^{2 \lceil \lg n \rceil - 1} (2 \lceil \lg n \rceil - 1)
      Pr \{ L_j \} + \sum_{j = 2 \lceil \lg n \rceil - 1}^{n} n Pr \{ L_j \} \\
  &=& 2 \lceil \lg n \rceil - 1 \sum_{j=0}^{2 \lceil \lg n \rceil - 1} 
      Pr \{ L_j \} + n \sum_{j = 2 \lceil \lg n \rceil - 1}^{n} Pr \{ L_j \} \\
  &<& 2 \lceil \lg n \rceil - 1 \cdot 1 + n \cdot (1/n) \\
  &=& O(\lg n)
\end{eqnarray*}
The chances that a streak of heads exceeds $r \lceil \lg n \rceil$ flips diminish quickly with $r$. For $r \ge 1$, the probability that a streak of $r \lceil \lg n \rceil$ heads starts in position $i$ is
\begin{eqnarray*}
  Pr \{ A_{i, r \lceil \lg n \rceil} \}
  &=& 1 / 2^{r \lceil \lg n \rceil} \\
  &\le& 1 / n^r
\end{eqnarray*}
Thus, the probability is at most $n / n^r = 1 / n^{r-1}$ that the longest streak is at least $r \lceil \lg n \rceil$. \\

We now prove a complementary lower bound: the expected length of the longest streak of heads in $n$ coin flips is $\Omega (\lg n)$. To prove this bound, we look for streaks of length $s$ by partitioning the $n$ flips into approximately $n/s$ groups of $s$ flips each. If we choose $s = \lfloor (\lg n)/2 \rfloor$, we can show that it is likely that at least one of these groups comes up all heads, and hence it is likely that the longest streak has length at least $s = \Omega (\lg n)$. We then show that the longest streak has expected length $\Omega (\lg n)$.
\begin{eqnarray*}
  Pr \{ A_{i, \lfloor (\lg n)/2 \rfloor} \}
  &=& 1 / 2^{\lfloor (\lg n)/2 \rfloor} \\
  &\ge& 1 / \sqrt n.
\end{eqnarray*}
The probability that a streak of heads of length at least $\lfloor (\lg n)/2 \rfloor$ does not begin in position $i$ is therefore at most $1 - 1 / \sqrt n$. Since the $\lfloor n / \lfloor (\lg n)/2 \rfloor \rfloor$ groups are formed from mutually exclusive, independent coin flips, the probability that every one of these groups fails to be a streak of length $\lfloor (\lg n)/2 \rfloor$ is at most
\begin{eqnarray*}
  (1 - 1 / \sqrt n)^{\lfloor n/ {\lfloor (\lg n)/2 \rfloor} \rfloor}
  &\le& (1 - 1 / \sqrt n)^{n/ {\lfloor (\lg n)/2 \rfloor} - 1} \\
  &\le& (1 - 1 / \sqrt n)^{2n/ {\lg n} - 1} \\
  &\le& e^{-(2n/ {\lg n} -1)/{\sqrt n}} \\
  &=& O(e^{- \lg n}) \\
  &=& O(1/n)
\end{eqnarray*}
For this argument, we used $(2n / {\lg n} - 1) / {\sqrt n} \ge \lg n$ for sufficiently large $n$. \\

Thus , the probability that the longest streak exceeds $\lfloor (\lg n)/2 \rfloor$ is
\begin{equation*}
  \sum_{j = \lfloor (\lg n)/2 \rfloor + 1}^{n} Pr \{ L_j \} \ge 1 - O(1/n)
\end{equation*}
We can now calculate a lower bound on the expected length of the longest streak:
\begin{eqnarray*}
  E[L]
  &=& \sum_{j=0}^{n} j Pr \{ L_j \} \\
  &=& \sum_{j=0}^{\lfloor (\lg n)/2 \rfloor} j Pr \{ L_j \}
      + \sum_{j = \lfloor (\lg n)/2 \rfloor + 1}^{n} j Pr \{ L_j \} \\
  &\ge& \sum_{j=0}^{\lfloor (\lg n)/2 \rfloor} 0 \cdot Pr \{ L_j \}
      + \sum_{j = \lfloor (\lg n)/2 \rfloor + 1}^{n} 
      \lfloor (\lg n)/2 \rfloor Pr \{ L_j \} \\
  &=& 0 \cdot \sum_{j=0}^{\lfloor (\lg n)/2 \rfloor} \cdot Pr \{ L_j \}
      + \lfloor (\lg n)/2 \rfloor \sum_{j = \lfloor (\lg n)/2 \rfloor + 1}^{n}
      Pr \{ L_j \} \\
  &\ge& 0 + \lfloor (\lg n)/2 \rfloor (1 - O(1/n)) \\
  &=& \Omega (\lg n).
\end{eqnarray*}
As with the birthday paradox, we can obtain a simpler but approximate analysis using indicator random variables. We let $X_{ik} = I \{ A_{ik} \}$ be the indicator random variable associated with a streak of heads of length at least $k$ beginning with the $i$th coin flip. To count the total number of such streaks, we define
\begin{equation*}
  X = \sum_{i=1}^{n-k+1} X_{ik}.
\end{equation*}
Taking expectations and using linearity of expectation, we have
\begin{eqnarray*}
  E[X]
  &=& E \left[ \sum_{i=1}^{n-k+1} X_{ik} \right] \\
  &=& \sum_{i=1}^{n-k+1} E[X_{ik}] \\
  &=& \sum_{i=1}^{n-k+1} Pr \{ X_{ik} \} \\
  &=& \sum_{i=1}^{n-k+1} 1 / 2^k \\
  &=& \frac {n-k+1}{2^k}
\end{eqnarray*}
By plugging in various values for $k$, we can calculate the expected number of streaks of length $k$. If $k = c \lg n$, for some positive constant $c$, we obtain
\begin{eqnarray*}
  E[X]
  &=& \frac {n - c \lg n + 1}{2^{c \lg n}} \\
  &=& \frac {n - c \lg n + 1}{n^c} \\
  &=& \frac {1}{n^c - 1} - \frac {(c \lg n - 1)/n}{n^{c-1}} \\
  &=& \Theta(1 / n^{c-1}).
\end{eqnarray*}

\section{Heapsort}

Like merge sort, but unlike insertion sort, heapsort's running time is $O(n \lg n)$. Like insertion sort, but unlike merge sort, heapsort sorts in place: only a constant number of array elements are stored outside the input array at any time.

\subsection{Heaps}

The \textbf {(binary) heap} data structure is an array object that we can view as a nearly complete binary tree. \\

PARENT($i$)
\begin{algorithmic}[1]
\State \textbf {return} $\lfloor i/2 \rfloor$
\end{algorithmic}

LEFT($i$)
\begin{algorithmic}[1]
\State \textbf {return} $2i$
\end{algorithmic}

RIGHT($i$)
\begin{algorithmic}[1]
\State \textbf {return} $2i+1$
\end{algorithmic}

There are two kinds of binary heaps: max-heaps and min-heaps. In both kinds, the values in the nodes satisfy a {\bf heap property}, the specifics of which depends on the kind of heap. In a {\bf max-heap}, the {\bf max-heap property} is that for every node $i$ other than the root,
\begin{equation*}
  A[\text{PARENT}(i)] \ge A[i],
\end{equation*}
that is, the value of a node is at most the value of its parent. \\

Viewing a heap as a tree, we define the {\bf height} of a node in a heap to be the number of edges on the longest simple downward path from the node to a leaf, and we define the height of the heap to be the height of its root.

\subsection{Maintaining the heap property}

MAX-HEAPIFY 's inputs are an array $A$ and an index $i$ into the array. When it is called, MAX-HEAPIFY assumes that the binary trees rooted at LEFT($i$) and RIGHT($i$) are max-heaps, but that $A[i]$ might be smaller than its children, thus violating he max-heap property. MAX-HEAPIFY lets the value at $A[i]$ ``float down'' in the max-heap so that the subtree rooted an index $i$ obeys the max-heap property. \\

 MAX-HEAPIFY($A,i$)
\begin{algorithmic}[1]
\State $l = \text {LEFT}(i)$
\State $r = \text {RIGHT}(i)$
\If {$l \le A.\text{heap-size}$ and $A[l] > A[i]$}
	\State $largest = l$
\Else
	\State $largest = i$
\EndIf
\If {$r \le A.\text{heap-size}$ and $A[r] > A[largest]$}
	\State $largest = r$
\EndIf
\If {$largest \neq i$}
	\State exchange $A[i]$ with $A[largest]$
        \State MAX-HEAPIFY($A, largest$)
\EndIf
\end{algorithmic}

We can describe the running time of MAX-HEAPIFY by recurrence
\begin{equation*}
  T(n) \le T(2n/3) + \Theta(1).
\end{equation*}
Worst case occurs when the bottom level of the tree is exactly half full. The solution to this recurrence is $T(n) = O(\lg n)$. Alternatively, we can characterize the running time of MAX-HEAPIFY on a node of height $h$ as $O(h)$.

\subsection{Building a heap}

BUILD-MAX-HEAP(A)
\begin{algorithmic}[1]
\State $A.\text{heap-size} = A.length$
\For {$i = \lfloor A.length/2 \rfloor \text {{ \bf downto} } 1$}
	\State MAX-HEAPIFY($A, i$)
\EndFor
\end{algorithmic}

The time required by MAX-HEAPIFY when called on a node of height $h$ is $O(h)$, so we can express the total cost of BUILD-MAX-HEAP as
\begin{eqnarray*}
  \sum_{h=0}^{\lfloor \lg n \rfloor} \lceil \frac {n}{2^{h+1}} \rceil O(h)
  &=& O(n \sum_{h=0}^{\lfloor \lg n \rfloor} \frac {h}{2^h}) \\
  &=& O(n \sum_{h=0}^{\infty} \frac {h}{2^h}) \\
  &=& O(2n) \\
  &=& O(n)
\end{eqnarray*}

\subsection{The heapsort algorithm}

HEAPSORT(A)
\begin{algorithmic}[1]
\State BUILD-MAX-HEAP(A)
\For {$i = A.length \text {{ \bf downto} } 2$}
	\State exchange $A[1]$ with $A[i]$
        \State $A.\text{heap-size} = A.\text{heap-size} - 1$
	\State MAX-HEAPIFY($A, 1$)
\EndFor
\end{algorithmic}

The HEAPSORT procedure takes time $O(n \lg n)$, since the call to BUILD-MAX-HEAP takes time O(n) and each of the $n-1$ calls to MAX-HEAPIFY takes time $O(\lg n)$.

\subsection{Priority queues}

HEAP-MAXIMUM(A)
\begin{algorithmic}[1]
\State \textbf {return} $A[1]$
\end{algorithmic}

HEAP-EXTRACT-MAX(A)
\begin{algorithmic}[1]
\If {$A.\text{heap-size} < 1$}
	\State \textbf {error} ``heap underflow''
\EndIf
\State $max$ = A[1]
\State $A[1] = A[A.\text{heap-size}]$
\State $A.\text{heap-size} = A.\text{heap-size} - 1$
\State MAX-HEAPIFY($A,1$)
\State \textbf {return} $max$
\end{algorithmic}

The running time of HEAP-EXTRACT-MAX is $O(\lg n)$, since it performs only a constant amount of work on top of the $O(\lg n)$ time for MAX-HEAPIFY. \\

HEAP-INCREASE-KEY($A, i, key$)
\begin{algorithmic}[1]
\If {$key < A[i]$}
	\State \textbf {error} ``new key is smaller than current key''
\EndIf
\State $A[i] = key$
\While {$i > 1$ and $A[\text {PARENT}(i)] < A[i]$}
	\State exchange $A[i]$ with $A[\text {PARENT}(i)]$
        \State $i = \text {PARENT}(i)$
\EndWhile
\end{algorithmic}

The running time of HEAP-INCREASE-KEY on an $n-$element heap is $O(\lg n)$. \\

MAX-HEAP-INSERT($A, key$)
\begin{algorithmic}[1]
\State $A.\text{heap-size} = A.\text{heap-size} + 1$
\State $A[A.\text{heap-size}] = -\infty$
\State HEAP-INCREASE-KEY($A, A.\text{heap-size},key$)
\end{algorithmic}

The running time of MAX-HEAP-INSERT on an $n-$element heap is $O(\lg n)$. \\

In summary, a heap can support any priority-queue operation on a set of size $n$ in $O(\lg n)$ time.

\section{Quicksort}

\subsection{Description of quicksort}

QUICKSORT($A, p, r$)
\begin{algorithmic}[1]
\If {$p < r$}
	\State $q = \text {PARTITION}(A, p, r)$
        \State QUICKSORT($A, p, q-1$)
        \State QUICKSORT($A, q+1, r$)
\EndIf
\end{algorithmic}

To sort an array $A$, the initial call is QUICKSORT($A, 1, A.length$). \\

PARTITION($A, p, r$)
\begin{algorithmic}[1]
\State $x = A[r]$
\State $i = p - 1$
\For {$j = p \textbf { to } r-1$}
	\If {$A[j] \le x$}
        	\State $i = i + 1$
                \State exchange $A[i]$ with $A[j]$
        \EndIf
\EndFor
\State exchange $A[i+1]$ with $A[r]$
\State \textbf{return } $i+1$
\end{algorithmic}

\subsection{Performance of quicksort}

\begin{itemize}
  \item \textbf{Worst-case partitioning}
    \begin{eqnarray*}
      T(n)
      &=& T(n-1) + T(0) + \Theta(n) \\
      &=& T(n-1) + \Theta(n).
    \end{eqnarray*}
    We get $T(n) = \Theta (n^2)$. This occurs when the input array is already completely sorted.
  \item \textbf {Best-case partitioning}
    \begin{eqnarray*}
      T(n)
      &=& 2T(n/2) + \Theta(n)
    \end{eqnarray*}
    We get $T(n) = \Theta (n \lg n)$.
  \item \textbf {Balanced partitioning}
    \begin{eqnarray*}
      T(n)
      &=& T(9n/10) + T(n/10) + cn
    \end{eqnarray*}    
    We get $T(n) = \Theta (n \lg n)$.
\end{itemize}

\subsection{A randomized version of quicksort}

RANDOMIZED-PARTITION($A, p, r$)
\begin{algorithmic}[1]
\State $i = \text{RANDOM}(p,r)$
\State exchange $A[r]$ with $A[i]$
\State \textbf{return } PARTITION($A, p, r$)
\end{algorithmic}

RANDOMIZED-QUICKSORT($A, p, r$)
\begin{algorithmic}[1]
\If {$p < r$}
	\State $q = \text {RANDOMIZED-PARTITION}(A, p, r)$
        \State RANDOMIZED-QUICKSORT($A, p, q-1$)
        \State RANDOMIZED-QUICKSORT($A, q+1, r$)
\EndIf
\end{algorithmic}

The expected running time of RANDOMIZED-QUICKSORT is $O(n \lg n)$.

\section{Sorting in Linear Time}

\subsection{Lower bounds for sorting}

\begin{theorem}
  Any comparison sort algorithm requires $\Omega (n \lg n)$ comparisons in the worst case.
\end{theorem}

\begin{corollary}
  Heapsort and merge sort are asymptotically optimal comparison sorts.
\end{corollary}

\subsection{Counting sort}

COUNTING-SORT($A, B, k$)
\begin{algorithmic}[1]
\State let $C[0..k]$ be a new array
\For {$i = 0 \textbf { to } k$}
	\State $C[i] = 0$
\EndFor
\For {$j = 1 \textbf { to } A.length$}
	\State $C[A[j]] = C[A[j]] + 1$
\EndFor
\State // $C[i]$ now contains the number of elements equal to $i$.
\For {i = 1 \textbf { to } k}
	\State $C[i] = C[i] + C[i-1]$
\EndFor
\State // $C[i]$ now contains the number of elements less than or equal to $i$.
\For {j = A.length \textbf { downto } 1}
	\State $B[C[A[j]]] = A[j]$
        \State $C[A[j]] = C[A[j]] - 1$
\EndFor
\end{algorithmic}

\subsection{Radix sort}

RADIX-SORT($A, d$)
\begin{algorithmic}[1]
\For {$i = 1 \textbf { to } d$}
	\State use a stable sort to sort array $A$ on digit $i$
\EndFor
\end{algorithmic}

\begin{lemma}
  Given $n$ $d-$digit numbers in which each digit can take on up to $k$ possible values, RADIX-SORT correctly sorts these numbers in $\Theta(d(n+k))$ time if the stable sort it uses takes $\Theta (n+k)$ time.
\end{lemma}

When $d$ is constant and $k = O(n)$, we can make radix sort run in linear time. More generally, we have some flexibility in how to break each key into digits.

\begin{lemma}
  Given $n$ $b$-bit numbers and any positive integer $r \le b$, RADIX-SORT correctly sorts these numbers in $\Theta ((b/r)(n + 2^r))$ time.
\end{lemma}

For a value $r \le b$, we view each key as having $d = \lceil b/r \rceil$ digits of $r$ bits each. Each digit is an integer in the range $0$ to $2^r-1$, so that we can use counting sort with $k = 2^r -1$.

\subsection{Bucket sort}

\textbf {Bucket sort} assumes that the input is drawn from a uniform distribution and has an average-case running time of $O(n)$. Bucket sort divides the interval $[0,1)$ into $n$ equal-sized sub-intervals, or \textbf {buckets}, and then distributes the $n$ input numbers into the buckets. \\

Our code for bucket sort assumes that the input is an $n$-element array $A$ and that each element $A[i]$ in the array satisfies $0 \le A[i] < 1$. The code requires an auxiliary array $B[0...n-1]$ of linked lists (buckets) and assumes that there is a mechanism for maintaining such lists. \\

BUCKET-SORT($A$)
\begin{algorithmic}[1]
\State let $B[0..n-1]$ be a new array
\State $n = A.length$
\For {$i = 0 \textbf { to } n-1$}
	\State make $B[i]$ an empty list
\EndFor
\For {$i = 1 \textbf { to } n$}
	\State insert $A[i]$ into list $B[\lfloor nA[i] \rfloor ]$
\EndFor
\For {$i = 0 \textbf { to } n-1$}
	\State sort list $B[i]$ with insertion sort
\EndFor
\State concatenate the lists $B[0], B[1], \dots, B[n-1]$ together in order
\end{algorithmic}

Since insertion sort runs in quadratic time, the running time of bucket sort is
\begin{equation*}
  T(n) = \Theta(n) + \sum_{i=0}^{n-1} O(n_i^2).
\end{equation*}
We now analyze the average-case running time of bucket sort, by computing the expected value of the running time, where we take the expectation over the input distribution. We have
\begin{eqnarray*}
  E[T(n)]
  &=& E \left[ \Theta (n) + \sum_{i=0}^{n-1} O(n_i)^2 \right] \\
  &=& \Theta (n) + \sum_{i=0}^{n-1} E \left[ O(n_i)^2 \right] \\
  &=& \Theta (n) + \sum_{i=0}^{n-1} E \left( O[n_i]^2 \right) \\
  &=& \Theta (n) + \sum_{i=0}^{n-1} (2 - 1/n) \\
  &=& \Theta (n)
\end{eqnarray*}

\section{Medians and Order Statistics}

The $i$th \textbf {order statistic} of a set of $n$ elements is the $i$th smallest element.

\subsection{Selection in expected linear time}

RANDOMIZED-SELECT($A, p, r, i$)
\begin{algorithmic}[1]
\If {$p == r$}
	\State \textbf {return } $A[p]$
\EndIf
\State $q = \text{RANDOMIZED-PARTITION}(A, p, r)$
\State $k = q - p + 1$
\If {$i == k$}
\Comment the pivot value is the answer
	\State \textbf {return} $A[q]$
\ElsIf {$i < k$}
	\State \textbf {return} RANDOMIZED-SELECT($A, p, q-1, i$)
\Else
	\State \textbf {return} RANDOMIZED-SELECT($A, q+1, r, i-k$)
\EndIf
\end{algorithmic}

\subsection{Selection in worst-case linear time}

Like RANDOMIZED-SELECT, the algorithm SELECT finds the desired element by recursively partitioning the input array. Here, however, we guarantee a good split upon partitioning the array. SELECT uses the deterministic partitioning algorithm PARTITION from quicksort, but modified to take the element to partition around as an input parameter. \\

The SELECT algorithm determines the $i$th smallest of an input array of $n>1$ distinct elements by executing the following steps. (If $n = 1$, then SELECT merely returns its only input value as the $i$th smallest.)

\begin{enumerate}
  \item Divide the $n$ elements of the input array into $\lfloor n/5 \rfloor$ groups of $5$ elements each and at most one group made up of remaining $n \mod 5$ elements.
  \item Find the median of each of the $\lceil n/5 \rceil$ groups by first insertion-sorting the elements of each group (of which there are at most $5$) and then picking the median from the sorted list of group elements.
  \item Use SELECT recursively to find the median $x$ of the $\lceil n/5 \rceil$ medians found in step $2$. (If there are an even number of medians, then by our convention, $x$ is the lower median.)
  \item Partition the input array around the median-of-medians $x$ using the modified version of PARTITION. Let $k$ be one more than the number of elements on low side of the partition, so that $x$ is the $k$th smallest element and there are $n-k$ elements on the high side of the partition.
  \item If $i = k$, then return $x$. Otherwise, use SELECT recursively to find the $i$th smallest element on the low side if $i < k$, or the $(i-k)$th smallest element on the high side if $i>k$.
\end{enumerate}

\section{Elementary Data Structure}

\begin{enumerate}
  \item Stacks and queues
  \item Linked lists
  \item Implementing pointers and objects
  \item Representing rooted trees
\end{enumerate}

\section{Hash Tables}

\subsection{Direct-address tables}

DIRECT-ADDRESS-SEARCH($T, k$)
\begin{algorithmic}[1]
\State \textbf {return} $T[k]$
\end{algorithmic}

DIRECT-ADDRESS-INSERT($T, x$)
\begin{algorithmic}[1]
\State $T[x.key] = x$
\end{algorithmic}

DIRECT-ADDRESS-DELETE($T, x$)
\begin{algorithmic}[1]
\State $T[x.key] = NIL$
\end{algorithmic}

Each of these operations takes only $O(1)$ time.

\subsection{Hash tables}

With hashing, an element with key $k$ is stored in slot $h(k)$; that is, we use a \textbf {hash function} $h$ to compute the slot from the key $k$. Here, $h$ maps the universe $U$ of keys into the slots of a \textbf {hash table} $T[0..m-1]$:
\begin{equation*}
  h: U \rightarrow \{ 0,1, \dots, m-1 \},
\end{equation*}
where the size $m$ of the hash table is typically much less than $|U|$.

\subsubsection*{Collision resolution by chaining}

In chaining, we place all elements that hash to the same slot into the same linked list.

CHAINED-HASH-INSERT($T, x$)
\begin{algorithmic}[1]
\State insert $x$ at the head of list $T[h(x.key)]$
\end{algorithmic}

CHAINED-HASH-SEARCH($T, k$)
\begin{algorithmic}[1]
\State search for an element with key $k$ in list $T[h(k)]$
\end{algorithmic}

CHAINED-HASH-DELETE($T, x$)
\begin{algorithmic}[1]
\State delete $x$ from the list $T[h(x.key)]$
\end{algorithmic}

\subsubsection*{Analysis of hashing with chaining}

Given a hash table $T$ with $m$ slots that stores $n$ elements, we define the \textbf {load factor} $\alpha$ for $T$ as $n/m$, that is, the average number of elements stored in a chain. Load factor can be less than, equal to, or greater than 1. \\

The average-case performance of hashing depends on how well the hash function $h$ distributes the set of keys to be stored among the $m$ slots, on the average. Now we shall assume that any given element is equally likely to hash into any of the $m$ slots, independently of where any other element has hashed to. We call this the assumption of \textbf {simple uniform hashing}.

\begin{theorem}
  In a hash table in which collisions are resolved by chaining, an unsuccessful search takes average-case time $\Theta (1 + \alpha)$, under the assumption of simple uniform hashing.
\end{theorem}

\begin{theorem}
  In a hash table in which collisions are resolved by chaining, a successful search takes average-case time $\Theta (1 + \alpha)$, under the assumption of simple uniform hashing.
\end{theorem}

\subsection{Hash functions}

A good hash function satisfies (approximately) the assumption of simple uniform hashing: each key is equally likely to hash to any of the $m$ slots, independently of where any other key has hashed to. Unfortunately, we typically have no way to check this condition, since we rarely know the probability distribution from which the keys are drawn. Moreover, the keys might not be drawn independently.

\subsubsection*{Interpreting keys as natural numbers}

Most hash functions assume that the universe of keys is the set $\mathbb {N} = \{0,1,2,\dots \}$ of natural numbers.

\subsubsection{The division method}

In the \textbf {division method} for creating hash functions, we map a key $k$ into one of $m$ slots by taking the remainder of $k$ divided by $m$. That is, the hash function is
\begin{equation*}
  h(k) = k \mod m.
\end{equation*}
A prime not too close to an exact power of $2$ is often a good choice for $m$.

\subsubsection{The multiplication method}

The \textbf {multiplication method} for creating hash functions operates in two steps. First, we multiply the key $k$ by a constant $A$ in the range $0 < A < 1$ and extract the fractional part of $kA$. Then, we multiply this value by $m$ and take the floor of the result. In short, the hash function is
\begin{equation*}
  h(k) = \lfloor m (kA \mod 1) \rfloor,
\end{equation*}
where ``$kA \mod 1$'' means the fractional part of $kA$, that is, $kA - \lfloor kA \rfloor$. \\

An advantage of the multiplication method is that the value of m is not critical. We typically choose it to be a power of $2$ ($m = 2^p$ for some integer $p$), since we can then easily implement the function on most computers as follows. Suppose that the word size of the machine is $w$ bits and that $k$ fits into a single word. We restrict $A$ to be a fraction of the form $s/2^w$, where $s$ is an integer in the range $0 < s < 2^w$. We first multiply $k$ by the $w$-bit integer $s = A \cdot 2^w$. The result is a $2w$-bit value $r_12^w+r_0$, where $r_1$ is the high-order word of the product and $r_0$ is the low-order word of the product. The desired $p$-bit hash value consists of the $p$ most significant bits of $r_0$.

\subsubsection{Universal hashing}

If a malicious adversary chooses the keys to be hashed by some fixed hash function, then the adversary can choose $n$ keys that all hash to the same slot, yielding an average retrieval time of $\Theta(n)$. Any fixed hash function is vulnerable to such terrible worst-case behavior; the only effective way to improve the situation is to choose the hash function randomly in a way that is independent of the keys that are actually going to be stored. This approach, called \textbf {universal hashing}, can yield provably good performance on average, no matter which keys the adversary chooses. \\

In universal hashing, at the beginning of execution we select the hash function at random from a carefully designed class of functions. Because we randomly select the hash function, the algorithm can behave differently on each execution, even for the same input, guaranteeing good average-case performance for any input. \\

Let $\mathcal {H}$ be a finite collection of hash functions that map a given universe $U$ of keys into the range $\{ 0,1,\dots,m-1 \}$. Such a collection is said to be \textbf {universal} if for each pair of distinct keys $k, l \in U$, the number of hash functions $h \in \mathcal {H}$ for which $h(k) = h(l)$ is at most $|\mathcal {H}| / m$. In other words, with a hash function randomly chosen from $\mathcal {H}$, the chance of a collision between distinct keys $k$ and $l$ is no more than the chance $1/m$ of a collision if $h(k)$ and $h(l)$ were randomly and independently chosen from the set $\{ 0,1,\dots, m-1\}$. \\

Recall that $n_i$ denotes the length of list $T[i]$.

\begin{theorem}
  Suppose that a hash function $h$ is chosen randomly from a universal collection of hash functions and has been used to hash $n$ keys into a table $T$ of size $m$, using chaining to resolve collisions. If key $k$ is not in the table, then the expected length $E[n_{h(k)}]$ of the list that key $k$ hashes to is at most the load factor $\alpha = n/m$. If key $k$ is in the table, then the expected length $E[n_{h(k)}]$ of the list containing key $k$ is at most $1 + \alpha$.
\end{theorem}

\begin{corollary}
  Using universal hashing and collision resolution by chaining in an initially empty table with $m$ slots, it takes expected time $\Theta (n)$ to handle any sequence of $n$ INSERT, SEARCH, and DELETE operations containing $O(m)$ INSERT operations.
\end{corollary}

\subsection{Open addressing}

In \textbf {open addressing}, all elements occupy the hash table itself. That is, each table entry contains either an element of the dynamic set or NIL. \\

To perform insertion using open addressing, we successively examine, or \textbf {probe}, the hash table until we find an empty slot in which to put the key. To determine which slot to probe, we extend the hash function to include the probe number (starting from 0) as a second input. Thus, the hash function becomes
\begin{equation*}
  h: U \times \{ 0,1,\dots,m-1 \} \rightarrow \{ 0,1,\dots,m-1 \}.
\end{equation*}
With open addressing, we require that for every key $k$, the \textbf {probe sequence}
\begin{equation*}
  <h(k,0), h(k,1), \dots, h(k, m-1)>
\end{equation*}
be a permutation of $<0,1,\dots,m-1>$, so that every hash-table position is eventually considered as a slot for a new key as the table fills up. \\

HASH-INSERT($T, k$)
\begin{algorithmic}[1]
\State i = 0
\Repeat
	\State $j = h(k,i)$
        \If {$T[j] == \text {NIL}$}
        	\State {$T[j] = k$}
                \State \textbf {return} $j$
        \Else
        	\State $i = i + 1$
        \EndIf
\Until {$i == m$}
\State \textbf {error} ``hash table overflow''
\end{algorithmic}

HASH-SEARCH($T, k$)
\begin{algorithmic}[1]
\State i = 0
\Repeat
	\State $j = h(k,i)$
        \If {$T[j] == k$}
                \State \textbf {return} $j$
        \EndIf
        \State $i = i + 1$
\Until {$T[j] == \text {NIL or } i == m$}
\State \textbf {return} NIL
\end{algorithmic}

\subsubsection*{Linear probing}

Given an ordinary hash function $h': U \rightarrow \{ 0,1,\dots,m-1 \}$, which we refer to as an \textbf {auxiliary hash function}, the method of \textbf {linear probing} uses the hash function
\begin{equation*}
  h(k,i) = (h'(k) + i) \mod m
\end{equation*}
for $i = 0,1,\dots,m-1$. Linear probing is easy to implement, but it suffers from a problem known as \textbf {primary clustering}. Long runs of occupied slots build up, increasing the average search time. Clusters arise because an empty slot preceded by $i$ full slots get filled next with probability $(i+1)/m$. Long runs of occupied slots tend to get longer, and the average search time increases.

\subsubsection*{Quadratic probing}

\textbf {Quadratic probing} uses a hash function of the form
\begin{equation*}
  h(k,i) = (h'(k) + c_1 i + c_2 i^2) \mod m,
\end{equation*}
where $h'$ is an auxiliary hash function, $c_1$ and $c_2$ are positive auxiliary constants and $i = 0,1,\dots,m-1$. This methods works much better than linear probing, but to make full use of the hash table, the values of $c_1, c_2$ and $m$ are constrained. Also, if two keys have the same initial probe position, then their probe sequences are the same. This property leads to a milder from of clustering, called \textbf {secondary clustering}.

\subsubsection*{Double hashing}

Double hashing offers one of the best methods available for open addressing because the permutations produced have many of the characteristics of randomly chosen permutations. \textbf {Double hashing} uses a hash function of the form
\begin{equation*}
  h(k,i) = (h_1(k) + ih_2(k)) \mod m,
\end{equation*}
where both $h_1$ and $h_2$ are auxiliary hash functions.

\subsubsection*{Analysis of open-address hashing}

\begin{theorem}
  Given an open-address hash table with load factor $\alpha =n/m < 1$, the expected number of probes in an unsuccessful search is at most $1/(1-\alpha)$, assuming uniform hashing.
\end{theorem}

\begin{corollary}
  Inserting an element into an open-address hash table with load factor $\alpha$ requires at most $1/(1-\alpha)$ probes on average, assuming uniform hashing.
\end{corollary}

\begin{theorem}
  Given an open-address hash table with load factor $\alpha < 1$, the expected number of probes in a successful search is at most
  \begin{equation*}
    \frac {1}{\alpha} \ln \frac {1}{1 - \alpha},
  \end{equation*}
  assuming uniform hashing and assuming that each key in the table is equally likely to be searched for.
\end{theorem}

\subsection{Perfect hashing}

Hashing can provide excellent worst-case performance when the set of keys is \textbf {static}: once the keys are stored in the table, the set of keys never changes. We call a hashing technique \textbf {perfect hashing} if $O(1)$ memory accesses are required to perform a search in the worst case. \\

To create a perfect hashing scheme, we use two levels of hashing, with universal hashing at each level.

\section{Binary Search Trees}

\subsection{What is a binary search tree}

The keys in a binary search tree are always stored in such a way as to satisfy the \textbf {binary-search-tree property}:
\begin{quote}
  Let $x$ be a node in a binary search tree. If $y$ is a node in the left subtree of $x$, then $y.key \le x.key$. If $y$ is a node in the right subtree of $x$, then $y.key \ge x.key$.
\end{quote}
\textbf {Inorder tree walk} prints the key of the root of a subtree between printing the values in its left subtree and printing those in its right subtree. Similarly, a \textbf {preorder tree walk} prints the root before the values in either subtree, and a \textbf {postorder tree walk} prints the root after the values in its subtrees. \\

INORDER-TREE-WALK($x$)
\begin{algorithmic}[1]
\If {$x \neq \text {NIL}$}
\State INORDER-TREE-WALK($x.\text{left}$)
\State print $x.\text{key}$
\State INORDER-TREE-WALK($x.\text{right}$)
\EndIf
\end{algorithmic}

\subsection{Querying a binary search tree}

\subsubsection*{Searching}

TREE-SEARCH($x, k$)
\begin{algorithmic}[1]
\If {$x == \text {NIL}$ or $k == x.\text{key}$}
	\State \textbf {return} $x$
\EndIf
\If {$k < x.\text{key}$}
	\State \textbf {return} TREE-SEARCH($x.\text{left}, k$)
\Else
	\State \textbf {return} TREE-SEARCH($x.\text{right}, k$)
\EndIf
\end{algorithmic}

ITERATIVE-TREE-SEARCH($x, k$)
\begin{algorithmic}[1]
\While {$x \neq \text {NIL}$ and $x \neq x.\text{key}$}
	\If {$k < x.\text{key}$}
		\State $x = x.\text{left}$
        \Else
		\State $x = x.\text{right}$
	\EndIf
\EndWhile
\State \textbf {return} $x$
\end{algorithmic}

TREE-MINIMUM($x$)
\begin{algorithmic}[1]
\While {$x.\text{left} \neq \text {NIL}$}
	\State $x = x.\text{left}$
\EndWhile
\State \textbf {return} $x$
\end{algorithmic}

TREE-MAXIMUM($x$)
\begin{algorithmic}[1]
\While {$x.\text{right} \neq \text {NIL}$}
	\State $x = x.\text{right}$
\EndWhile
\State \textbf {return} $x$
\end{algorithmic}

TREE-SUCCESSOR($x$)
\begin{algorithmic}[1]
\If {$x.\text{right} \neq \text {NIL}$}
	\State \textbf {return} TREE-MINIMUM($x.\text{right}$)
\EndIf
\State $y = x.p$
\While {$y \neq \text {NIL}$ and $x == y.\text{right}$}
	\State $x = y$
        \State $y = y.p$
\EndWhile
\State \textbf {return} $y$
\end{algorithmic}

\begin{theorem}
  We can implement the dynamic-set operations SEARCH, MINIMUM, MAXIMUM, SUCCESSOR, and PREDECESSOR so that each one runs in $O(h)$ time on a binary search tree of height $h$.
\end{theorem}

\subsection{Insertion and deletion}

\subsubsection*{Insertion}

TREE-INSERT($T,z$)
\begin{algorithmic}[1]
\State $y = \text {NIL}$
\State $x = T.\text{root}$
\While {$x \neq \text {NIL}$}
	\State $y = x$
        \If {$z.\text{key} < x.\text{key}$}
        	\State $x = x.\text{left}$
        \Else
        	\State $x = x.\text{right}$
        \EndIf
\EndWhile
\State $z.p = y$
\If {$y == \text {NIL}$}
	\State $T.\text{root} = z$
        \Comment tree $T$ was empty
\ElsIf {$z.\text{key} < y.\text{key}$}
	\State $y.\text{left} = z$
\Else
	\State $y.\text{right} = z$
\EndIf
\end{algorithmic}

\subsubsection{Deletion}

TRANSPLANT replaces one subtree ($u$) as a child of its parent ($u.p$) with another subtree ($v$). \\

TRANSPLANT($T,u,v$)
\begin{algorithmic}[1]
\If {$u.p == \text {NIL}$}
	\State $T.\text{root} = v$
\ElsIf {$u == u.p.\text{left}$}
	\State $u.p.\text{left} = v$
\Else
	\State $u.p.\text{right} = v$
\EndIf
\If {$v \neq \text {NIL}$}
	\State $v.p = u.p$
\EndIf
\end{algorithmic}

Deletion: Replace $z$ with its successor $y$. Note that when $z$ has both left and right subtrees, then its successor $y$ does not have a left subtree. \\

TREE-DELETE($T,z$)
\begin{algorithmic}[1]
\If {$z.\text{left} == \text {NIL}$}
	\State TRANSPLANT($T,z,z.\text{right}$)
\ElsIf {$z.\text{right} == \text {NIL}$}
	\State TRANSPLANT($T,z,z.\text{left}$)
\Else
	\State $y = \text {TREE-MINIMUM}(z.\text{right})$
        \If {$y.p \neq z$}
		\State TRANSPLANT($T,y,y.\text{right}$)
                \State $y.\text{right} = z.\text{right}$
                \State $y.\text{right}.p = y$
        \EndIf
        \State TRANSPLANT($T,z,y$)
        \State $y.\text{left} = z.\text{left}$
        \State $y.\text{left}.p = y$
\EndIf
\end{algorithmic}

\begin{theorem}
  We can implement the dynamic-set operations INSERT and DELETE so that each one runs in $O(h)$ time on a binary search tree of height $h$.
\end{theorem}

\subsection{Randomly built binary search tree}

A \textbf {randomly built binary search tree} on $n$ keys is one that arises from inserting the keys in random order into an initially empty tree, where each of the $n!$ permutations of the input keys is equally likely. 

\begin{theorem}
  The expected height of a randomly built binary search tree on $n$ distinct keys is $O(\lg n)$.
\end{theorem}

\section{Red-Black Tree}

Red-black trees are one of many search-tree schemes that are ``balanced'' in order to guarantee that basic dynamic-set operations take $O(\lg n)$ time in the worst case.

\subsection{Properties of red-black trees}

A \textbf {red-black tree} is a binary search tree with one extra bit of storage per node: its \textbf {color}, which can be either RED or BLACK. By constraining the node colors on any simple path from the root to a leaf, red-black trees ensure that no such path is more than twice as long as any other, so that the tree is approximately \textbf {balanced}. \\

A red-black tree is a binary tree that satisfies the following \textbf {red-black properties}:
\begin{enumerate}
  \item Every node is either red or black.
  \item The root is black.
  \item Every leaf (NIL) is black.
  \item Of a node is red, then both its children are black.
  \item For each node, all simple paths from the node to descendant leaves contain the same number of black nodes.
\end{enumerate}

We call the number of black nodes on any simple path from, but not including, a node $x$ down to a leaf the \textbf {black-height} of the node, denoted $bh(x)$. We define the black-height of a red-black tree to be the black-height of its root.

\begin{lemma}
  A red-black tree with $n$ internal nodes has height at most $2 \lg (n+1)$.
\end{lemma}

As an immediate consequence of this lemma, we can implement the dynamic-set operations SEARCH, MINIMUM, MAXIMUM, SUCCESSOR, and PREDECESSOR in $O(\lg n)$ time on red-black tree.

\subsection{Rotations}

We change the pointer structure through \textbf {rotation}, which is a local operation in a search tree that preserves the binary-search-tree property. \\

The pseudocode for LEFT-ROTATE assumes that $x.right \neq T.nil$ and that root's parent is $T.nil$. \\

LEFT-ROTATE($T,x$)
\begin{algorithmic}[1]
\State $y = x.\text{right}$
\Comment set $y$
\State $x.\text{right} = y.\text{left}$
\Comment turn $y$'s left subtree into $x$'s right subtree
\If {$y.\text{left} \neq T.\text{nil}$}
	\State $y.\text{left}.p = x$
\EndIf
\State $y.p = x.p$
\Comment link $x$'s parent to $y$
\If {$x.p == T.\text{nil}$}
	\State $T.\text{root} = y$
\ElsIf {$x == x.p.\text{left}$}
	\State $x.p.\text{left} = y$
\Else
	\State $x.p.\text{right} = y$
\EndIf
\State $y.\text{left} = x$
\Comment put $x$ on $y$'s left
\State $x.p = y$
\end{algorithmic}

Both LEFT-ROTATE and RIGHT-ROTATE run in $O(1)$ time. Only pointers are changed by a rotation; all other attributes in a node remain the same.

\subsection{Insertion}

RB-INSERT($T,z$)
\begin{algorithmic}[1]
\State $y = T.\text{nil}$
\State $x = T.\text{root}$
\While {$x \neq T.\text{nil}$}
	\State $y = x$
        \If {$z.key < x.\text{key}$}
        	\State $x = x.\text{left}$
        \Else
        	\State $x = x.\text{right}$
        \EndIf
\EndWhile
\State $z.p = y$
\If {$y == T.\text{nil}$}
	\State $T.\text{root} = z$
\ElsIf {$z.\text{key} < y.\text{key}$}
	\State $y.\text{left} = z$
\Else
	\State $y.\text{right} = z$
\EndIf
\State $z.\text{left} = T.\text{nil}$
\State $z.\text{right} = T.\text{nil}$
\State $z.\text{color} = RED$
\State RB-INSERT-FIXUP($T,z$)
\end{algorithmic}

RB-INSERT-FIXUP($T,z$)
\begin{algorithmic}[1]
\While {$z.p.\text{color} == RED$}
        \If {$z.p == z.p.p.\text{left}$}
        	\State $y = z.p.p.\text{right}$
                \If {$y.\text{color} == RED$}
                	\State $z.p.\text{color} = BLACK$
                        \State $y.\text{color} = BLACK$
                        \State $z.p.p.\text{color} = RED$
                        \State $z = z.p.p$
                \Else
                	\If {$z == z.p.\text{right}$}
                		\State $z = z.p$
                        	\State LEFT-ROTATE($T,z$)
                        \EndIf
                        \State $z.p.\text{color} = BLACK$
                        \State $z.p.p.\text{color} = RED$
                        \State RIGHT-ROTATE($T,z.p.p$)
                \EndIf
        \Else
        	\State (same as \textbf {then} clause with ``right'' and ``left'' exchanged)
        \EndIf
\EndWhile
\State $T.\text{root}.\text{color} = BLACK$
\end{algorithmic}

\section{Augmenting Data Structures}

\subsection{Dynamic order statistics}

Recall that the $i$th order statistic of a set of $n$ elements, where $i \in \{ 1,2,\dots,n \}$, is simply the element in the set with the $i$th smallest key. The \textbf{rank} of an element is its position in the linear order of the set. \\

An \textbf{order-statistic tree} T is simply a red-black tree with additional information sorted in each node. Besides the usual red-black tree attributes $x.key$, $x.color$, $x.p$, $x.left$ and $x.right$ in a node x, we have another attribute, $x.size$. This attribute contains the number of (internal) nodes in the subtree rooted at $x$ (including $x$ itself), that is, the size of the subtree. If we define the sentinel's size to be 0 -- that is, we set $T.\text{nil}.\text{size}$ to be 0 -- then we have the identity
\begin{equation*}
  x.\text{size} = x.\text{left}.\text{size} + x.\text{right}.\text{size} + 1
\end{equation*}

\subsubsection*{Retrieving an element with a given rank}

OS-SELECT($x,i$)
\begin{algorithmic}[1]
\State $r = x.left.size + 1$
\If {$i == r$}
	\State \textbf{return} $x$
\ElsIf {$i < r$}
	\State \textbf{return} OS-SELECT($x.left, i$)
\Else
	\State \textbf{return} OS-SELECT($x.right, i-r$)
\EndIf
\end{algorithmic}

The running time of OS-SELECT is $O(\lg n)$ for a dynamic set of $n$ elements.

\subsubsection*{Determining the rank of an element}

OS-RANK($T, x$)
\begin{algorithmic}[1]
\State $r = x.left.size + 1$
\State $y = x$
\While {$y \neq T.root$}
	\If {$y == y.p.right$}
        	\State $r = r + y.p.left.size + 1$
        \EndIf
        \State $y = y.p$
\EndWhile
\State \textbf{return} $r$
\end{algorithmic}

The running time of OS-RANK is at worst proportional to the height of the tree: $O(\lg n)$ on an $n$-node order-statistic tree.

\subsection{How to augment a data structure}

We can break the process of augmenting a data structure into four steps:
\begin{enumerate}
  \item Choose an underlying data structure.
  \item Determine additional information to maintain in the underlying data structure.
  \item Verify that we can maintain the additional information for the basic modifying operations on the underlying data structure.
  \item Develop new operations.
\end{enumerate}

\begin{theorem} [Augmenting a red-black tree]
  Let $f$ be an attribute that augments a red-black tree $T$ of $n$ nodes, and suppose that the value of $f$ for each node $x$ depends on only the information in nodes $x$, $x.\text{left}$, and $x.\text{right}$, possibly including $x.\text{left}.f$ and $x.\text{right}.f$. Then, we can maintain the values of $f$ in all nodes of $T$ during insertion and deletion without asymptotically affecting the $O(\lg n)$ performance of these operations.
\end{theorem}

\section{Dynamic Programming}

Dynamic programming, like the divide-and-conquer method, solves problems by combining the solutions to sub-problems. (``Programming'' in this context refers to a tabular method, not to writing computer code.)

We typically apply dynamic programming to optimization problems. When developing a dynamic-programming algorithm, we follow a sequence of four steps:
\begin{enumerate}
  \item Characterize the structure of an optimal solution.
  \item Recursively define the value of an optimal solution.
  \item Compute the value of an optimal solution, typically in a bottom-up fashion.
  \item Construct an optimal solution from computed information.
\end{enumerate}

\subsection{Rod cutting}

The \textbf{rod-cutting problem} is the following. Given a rod of length $n$ inches and a table of prices $p_i$ for $i = 1, 2, \dots, n$, determine the maximum revenue $r_n$ obtainable by cutting up the rod and selling the pieces. Note that if the price $p_n$ for a rod of length n is large enough, an optimal solution may require no cutting at all.

\subsubsection*{Recursive top-down implementation}

CUT-ROD($p, n$)
\begin{algorithmic}[1]
\If {$n == 0$}
	\State \textbf{return } $0$
\EndIf
\State $q = -\infty$
\For {$i = 1 \textbf { to } n$}
	\State $q = \max (q, p[i] + \text{CUT-ROD}(p, n-i))$
\EndFor
\State \textbf{return } $q$
\end{algorithmic}

For this algorithm, $T(0) = 1$. And the time complexity is

\begin{eqnarray*}
  T(n) &=& 1 + \sum_{j=0}^{n-1} {T(j)} \\
  \Rightarrow T(n) &=& 2^n
\end{eqnarray*}

\subsubsection*{Using dynamic programming for optimal rod cutting}

The dynamic-programming method works as follows. Having observed that naive recursive solution is inefficient because it solves the same sub-problems repeatedly, we arrange for each sub-problem to be solved only once, saving its solution. If we need to refer to this sub-problem's solution again later, we can just look it up, rather than recompute it. Dynamic programming thus uses additional memory to save computation time; it serves an example of a \textbf{time-memory trade-off}. The savings may be dramatic: an exponential-time solution may be transformed into a polynomial-time solution. A dynamic-programing approach runs in polynomial time when the number of distinct sub-problems involved is polynomial int the input size and we can solve each sub-problem in polynomial time. \\

There are usually two equivalent ways to implement a dynamic-programming approach: \textbf{top-down with memorization} and \textbf{bottom-up method}. \\

MEMORIZED-CUT-ROD($p, n$)
\begin{algorithmic}[1]
\State let $r[0 \dots n]$ be a new array
\For {$i = 0 \textbf{ to } n$}
	\State $r[i] = -\infty$
\EndFor
\State \textbf{return } MEMORIZED-CUT-ROD-AUX($p, n, r$)
\end{algorithmic}


MEMORIZED-CUT-ROD-AUX($p, n$)
\begin{algorithmic}[1]
\If $r[n] \ge 0$
	\State \textbf{return } $r[n]$
\EndIf
\If {$n == 0$}
	\State $q = 0$
\Else
	\State $q = -\infty$
        \For {$i = 1 \textbf{ to } n$}
        	\State $q = \max(q, p[i] + MEMORIZED-CUT-ROD-AUX(p, n-i, r))$
        \EndFor
\EndIf
\State $r[n] = q$
\State \textbf{return } $q$
\end{algorithmic}

The bottom-up version is even simpler: \\

BOTTOM-UP-CUT-ROD($p, n$)
\begin{algorithmic}[1]
\State let $r[0 \dots n]$ be a new array
\State $r[0] = 0$
\For {$j = 1 \textbf{ to } n$}
	\State $q = -\infty$
        \For {$i = 1 \textbf{ to } j$}
        	\State $q = \max(q, p[i] + r(j-i))$
        \EndFor
        \State $r[j] = q$
\EndFor
\State \textbf{return } $r[n]$
\end{algorithmic}

\subsubsection{Reconstructing a solution}

EXTENDED-BOTTOM-UP-CUT-ROD($p, n$)
\begin{algorithmic}[1]
\State let $r[0 \dots n]$ and $s[0 \dots n]$ be a new array
\State $r[0] = 0$
\For {$j = 1 \textbf{ to } n$}
	\State $q = -\infty$
        \For {$i = 1 \textbf{ to } j$}
        	\State $q = \max(q, p[i] + r(j-i))$
                \State $S[j] = i$
        \EndFor
        \State $r[j] = q$
\EndFor
\State \textbf{return } $r[n]$
\end{algorithmic}

The following procedure prints out the complete list of piece sizes in an optimal decomposition of a rod of length $n$: \\

PRINT-CUT-ROD-SOLUTION($p, n$)
\begin{algorithmic}[1]
\State $(r,s) = \text{EXTENDED-BOTTOM-UP-CUT-ROD($p, n$)}$
\While {$ n > 0$}
	\State print $S[n]$
        \State $n = n - S[n]$
\EndWhile
\end{algorithmic}

\section{Greedy Algorithms}

For many optimization problems, using dynamic programming to determine the best choices is overkill; simpler, more efficient algorithms will do. A \textbf{greedy algorithm} always makes the choice that looks best at the moment. That is, it makes a locally optimal choice in the hope that this choice will lead to a globally optimal solution.

\subsection{An activity-selection problem}

Suppose we have a set $S = \{ a_1, a_2, \dots, a_n \}$ of $n$ proposed \textbf{activities} that wish to use a resource, such as a lecture hall, which can serve only one activity at a time. Each activity $a_i$ has a \textbf{start time} $s_i$ and a \textbf{finish time} $f_i$, where $0 \le s_i < f_i < \infty$. If selected, activity $a_i$ takes place during the half0open time interval $[s_i, f_i)$. Activities $a_i$ and $a_j$ are \textbf{compatible} if the intervals $[s_i, f_i)$ and $[s_j, f_j)$. do not overlap. That is, $a_i$ and $a_j$ are compatible if $s_i \ge f_j$ or $s_j \ge f_i$. In the \textbf{activity-selection problem}, we wish to select a maximum-size subset of mutually compatible activities. We assume that the activities are sorted in monotonically increasing order of finish time:

\begin{equation*}
  f_1 \le f_2 \le f_3 \le \dots \le f_{n-1} \le f_n
\end{equation*}

\subsubsection*{The optimal sub-structure of the activity-selection problem}

Let us denote by $S_{ij}$ the set of activities that start after activity $a_i$ finishes and that finish before activity $a_j$ starts. Suppose that we wish to find a maximum set of mutually compatible activities in $S_{ij}$, and suppose further that such a maximum set is $A_{ij}$, which includes some activity $a_k$. By including $a_k$ in an optimal solution, we are left with two sub-problems: finding mutually compatible activities in the set $S_{ik}$ and fining mutually compatible activities in the set $S_{kj}$. Let $A_{ik} = A_{ij} \cap S_{ik}$ and $A_{kj} = A_{ij} \cap S_{kj}$, so that $A_{ik}$ contains the activities in $A_{ij}$ finish before $a_k$ starts and $A_{kj}$ contains activities in $A_{ij}$ that start after $a_k$ finishes. Thus we have $A_{ij} = A_{ik} \cup \{ a_k \} \cup A_{kj}$, and so the maximum-size set $A_{ij}$ of mutually compatible activities in $S_{ij}$ consists of $|A_{ij}| = |A_{ik}| + |A_{kj}| + 1$activities. \\

The usual cut-and-paste argument shows that the optimal solution $A_{ij}$ must also include optimal solutions to the two sub-problems for $S_{ik}$ and $S_{kj}$. \\

This way of characterizing optimal substructure suggests that we might solve the activity-selection problem by dynamic programming. If we denote the size of an optimal solution for the set $S_{ij}$ by $c[i,j]$, then we would have the recurrence

\begin{equation*}
  c[i,j] = c[i,k] + c[k,j] + 1
\end{equation*}

Of course, if we did not know that an optimal solution for the set $S_{ij}$ includes activity $a_k$, we would have to examine all activities in $S_{ij}$ to find which one to choose, so that

\begin{equation*}
  c[i,j] =
  \begin{cases}
    0 & \text{if $S_{ij} = \emptyset$,} \\
    \max_{a_k \in S_{i,j}} \{ c[i,k] + c[k,j] + 1\} & \text{if $S_{ij} \neq \emptyset$.}
  \end{cases}
\end{equation*}

\subsubsection*{Making the greedy choice}

For the activity-selection problem, we need consider only one choice: the greedy choice. \\

What do we mean by the greedy choice for the activity-selection problem? Intuition suggests that we should choose an activity that leaves the resource available for as many other activities as possible. Now, of activities we end up choosing, one of them must be the first one to finish. Our intuition tells us, therefore, to choose the activity in S with the earliest finish time, since that would leave the resource available for as many of the activities that follow it as possible. \\

\begin{theorem}
  Consider any nonempty sub-problem $S_k$, and let $a_m$ be an activity in $S_k$ with the earliest finish time. Then $a_m$ is included in some maximum-size subset of mutually compatible activities of $S_k$.
\end{theorem}

\subsubsection*{A recursive greedy algorithm}

The procedure $RECURSIVE-ACTIVITY-SELECTOR$ takes the start and finish time of the activities, represented as arrays $s$ and $f$, the index $k$ that defines the sub-problem $S_k$ it is to solve, and the size $n$ of the original problem. It returns a maximum-size set of mutually compatible activities in $S_k$. We assume that the $n$ input activities are already ordered by monotonically increasing finish time, according to the previous equation. If not we can sort them into this order in $O(n \log n)$ time, breaking ties arbitrarily. In order to start, we add the fictitious activity $a_0$ with $f_0 = 0$, so that sub-problem $S_0$ is the entire set of activities $S$. The initial call, which solves the entire problem, is $RECURSIVE-ACTIVITY-SELECTOR(s, f, 0, n)$

RECURSIVE-ACTIVITY-SELECTOR($s, f, k, n$)
\begin{algorithmic}[1]
\State $m = k + 1$
\While {$ m \le n \text{ and } s[m] < f[k]$}
	\State $m = m + 1$
\EndWhile
\If {$m \le n$}
	\State \textbf{return } $\{ a_m\} \cup \text{RECURSIVE-ACTIVITY-SELECTOR}(s, f, m, n)$
\Else
	\State \textbf{return } $\emptyset$
\EndIf
\end{algorithmic}

\subsubsection*{An iterative greedy algorithm}

GREEDY-ACTIVITY-SELECTOR($s, f$)
\begin{algorithmic}[1]
\State $n = s. \text{length}$
\State $A = {a_1}$
\State $k = 1$
\For {$ m = 2 \textbf{ to } n$}
	\If {$s[m] \ge f[k]$}
		\State $A = A \cup \{ a_m \}$
                \State $k = m$
	\EndIf
\EndFor
\State \textbf{return } $A$
\end{algorithmic}

\subsection{Elements of the greedy strategy}

\begin{enumerate}
  \item Determine the optimal substructure of the problem.
  \item Develop a recursive solution.
  \item Show that if we make the greedy choice, then only one sub-problem remains.
  \item Prove that it is always safe to make the greedy choice.
  \item Develop a recursive algorithm that implements that greedy strategy.
  \item Convert the recursive algorithm to an iterative algorithm.
\end{enumerate}

More generally, we design greedy algorithms according to the following sequence of steps:

\begin{enumerate}
  \item Cast the optimization problem as one in which we make a choice and are left with one sub-problem to solve.
  \item Prove that there is always an optimal solution to the original problem that makes the greedy choice, so that greedy choice is always safe.
  \item Demonstrate optimal sub-structure by showing that, having made the greedy choice, what remains is a sub-problem wit the property that if we combine an optimal solution to the sub-problem with the greedy choice we have made, we arrive at an optimal solution to the original problem.
\end{enumerate}

\subsubsection*{Greedy-choice property}

The first key ingredient is the \textbf{greedy-choice property}: we can assemble a globally optimal solution by making locally optimal (greedy) choices. \\

Here is where greedy algorithms differ from dynamic programming. In dynamic programming, we make a choice at each step, but the choice usually depends on the solutions to sub-problems. Consequently, we typically solve dynamic-programming problems in a bottom-up manner, progressing from smaller sub-problems to larger sub-problems. In a greedy algorithm, we make whatever choice seems best at the moment and then solve the sub-problem that remains. The choice made by a greedy algorithm may depend on choices so far, but it cannot depend on any future choices or on the solutions to sub-problems. Thus, unlike dynamic programming, which solves the sub-problems before making the first choice, a greedy algorithm makes its first choice before solving any sub-problems.

\subsubsection*{Optimal substructure}

A problem exhibits \textbf{optimal substructure} if an optimal solution to the problem contains within it optimal solutions to sub-problems. This property is a key ingredient of assessing the applicability of dynamic programming as well as greedy algorithms.

\section{Amortized Analysis}

In an amortized analysis, we average the time required to perform a sequence of data-structure operations over all the operations performed. With amortized analysis, we can show that the average cost of an operation is small, if we average over a sequence of operations, even though a single operation within the sequence might be expensive. Amortized analysis differs from average-case analysis in that probability is not involved; an amortized analysis guarantees the average performance of each operation in the worst case.

\subsection{Aggregate analysis}

In \textbf{aggregate analysis}, we show that for all $n$, a sequence of $n$ operations takes worst-case time $T(n)$ in total. In the worst case, the average cost, or \textbf{amortized cost}, per operation is therefore $T(n)/n$.

\subsection{The accounting method}

In the \textbf{accounting method} of amortized analysis, we assign differing charges to different operations, with some operations charged more or less than they actually cost. We call the amount we charge an operation its \textbf{amortized cost}. When an operation's amortized cost exceeds its actual cost, we assign the difference to specific objects in the data structure as \textbf{credits}. Credit can help pay for later operations whose amortized cost is less than their actual cost. Thus, we can view the amortized cost of an operation as being split between its actual cost and credit that is either deposited or used up. Different operations may have different amortized costs. This method differs from aggregate analysis, in which all operations have the same amortized cost. \\

IF we denote the actual cost of the $i$th operation by $c_i$ and the amortized cost of the $i$th operation by $\hat{c}_i$, we require

\begin{equation*}
  \sum_{i=1}^{n} \hat{c}_i \ge \sum_{i=1}^n c_i
\end{equation*}

for all sequences of $n$ operations. The total credit stored in the data structure is the difference between the total amortized cost and the total actual cost, or $\sum_{i=1}^{n} \hat{c}_i - \sum_{i=1}^n c_i$. By the previous inequality, the total credit associated with the data structure must be non-negative at all times. 

\subsection{The potential method}

Instead of representing prepaid work as credit stored with specific objects in the data structure, the \textbf{potential method} of amortized analysis represents the prepaid work as ``potential energy'', or just ``potential,'' which can be released to pay for future operations. We associate the potential with the data structure as a whole rather than with specific objects with the data structure. \\

The potential method works as follows. We will perform $n$ operations, starting with an initial data structure $D_0$. For each $i = 1,2,\dots$, we let $c_i$ be the actual cost of the $i$th operation and $D_i$ be the data structure that results after applying the $i$th operation to the data structure $D_{i-1}$. A \textbf{potential function} $\Phi$ maps each data structure $D_i$ to a real number $\Phi(D_i)$, which is the \textbf{potential} associated with data structure $D_i$. The \textbf{amortized cost} $\hat{c}_i$ of the $i$th operation with respect to potential function $\Phi$ is defined by

\begin{equation*}
  \hat{c}_i = c_i + \Phi(D_i) - \Phi(D_{i-1}).
\end{equation*}

The amortized cost of each operation is therefore its actual cost plus the change in potential due to the operation. By the previous equation, the total amortized cost of the $n$ operation is

\begin{eqnarray*}
  \sum_{i=1}^n \hat{c}_i
  &=& \sum_{i=1}^n (c_i + \Phi(D_i) - \Phi(D_{i-1})) \\
  &=& \sum_{i=1}^n c_i + \Phi(D_i) - \Phi(D_0)
\end{eqnarray*}

If we can define a potential function $\Phi$ so that $\Phi(D_n) \ge \Phi(D_0)$, then the total amortized cost $\sum_{i=1}^n \hat{c}_i$ gives an upper bound on the total actual cost $\sum_{i=1}^n c_i$. In practice, we do not always know how many operations might be performed. Therefore, if we require that $\Phi(D_i) \ge \Phi(D_0)$ for all $i$, then we guarantee, as in the accounting method, that we pay in advance. We usually just define $\Phi(D_0)$ to be 0 and then show that $\Phi(D_i) \ge 0$ for all $i$.

\section{B-Trees}

B-trees are balanced search trees designed to work well on disks or other direct-access secondary storage devices. B-trees are similar to red-black trees, but they are better at minimizing disk I/O operations. Many database systems use B-trees, or variants of B-trees, to store information. \\

B-tree differ from red-black trees in that B-tree nodes may have many children, from a few to thousands. That is, the ``branching factor'' of a B-tree can be quite large, although it usually depends on characteristics of the disk unit used. B-trees are similar to red-black trees in that every n-node B-tree has height $O(\log n)$. The exact height of a B-tree can be considerably less than that of a red-black tree, however, because its branching factor, and hence the base of the logarithm that expresses its height, can be much larger. Therefore, we can also use B-trees to implement many dynamic-set operations in time $O(\log n)$.

\subsection{Definition of B-trees}

A common variant on a B-tree, known as a \textbf{$B^+$-tree}, stores all the satellite information in the leaves and stores only keys and child pointers in the internal nodes, thus maximizing the branching factor of the internal nodes. \\

A \textbf{B-tree} $T$ is a rooted tree (whose root is T.root) having the following properties:
\begin{enumerate}
  \item Every node $x$ has the following attributes:
    \begin{enumerate}
    	\item $x.n$, the number of keys currently stored in node $x$,
        \item the $x.n$ keys themselves, $x.\text{key}_1, x.\text{key}_2, \dots, x.\text{key}_{x.n}$, stored in non-decreasing order, so that $x.\text{key}_1 \le x.\text{key}_2 \le \dots \le x.\text{key}_{x.n}$,
        \item $x.\text{leaf}$, a boolean value that is TRUE if $x$ is a leaf and FALSE if $x$ is an internal node.
    \end{enumerate}
  \item Each internal node $x$ also contains $x.n+1$ pointers $x.c_1, x.c_2, \dots, x.c_{x.n+1}$ to its children. Leaf nodes have no children, and so their $c_i$ attributes are undefined.
  \item The keys $x.\text{key}_i$ separate the ranges of keys stored in each subtree: if $k_i$ is any key stored in the subtree with root $x.c_i$, then 
    \begin{equation}
      k_1 \le x.key_1 \le k_2 \le x.key_2 \le \dots \le x.key_{x.n} \le k_{x.n+1}
    \end{equation}
  \item All leaves have the same depth, which is the tree's height $h$.
  \item Nodes have lower and upper bounds on the number of keys they can contain. We express these bounds in terms of a fixed integer $t \ge 2$ called the \textbf{minimum degree} of the B-tree:
    \begin{enumerate}
      \item Every node other than the root must have at least $t-1$ keys. Every internal node other than the root thus has at least $t$ children. If the tree is non-empty, the root must have at least one key.
      \item Ever node may contain at most $2t-1$ keys. Therefore, an internal node may have at most $2t$ children. We say that a node is \textbf{full} if it contains exactly $2t-1$ keys.
    \end{enumerate}
\end{enumerate}

The simplest B-tree occurs when $t=2$. Every internal node then has either 2, 3, or 4 children, and we have a \textbf{2-3-4 tree}. In practice, however, much larger values of $t$ yield of B-trees with smaller height.

\section{Elementary Graph Algorithms}

\subsection{Representations of graphs}

We can choose between two standard ways to represent a graph $G = (V,E)$: as a collection of adjacency lists or as an adjacency matrix. Either way applies to both directed and undirected graphs. Because the adjacency-list representation provides a compact way to represent \textbf{sparse} graphs--those for which $|E|$ is much less than $|V|^2$--it is usually the method of choice. Most of the graph algorithms presented in this book assume that an input graph is represented in adjacency-list form. We may prefer an adjacency-matrix representation, however, when the graph is \textbf{dense}--$|E|$ is close to $|V|^2$--or when we need to be able to tell quickly if there is an edge connecting two given vertices. \\

The \textbf{adjacency-list representation} of a graph $G = (V,E)$ consists of an array $Adj$ of $|V|$ lists, one for each vertex in $V$. For each $u \in V$, the adjacency list $Adj[u]$ contains all the vertices $v$ such that there is an edge $(u,v) \in E$. That is $Adj[u]$ consists of all the vertices adjacent to $u$ in $G$. (Alternatively, it may contain pointers to these vertices.) Since the adjacency lists represent the edges of a graph, in pseudocode we treat the array $Adj$ as an attribute of the graph, just as we treat the edge set $E$. In pseudocode, therefore, we will see notation such as $G.Adj[u]$. For both directed and undirected graphs, the adjacency-list representation has the desirable property that the amount of memory it requires is $\Theta (V+E)$. \\

We can readily adapt adjacency list to represent \textbf{weighted graphs}, that is, graphs for which each edge has an associated \textbf{weight}, typically given by a \textbf{weight function} $\omega : E \rightarrow \mathbb{
R}$. We simply store the weight $\omega(u,v)$ of the edge $(u,v) \in E$ with vertex $v$ in $u$'s adjacency list. The adjacency-list representation is quite robust in that we can modify it to support many other graph variants. \\

For the \textbf{adjacency-matrix representation} of a graph $G = (V,E)$, we assume that the vertices are numbered $1,2,\dots,|V|$ in some arbitrary manner. Then the adjacency-matrix representation of a graph $G$ consists of a $|V| \times |V|$ matrix $A = (a_{ij})$ such that

\begin{equation*}
  a_{ij} =
  \begin{cases}
    1 & \text{if $(i,j) \in E$,} \\
    0 & \text{otherwise.}
  \end{cases}
\end{equation*}

Like the adjacency-list representation of a graph, an adjacency matrix can represent a weighted graph. We can simply store the weight $\omega(u,v)$ of the edge $(u,v) \in E$ as the entry in row $u$ and column $v$ of the adjacency matrix. If an edge does not exist, we can store a $NIL$ value as its corresponding matrix entry, though for many problems it is convenient to use a value such as $0$ or $\infty$. \\

Although the adjacency-list representation is asymptotically at least as space-efficient as the adjacency-matrix representation, adjacency matrices are simpler, and so we may prefer them when the graphs are reasonably small. Moreover, adjacency matrices carry a further advantage for unweighted graphs: they require only one bit per entry.

\subsection{Breadth-first search}

Given a graph $G = (V,E)$ and a distinguished \textbf{source} vertex $s$, breadth-first search systematically explores the edges of $G$ to ``discover'' every vertex that is reachable from $s$. It computes the distance (smallest number of edges) from $s$ to each reachable vertex. It also produce a ``breadth-first tree'' with root $s$ that to each reachable vertices. For any vertex $v$ reachable from $s$, the simple path in the breadth-first tree from $s$ to $v$ corresponds to a ``shortest path'' from $s$ to $v$ in $G$, that is, a path containing the smallest number of edges. The algorithm works on both directed and undirected graphs. \\

The breadth-first-search procedure BFS below assumes that the input graph $G = (V,E)$ is represented using adjacency lists. \\

BFS($G, s$)
\begin{algorithmic}[1]
\For {each vertex $u \in G.V - \{ s \}$}
	\State $u.\text{color} = \text{WHITE}$
	\State $u.d = \infty$
	\State $u.\pi = \text{NIL}$
\EndFor
\State $s.\text{color} = \text{WHITE}$
\State $s.d = 0$
\State $s.\pi = \text{NIL}$
\State $Q = \emptyset$
\State ENQUEUE($Q,s$)
\While {$Q \neq \emptyset$}
	\State $u = \text{DEQUEUE}(Q)$
        \For {each $v \in G.Adj[u]$}
        	\If {$v.\text{color} == \text{WHITE}$}
                	\State $v.\text{color} == \text{GREY}$
                        \State $v.d = u.d + 1$
                        \State $v.\pi = u$
                        \State ENQUEUE($Q, v$)
                \EndIf
        \EndFor
        \State $u.\text{color} == \text{BLACK}$
\EndWhile
\end{algorithmic}

\subsubsection*{Analysis}

Because the procedure scans the adjacency list of each vertex only when the vertex is dequeued, it scans each adjacency list at most once. Since the sum of the lengths of all the adjacency lists is $\Theta(E)$, the total time spent in scanning adjacency lists is $O(E)$. The overhead for initialization is $O(V)$, and thus the total running time of the BFS procedure is $O(V+E)$.

\subsubsection*{Shortest paths}

Define the \textbf{shortest-path distance} $\delta(s,v)$ from $s$ to $v$ as the minimum number of edges in any path from vertex $s$ to vertex $v$; if there is no path from $s$ to $v$, then $\delta (s,v) = \infty$. We call a path of length $\delta(s,v)$ from $s$ to $v$ a \textbf{shortest path} from $s$ to $v$.

\begin{lemma}
  Let $G = (V,E)$ be a directed or undirected graph, and let $s \in V$ be an arbitrary vertex. Then, for any edge $(u,v) \in E$,
  \begin{equation*}
    \delta(s,v) \le \delta(s,u) + 1
  \end{equation*}
\end{lemma}

\begin{lemma}
  Let $G = (V,E)$ be a directed or undirected graph, and suppose that BFS is run on $G$ from a given source vertex $s \in V$. Then upon termination, for each vertex $v \in V$, the value $v.d$ computed by BFS satisfies $v.d \ge \delta(s,v)$.
\end{lemma}

\begin{lemma}
  Suppose that during the execution of BFS on a graph $G = (V,E)$, the queue $Q$ contains the vertices $(v_1, v_2, \dots, v_r)$, where $v_1$ is the head of $Q$ and $v_r$ is the tail. Then, $v_r.d \le v_1.d + 1$ and $v_i.d \le v_{i+1}.d$ for $i = 1, 2, \dots, r-1$.
\end{lemma}

\begin{corollary}
  Suppose that vertices $v_i$ and $v_j$ are enqueued during the execution of BFS, and that $v_i$ is enqueued before $v_j$, Then $v_i.d \le v_j.d$ at the time that $v_j$ is enqueued.
\end{corollary}

\begin{theorem}
  Let $G = (V,E)$ be a directed or undirected graph, and suppose that BFS is run on $G$ from a given source vertex $s \in V$. Then, during its execution, BFS discovers every vertex $v \in V$ that is reachable from the source $s$, and upon termination, $v.d = \delta (s,v)$ for all $v \in V$. Moreover, for any vertex $v \neq s$ that is reachable from $s$, one of the shortest paths from $s$ to $v$ is a shortest path from $s$ to $v.\pi$ followed by the edge $()v.\pi, v$.
\end{theorem}

\subsubsection*{Breadth-first trees}

For a graph $G = (V,E)$ with source $s$, we define the \textbf{predecessor subgraph} of $G$ as $G_{\pi} = \{ V_{\pi}, E_{\pi} \}$, where

\begin{equation*}
  V_{\pi} = \{ v \in V : v.\pi \neq \text{NIL} \} \cup \{ s \}
\end{equation*}

and

\begin{equation*}
  E_{\pi} = \{ (v.\pi, v) : v \in V_{\pi} - \{ s \} \} 
\end{equation*}

The predecessor subgraph $G_{\pi}$ is a \textbf{breadth-first tree} if $V_{\pi}$ consists of the vertices reachable from $s$ and, for all $v \in V_{\pi}$, the subgraph $G_{\pi}$ contains a unique simple path from $s$ to $v$ that is also a shortest path from $s$ to $v$ in $G$. We call the edges in $E_{\pi}$ \text{tree edges}.

\begin{lemma}
  When applied to a directed or undirected graph $G = (V,E)$, procedure BFS constructs $\pi$ so that the predecessor subgraph $G_{\pi} = (V_{\pi}, E_{\pi})$ is a breadth-first tree.
\end{lemma}

\subsection{Depth-first search}

Unlike breadth-first search, whose predecessor subgraph forms a tree, the predecessor subgraph produced by a depth-first search may be composed of several trees, because the search may repeat from multiple sources. Therefore, We define the \textbf{predecessor subgraph} of a depth-first search slightly differently from that of a breadth-first search: we let $G_{\pi} = (V, E_{\pi})$, where

\begin{equation*}
  E_{\pi} = \{ (v.\pi, v) : v \in V \text{ and } v.\pi \neq \text{NIL} \}
\end{equation*}

The predecessor subgraph of a depth-first search forms a \textbf{depth-first forest} comprising several \textbf{depth-first trees}. The edges in $E_{\pi}$ are \textbf{tree edges}. \\

The following pseudocode is the basic depth-first-search algorithm. The input graph $G$ may be undirected or directed. The variable $time$ is a global variable that we use for time stamping. \\

DFS($G$)
\begin{algorithmic}[1]
\For {each vertex $u \in G.V$}
	\State $u.\text{color} = \text{WHITE}$
	\State $u.\pi = \text{NIL}$
\EndFor
\State $\text{time} = 0$
\For {each vertex $u \in G.V$}
	\If {$u.\text{color} == \text{WHITE}$}
		DFS-VISIT($G,u$)
	\EndIf
\EndFor
\end{algorithmic}

DFS-VISIT($G, u$)
\begin{algorithmic}[1]
\State $time = time + 1$
\State $u.d = time$
\State $u.\text{color} = \text{GRAY}$
\For {each vertex $v \in G.Adj[u]$}
	\If {$v.\text{color} == \text{WHITE}$}
		\State $v.\pi == u$
		\State DFS-VISIT($G,v$)
	\EndIf
\EndFor
\State $u.\text{color} = \text{BLACK}$
\State $time = time + 1$
\State $u.f = time$
\end{algorithmic}

Since

\begin{equation*}
  \sum_{v \in V} |Adj[v]| = \Theta(E)
\end{equation*}

the running time of DFS is $\Theta(V+E)$. \\

\subsubsection*{Properties of depth-first search}

Perhaps the most basic property of depth-first search is that the predecessor subgraph $G_{\pi}$ does indeed form a forest of trees. Additionally, vertex $v$ is a descendant of vertex $u$ in the depth-first forest if and only if $v$ is discovered during the time in which $u$ is gray. \\

Another important property of depth-first search is that discovery and finishing times have \textbf{parenthesis structure}. If we represent the discovery of vertex $u$ with a left parenthesis ``$(u$'' and its finishing by a right parenthesis ``$u)$'', then the history of discoveries and finishings makes a well-formed expression in the sense that the parentheses are properly nested.

\begin{theorem}
  In any depth-first search of a (directed or undirected) graph $G=(V,E)$m for any two vertices $u$ and $v$, exactly one of the following three condition holds:
  \begin{itemize}
  \item the intervals $[u.d, u.f]$ and $[v.d, v.f]$ are entirely disjoint, and neither $u$ nor $v$ is a descendant of the other in the depth-first forest,
  \item the interval $[u.d, u.f]$ is contained entirely within the interval $[v.d, v.f]$ and $u$ is the descendant of $v$ in a depth-first tree,
  \item the interval $[v.d, v.f]$ is contained entirely within the interval $[u.d, u.f]$, and $v$ is a descendant of $u$ in a depth-first tree.
  \end{itemize}
\end{theorem}

\begin{corollary}
  Vertex $v$ is a proper descendant of vertex $u$ in the depth-first forest for a (directed or undirected) graph $G$ if and only if $u.d < v.d < v.f < u.f$
\end{corollary}

\begin{theorem} [White-path theorem]
  In a depth-first of a (directed or undirected) graph $G = (V,E)$, vertex $v$ is a descendant of vertex $u$ if and only if at the time $u.d$ that the search discovers $u$, there is a path from $u$ to $v$ consisting entirely of white vertices.
\end{theorem}

\subsubsection*{Classification of edges}

We can define four edge types in terms of the depth-first forest $G_{\pi}$ produced by a depth-first search on $G$:

\begin{enumerate}
  \item \textbf{Tree edges} are edges in the depth-first forest $G_{\pi}$, Edge $(u,v)$ is a tree edge if $v$ was first discovered by exploring edge $(u,v)$
  \item \textbf{Back edges} are those edges $(u,v)$ connecting a vertex $u$ to an ancestor $v$ in a depth-first tree. We consider self-loops, which may occur in directed graphs, to be back edges.
  \item \textbf{Forward edges} are those non-tree edges $(u,v)$ connecting a vertex $u$ to a descendant $v$ in a depth-first tree.
  \item \textbf{Cross edges} all other edges. They can go between vertices in the same depth-first tree, as long as one vertex is not an ancestor of the other, or they can go between vertices in different depth-first trees.
\end{enumerate}

The DFS algorithm has enough information to classify some edges as it encounters them. The key idea is that when we first explore an edge $(u,v)$, the color of vertex $v$ tells us something about the edge:

\begin{enumerate}
  \item WHITE indicates a tree edge.
  \item GRAY indicates a back edge, and
  \item BLACK indicates a forward or cross edges.
\end{enumerate}

An undirected graph may entail some ambiguity in how we classify edges, since $(u,v)$ and $(v,u)$ are really the same edge. In such a case, we classify the edge as the first type in the classification list that applies. Equivalently, we can classify the edge according to whichever of $(u,v)$ or $(v,u)$ the search encounters first.

\begin{theorem}
  In a depth-first search of an undirected graph $G$, every edge of $G$ is neither a tree edge or a back edge.
\end{theorem}

\subsection{Topological sort}

This section shows how we can use depth-first search to perform a topological sort of a directed acyclic graph, or a ``dag'' as it is sometimes called. A \textbf{topological sort} of a dag $G = (V,E)$ is a linear ordering of all its vertices such that if $G$ contains an edge $(u,v)$, then $u$ appears before $v$ in the ordering. (If the graph contains a cycle, then no linear ordering is possible.) \\

The following simple algorithm topologically sorts a dag: \\

TOPOLOGICAL-SORT($G$)
\begin{algorithmic} [1]
\State call DFS($G$) to compute finishing times $v.f$ for each vertex $v$
\State as each vertex is finished, insert it onto the front of a linked list
\State \textbf{return } the linked list of vertices 
\end{algorithmic}

The time complexity of a topological sort is $\Theta(V+E)$. \\

\begin{lemma}
  A directed graph $G$ is acyclic if and only if a depth-first search of $G$ yields no back edges.
\end{lemma}

\begin{theorem}
  TOPOLOGICAL-SORT produces a topological sort of the directed acyclic graph provided as its input.
\end{theorem}

\subsection{Strongly connected component}

We now consider a classic application of depth-first search: decomposing a directed graph into its strongly connected components. This section shows how to do so suing two depth-first searches. Many algorithms that work with directed graphs begin with such a decomposition. After decomposing the graph into strongly connected components, such algorithms run separately on each one and then combine the solutions according to the structure of connections among components. \\

A strongly connected component of a directed graph $G=(V,E)$ is a maximal set of vertices $C \subseteq V$ such that for every pair of vertices $u$ and $v$ in $C$, we have both $u \leadsto v$ and $v \leadsto u$; that is, vertices $u$ and $v$ are reachable from each other. \\

We define the transpose of $G$ is the graph $G^T = (V,E^T)$, where $E^T = \{(u,v) : (v,u) \in E \}$. Given an adjacency-list representation of $G$, he time to create $G^T$ is $O(V+E)$. It is interesting to observe that $G$ and $G^T$ have exactly the same strongly connected components: $u$ and $v$ are reachable from each other in $G$ if and only if they are reachable from each other in $G^T$. \\

STRONGLY-CONNECTED-COMPONENTS($G$)
\begin{algorithmic} [1]
\State call DFS($G$) to compute finishing times $u.f$ for each vertex $x$
\State compute $G^T$
\State call DFS($G^T$), but in the main loop of DFS, consider the vertices in order of decreasing $u.f$ (as computed in line 1)
\State output the vertices of each tree in the depth-first forest formed in line 3 as a separately strongly connected component
\end{algorithmic}

The idea behind this algorithm comes from a key property of the \textbf{component graph} $G^{SCC} = (V^{SCC}, E^{SCC})$, which we define as follows. Suppose that $G$ has a strongly connected components $C_1, C_2, \dots, C_k$. The vertex set $V^{SCC}$ is $\{ v_1, v_2, \dots, v_k \}$, and it contains a vertex $v_i$ for each strongly connected component $C_i$ of $G$. There is an edge $(v_i, v_j) \in E^{SCC}$ if $G$ contains a directed edge $(x, y)$ for some $x \in C_i$ and some $y \in C_j$. Looked at another way, by contracting all edges whose incident vertices are within the same strongly connected component of $G$, the resulting graph is $G^{SCC}$. \\

The key property is that the component graph is a dag, which the following lemma implies.

\begin{lemma}
  Let $C$ and $C'$ be distinct strongly connected components in directed graph $G = (V,E)$, let $u,v \in C$, let $u', v' \in C'$, and suppose that $G$ contains a path $u \leadsto u'$. Then $G$ cannot also contain a path $v' \leadsto v$.
\end{lemma}

We extend the notation for discovery and finishing times to sets of vertices. If $U \subseteq V$, then we define $d(U) = \min_{u \in U} \{ i.d \}$ and $f(U) = \max_{u \in U} \{ u.f \}$. That is, $d(U)$ and $f(U)$ are the earliest discovery time and latest finishing time, respectively, of any vertex in U. \\

The following lemma and its corollary give a key property relating strongly connected components and finishing times in the first depth-first search.

\begin{lemma}
  Let $C$ and $C'$ be distinct strongly connected components in directed graph $G = (V,E)$. Suppose that there is an edge $(u,v) \in E$, where $u \in C$ and $v \in C'$. Then $f(C) > f(C')$. 
\end{lemma}

The following corollary tells us that each edge in $G^T$ that goes between different strongly connected components goes from a component with an earlier finishing time (in the first depth-first search) to a component with a later finishing time.

\begin{corollary}
  Let $C$ and $C'$ be distinct strongly connected components in directed graph $G = (V,E)$. Suppose that there is an edge $(u,v) \in E^T$, where $u \in C$ and $v \in C'$. Then $f(C) < f(C')$.
\end{corollary}

\begin{theorem}
  The STRONGLY-CONNECTED-COMPONENTS procedure correctly computes the strongly connected components of the directed graph $G$ provided as its input.
\end{theorem}

Here is another way to look at how the second depth-first search operates. Consider the component graph $(G^T)^{SCC}$ of $G^T$. If we map each strongly connected component visited in the second depth-first search to a vertex of $(G^T)^{SCC}$, the second depth-first search visits vertices of $(G^T)^{SCC}$, the second depth-first search visits vertices of $(G^T)^{SCC}$ in the reverse of a topologically sorted order. If we reverse the edges of $(G^T)^{SCC}$, we get the graph $((G^T)^{SCC})^T$. Because $((G^T)^{SCC})^T = (G^T)^{SCC}$, the second depth-first search visits the vertices of $G^{SCC}$ in topologically sorted order.








\end{document}


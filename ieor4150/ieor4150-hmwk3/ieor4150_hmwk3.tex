\documentclass[12pt]{article}
\parindent=.25in

\setlength{\oddsidemargin}{0pt}
\setlength{\textwidth}{440pt}
\setlength{\topmargin}{0in}

\usepackage[dvips]{graphicx}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsmath}

\title{IEOR 4150 Homework 3}
\author{Mengqi Zong $<mz2326@columbia.edu>$}

\begin{document}

\maketitle

\setlength{\parindent}{0in}

\section*{Chapter 4}

22. \\
Based on the description, the sample space is
\begin{eqnarray*}
  S = \{ HHH, HHT, HTH, HTT, THH, THT, TTH, TTT\}
\end{eqnarray*}
where $H$ means head and $T$ means tail. \\

We first compute the probabilities associated with the values that X can take on
\begin{eqnarray*}
  P(X = -3) &=& \frac {|\{ TTT \}|}{|S|} = \frac {1}{8} \\
  P(X = -1) &=& \frac {|\{ HTT, THT, TTH \}|}{|S|} = \frac {3}{8} \\
  P(X =  1) &=& \frac {|\{ HHT, HTH, THH \}|}{|S|} = \frac {3}{8} \\
  P(X =  3) &=& \frac {|\{ HHH \}|}{|S|} = \frac {1}{8} \\
\end{eqnarray*}
Then we get
\begin{eqnarray*}
  E(X) &=& \sum_x x Pr(x) \\
       &=& (-3) \cdot \frac {1}{8} + (-1) \cdot \frac {3}{8}
           + 1 \cdot \frac {3}{8} + 3 \cdot \frac {1}{8} \\
       &=& 0
\end{eqnarray*}

34. \\
a)
\begin{eqnarray*}
  F(x) &=& \int_0^x e^{-x} dx \\
       &=& -e^{-x}|_0^x \\
       &=& 1 - e^{-x}
\end{eqnarray*}
To find the median, we have
\begin{eqnarray*}
  F(m) &=& \frac {1}{2} \\
  1 - e^{-m} &=& \frac {1}{2} \\ 
  e^{-m} &=& \frac {1}{2} \\
  m &=& \ln 2
\end{eqnarray*}
b)
\begin{eqnarray*}
  F(x) &=& \int_0^x 1 dx \\
       &=& x|_0^x \\
       &=& x
\end{eqnarray*}
To find the median, we have
\begin{eqnarray*}
  F(m) &=& \frac {1}{2} \\
  x &=& \frac {1}{2} \\ 
\end{eqnarray*}

45. \\
a) The marginal probability distribution of $X_1$ is
\begin{eqnarray*}
  f(X_1 = 0) &=& f(X_1 = 0, X_2 = 1) + f(X_1 = 0, X_2 = 2) = \frac {3}{16} \\ 
  f(X_1 = 1) &=& f(X_1 = 1, X_2 = 1) + f(X_1 = 1, X_2 = 2) = \frac {1}{8} \\ 
  f(X_1 = 2) &=& f(X_1 = 2, X_2 = 1) + f(X_1 = 2, X_2 = 2) = \frac {1}{4} \\ 
  f(X_1 = 3) &=& f(X_1 = 3, X_2 = 1) + f(X_1 = 3, X_2 = 2) = \frac {3}{8}
\end{eqnarray*}
The marginal probability distribution of $X_2$ is
\begin{eqnarray*}
  f(X_2 = 1) &=& f(X_1 = 0, X_2 = 1) + f(X_1 = 1, X_2 = 1) 
    + f(X_1 = 2, X_2 = 1) + f(X_1 = 3, X_2 = 1) = \frac {1}{2} \\ 
  f(X_2 = 2) &=& f(X_1 = 0, X_2 = 2) + f(X_1 = 1, X_2 = 2)
    + f(X_1 = 2, X_2 = 2) + f(X_1 = 3, X_2 = 2) = \frac {1}{2}
\end{eqnarray*}
b)
\begin{eqnarray*}
  E[(X_1)] &=& \sum_{x_1} x_1 f(x_1) \\
           &=& 0 \cdot \frac {3}{16} + 1 \cdot \frac{1}{8}
               + 2 \cdot \frac {1}{4} + 3 \cdot \frac{3}{8} \\
           &=& 1.75 \\
  E[(X_2)] &=& \sum_{x_2} x_2 f(x_2) \\
           &=& 1 \cdot \frac{1}{2} + 2 \cdot \frac {1}{2} \\
           &=& 1.5 \\
  Var(X_1) &=& E[(X_1 - \mu_{X_1})^2] \\
           &=& (0 - 1.75)^2 \cdot \frac {3}{16}
               + (1 - 1.75)^2 \cdot \frac {1}{8}
               + (2 - 1.75)^2 \cdot \frac {1}{4}
               + (3 - 1.75)^2 \cdot \frac {3}{8} \\
           &=& 1.2461 \\
  Var(X_2) &=& E[(X_1 - \mu_{X_2})^2] \\
           &=& (1 - 1.5)^2 \cdot \frac {1}{2}
               + (2 - 1.5)^2 \cdot \frac {1}{2} \\
           &=& \frac {1}{4} \\
  Cov(X_1, X_2)
  &=& E[(X_1 - \mu_{X_1})(X_2 - \mu_{X_2})] \\
  &=& (0 - 1.75)(1 - 1.5) \cdot \frac {3}{16} \cdot \frac {1}{2}
      + (1 - 1.75)(1 - 1.5) \cdot \frac {1}{8} \cdot \frac {1}{2} \\
  &+& (2 - 1.75)(1 - 1.5) \cdot \frac {1}{4} \cdot \frac {1}{2}
      + (3 - 1.75)(1 - 1.5) \cdot \frac {3}{8} \cdot \frac {1}{2} \\
  &+& (0 - 1.75)(2 - 1.5) \cdot \frac {3}{16} \cdot \frac {1}{2}
      + (1 - 1.75)(2 - 1.5) \cdot \frac {1}{8} \cdot \frac {1}{2} \\
  &+& (2 - 1.75)(2 - 1.5) \cdot \frac {1}{4} \cdot \frac {1}{2}
      + (3 - 1.75)(2 - 1.5) \cdot \frac {3}{8} \cdot \frac {1}{2} \\
  &=& 0
\end{eqnarray*}

46. \\
a)
\begin{eqnarray*}
  \int_{-\infty}^{+\infty} f(z) dz
  &=& \int_{0}^{1} kz^2 dz + \int_{1}^{\frac {4}{3}} 1 dz \\
  &=& \frac {k}{3} z^3|_0^1 + z|_1^{\frac {4}{3}} \\
  &=& \frac {k}{3} (1 - 0) + (\frac {4}{3} - 1) \\
  &=& \frac {k}{3} + \frac{1}{3} \\
  &=& \frac {k+1}{3} = 1 \\
  &\Longrightarrow& k = 2
\end{eqnarray*}
b)
\begin{eqnarray*}
  P(b)
  &=&\int_{0}^{1} 2 z^2 dz \\
  &=& \frac {2}{3} z^3|_0^1 \\
  &=& \frac {2}{3}
\end{eqnarray*}
c)
\begin{eqnarray*}
  E[(z)]
  &=& \int_{-\infty}^{+\infty} zf(z) dz \\
  &=& \int_{0}^{1} 2z^3 dz + \int_{1}^{\frac {4}{3}} z dz \\
  &=& \frac {1}{2} z^4|_0^1 + \frac {1}{2} z^2|_1^{\frac {4}{3}} \\
  &=& \frac {1}{2} + \frac {7}{18} \\
  &=& \frac {8}{9} \\
  Var(z)
  &=& \int_{-\infty}^{+\infty} (z - \frac {8}{9})^2 f(z) dz \\
  &=& \int_{0}^{1} (z - \frac {8}{9})^2 2z^2 dz
  + \int_{1}^{\frac {4}{3}} (z - \frac {8}{9})^2 dz \\
  &=& \int_{0}^{1} (2 z^4 - \frac {32}{9} z^3 + \frac {128}{81} z^2) dz
  + \int_{1}^{\frac {4}{3}} (z^2 - \frac {16}{9} z + \frac {64}{81}) dz \\
  &=& (\frac {2}{5} z^5 - \frac {8}{9} z^4 + \frac {128}{243} z^3)|_0^1
  + (\frac{1}{3} z^3 - \frac{8}{9} z^2 + \frac{64}{81} z)|_1^{\frac {4}{3}} \\
  &=& \frac {2}{5} - \frac {8}{9} + \frac {128}{243}
  + \frac {1}{3} (\frac{64}{27} - 1) - \frac{8}{9}(\frac{16}{9} - 1)
  + \frac{64}{81} (\frac {4}{3} - 1) \\
  &=& \frac {1}{15}
\end{eqnarray*}

50. For i,j = 1,...,n, let
\begin{eqnarray*}
  X_i &=&
\begin{cases}
  1 & \text {if trial $i$ results in outcome 1} \\
  0 & \text {if trial $i$ does not result in outcome 1}
\end{cases} \\
  Y_i &=&
\begin{cases}
  1 & \text {if trial $i$ results in outcome 2} \\
  0 & \text {if trial $i$ does not result in outcome 2}
\end{cases}
\end{eqnarray*}
Since all $n$ trials are independent, we have
\begin{eqnarray*}
  N_1 &=& \sum_{i=1}^n X_i \\
  N_2 &=& \sum_{j=1}^n Y_j
\end{eqnarray*}
By linearity of expectation, we have
\begin{eqnarray*}
  E[N_1] &=& \sum_{i=1}^n E[X_i] = np_1 \\
  E[N_2] &=& \sum_{j=1}^n E[Y_j] = np_2
\end{eqnarray*}
Then we get
\begin{eqnarray*}
  Cov(N_1, N_2)
  &=& E[(N_1 - E[N_1])(N_2 - E[N_2])] \\
  &=& E[N_1N_2] - E[N_1]E[N_2] \\
  &=& E[(\sum_{i=1}^n X_i)(\sum_{j=1}^n Y_j)] - n^2 p_1p_2 \\
  &=& E[\sum_{i = j} X_iY_j + \sum_{i \neq j} X_iY_j] - n^2 p_1p_2 \\
  &=& E[\sum_{i = j} X_iY_j] + E[\sum_{i \neq j} X_iY_j] - n^2 p_1p_2 \\
  &=& \sum_{i = j} E[X_iY_j] + \sum_{i \neq j} E[X_iY_j] - n^2 p_1p_2 \\
  &=& \sum_{i = j} E[X_iY_j] + \sum_{i \neq j} E[X_i]E[Y_j] - n^2 p_1p_2 \\
  &=& 0 + n(n-1) p_1 p_2 - n^2 p_1 p_2 \\
  &=& - n p_1 p_2
\end{eqnarray*}
For the $i$th toss, obviously, it can not result in both outcome 1 and outcome 2 at the same time. So $E[X_iY_j] = 0$ when $i = j$. \\

Intuitively, $N_1$ and $N_2$ are negatively correlated. That is, If more trials result in outcome 1, then less trials will result in outcome 2. \\

53.

\begin{eqnarray*}
  \phi(t)
  &=& \int_{0}^{+\infty} e^{tx}e^{-x} dx \\
  &=& \int_{0}^{+\infty} e^{(t-1)x} dx \\
  &=& \frac {1}{t-1} e^{(t-1)x}|_{0}^{+\infty} \\
  &=& \frac {1}{1 - t}
\end{eqnarray*}
where $t < 1$.
\begin{eqnarray*}
  \phi'(t) &=& \frac {1}{(t-1)^2} \\
  \Rightarrow \phi'(0) &=& 1 \\
  \phi''(t) &=& \frac {-2}{(t-1)^3} \\
  \Rightarrow \phi''(0) &=& 2
\end{eqnarray*}
then we get
\begin{eqnarray*}
  E[X] &=& \phi'(0) = 1 \\
  Var(X)
  &=& E[X^2] - (E[X])^2 \\
  &=& \phi''(0) - (\phi'(0))^2 \\
  &=& 2 - 1^2 \\
  &=& 1
\end{eqnarray*}
Now we try to calculate the mean directly
\begin{eqnarray*}
  E[X]
  &=& \int_{0}^{+\infty} x e^{-x} dx \\
  &=& \int_{0}^{+\infty} -x de^{-x} \\
  &=& -xe^{-x}|_0^{+\infty} - \int_{0}^{+\infty} e^{-x} d(-x) \\
  &=& -xe^{-x}|_0^{+\infty} - e^{-x}|_0^{+\infty} \\
  &=& 1
\end{eqnarray*}

55. \\
By 
\begin{equation*}
  P(|X - \mu| \ge k) \le \frac {\sigma^2}{k^2}
\end{equation*}
we get
\begin{equation*}
  P(|X - 20| \ge 20) \le \frac {20}{20^2} = \frac {1}{20}.
\end{equation*}
Then we get
\begin{eqnarray*}
  P(0 \le X \le 40)
  &=& 1 - P(|X - 20| \ge 20) \\
  &\ge& 1 - \frac {1}{20} \\
  &=& \frac {19}{20}
\end{eqnarray*}

\section*{Chapter 5}

6.
\begin{eqnarray*}
  np &=& 7 \\
  np(1-p) &=& 2.1 \\
  \Rightarrow p &=& 0.7 \\
  \Rightarrow n &=& 10
\end{eqnarray*}
So we get
\begin{eqnarray*}
  P(X = 4)
  &=& \binom {10}{4} 0.7^4 0.3^6 \\
  &=& \frac {10!}{4!6!} 0.7^4 0.3^6 \\
  &=& \frac {3^7 7^4}{10^9} \\
  &=& 0.0368
\end{eqnarray*}
Since $n = 10$, then
\begin{eqnarray*}
  P(X > 12) = 0
\end{eqnarray*}

10. \\
a)
\begin{eqnarray*}
  P_{binom}
  &=& \binom {10}{2} 0.1^2 0.9^8 \\
  &=& 0.1937 \\
  P_{poss}
  &=& e^{- (10 \cdot 0.1)} \frac {(10 \cdot 0.1)^2}{2!} \\
  &=& \frac {1}{2e} \\
  &=& 0.1839
\end{eqnarray*}
So $P_{binom} > P_{poss}$. \\
b)
\begin{eqnarray*}
  P_{binom}
  &=& \binom {10}{0} 0.9^{10} \\
  &=& 0.3487 \\
  P_{poss}
  &=& e^{- (10 \cdot 0.1)} \frac {(10 \cdot 0.1)^0}{0!} \\
  &=& \frac {1}{e} \\
  &=& 0.3679
\end{eqnarray*}
So $P_{binom} < P_{poss}$. \\
c)
\begin{eqnarray*}
  P_{binom}
  &=& \binom {9}{4} 0.2^4 0.8^5 \\
  &=& 0.0661 \\
  P_{poss}
  &=& e^{- (9 \cdot 0.2)} \frac {(9 \cdot 0.2)^4}{4!} \\
  &=& \frac {1}{2e} \\
  &=& 0.0723
\end{eqnarray*}
So $P_{binom} < P_{poss}$. \\

17.
\begin{eqnarray*}
  \frac {P \{ X = i \}}{P \{ X = i - 1 \}}
  &=& \frac {e^{- \lambda} \frac {\lambda^i}{i!}}
  {e^{- \lambda} \frac {\lambda^{i-1}}{(i-1)!}} \\
  &=& \frac {\lambda}{i}          
\end{eqnarray*}
As a result
\begin{equation*}
\begin{cases}
  P \{ X = i \} > P \{ X = i - 1 \} & \text {if } i < \lambda \\
  P \{ X = i \} < P \{ X = i - 1 \} & \text {if } i > \lambda
\end{cases}
\end{equation*}
So $P \{ X = i \}$ reaches its maximum value when $i$ is the largest integer less than or equal to $\lambda$.

\end{document}
